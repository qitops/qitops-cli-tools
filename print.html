<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>QitOps Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="custom.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">QitOps Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/qitops/qitops-cli-tools" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="qitops-cli-tools"><a class="header" href="#qitops-cli-tools">QitOps CLI Tools</a></h1>
<p><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a>
<a href="https://github.com/qitops/qitops-cli-tools/actions/workflows/ci.yml"><img src="https://github.com/qitops/qitops-cli-tools/actions/workflows/ci.yml/badge.svg" alt="CI" /></a>
<a href="https://crates.io/crates/qitops"><img src="https://img.shields.io/crates/v/qitops" alt="Crates.io" /></a>
<a href="https://www.rust-lang.org/"><img src="https://img.shields.io/badge/rust-1.70%2B-blue.svg" alt="Rust Version" /></a>
<a href="https://github.com/qitops/qitops-cli-tools/tree/master/docs"><img src="https://img.shields.io/badge/docs-latest-brightgreen.svg" alt="Documentation" /></a></p>
<p>QitOps is a comprehensive Software Quality Assurance CLI tool for API, Performance, Security, and Web Testing. It provides a unified command-line interface with minimal dependencies and maximum flexibility.</p>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<pre><code class="language-bash"># Install QitOps
cargo install --path .

# Run a basic API test
qitops api -c tests/configs/api_test.json

# Run an API collection (multiple requests with dependencies)
qitops collection -c tests/configs/api_collection.json

# Run a performance test
qitops performance -c tests/configs/performance_test.json -u 10 -d 30

# Run a security scan
qitops security -c tests/configs/security_test.json -d 3

# Run a web test
qitops web -c tests/configs/web_test.json

# Generate a report in HTML format
qitops -r html -o report.html api -c tests/configs/api_test.json

# Run in CI mode (reduced output, exit code based on test results)
qitops --ci-mode -r json -o results.json api -c tests/configs/api_test.json

# Run data-driven tests with CSV data
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv

# Run data-driven tests with JSON data
qitops data-driven -c tests/configs/data_driven_collection.json -d tests/data/products.json -t json
</code></pre>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<h3 id="api-testing"><a class="header" href="#api-testing">API Testing</a></h3>
<ul>
<li>HTTP method support (GET, POST, PUT, DELETE, etc.)</li>
<li>URL configuration with environment-specific settings</li>
<li>Custom headers and request body support</li>
<li>Response validation (status codes, body, headers)</li>
<li>Response time monitoring</li>
<li>Configurable timeouts and retries</li>
<li>Retry mechanism with exponential backoff and jitter
<ul>
<li>Configurable retry attempts</li>
<li>Customizable retry delay</li>
<li>Status code-based retry conditions</li>
<li>Connection error handling</li>
<li>Timeout handling</li>
</ul>
</li>
</ul>
<h3 id="api-collections"><a class="header" href="#api-collections">API Collections</a></h3>
<ul>
<li>Group related API requests in a single configuration</li>
<li>Define dependencies between requests</li>
<li>Capture and use data from previous responses using JSONPath</li>
<li>Variable interpolation with {{variable}} syntax</li>
<li>Environment variables and environment-specific configurations</li>
<li>Sequential request execution with dependency management</li>
<li>Shared authentication across requests (Basic, Bearer, API Key)</li>
<li>Default request configuration (headers, timeout, retries)</li>
<li>Detailed collection reporting with captured variables</li>
<li>Request chaining for complex workflows</li>
</ul>
<h3 id="performance-testing"><a class="header" href="#performance-testing">Performance Testing</a></h3>
<ul>
<li>Load testing with configurable concurrent users</li>
<li>Response time analysis</li>
<li>Success rate monitoring</li>
<li>Ramp-up time configuration</li>
<li>Detailed performance metrics
<ul>
<li>Average response time</li>
<li>Minimum response time</li>
<li>Maximum response time</li>
<li>Total requests</li>
<li>Success/error counts</li>
<li>Success rate percentage</li>
</ul>
</li>
</ul>
<h3 id="enhanced-performance-testing"><a class="header" href="#enhanced-performance-testing">Enhanced Performance Testing</a></h3>
<ul>
<li>Multiple load profiles (constant, ramping, spike)</li>
<li>Multi-stage test execution</li>
<li>Multiple scenarios in a single test</li>
<li>Weighted scenario distribution</li>
<li>Detailed metrics collection and reporting</li>
<li>Percentile calculations (p50, p90, p95, p99)</li>
<li>Custom thresholds with pass/fail criteria</li>
<li>Real-time metrics streaming</li>
<li>Tagged metrics for detailed analysis</li>
<li>Scenario-based reporting</li>
</ul>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<ul>
<li>GitHub Actions workflow templates</li>
<li>CI mode with reduced output</li>
<li>Exit codes based on test results</li>
<li>JSON report generation for CI pipelines</li>
<li>Parallel test execution</li>
<li>Environment-specific configurations</li>
<li>Scheduled test runs</li>
<li>Artifact storage for test results and reports</li>
</ul>
<h3 id="data-driven-testing"><a class="header" href="#data-driven-testing">Data-Driven Testing</a></h3>
<ul>
<li>Parameterize tests with CSV and JSON datasets</li>
<li>Variable interpolation with {{placeholder}} syntax</li>
<li>Support for multiple iterations of the same test</li>
<li>Configurable iteration limits</li>
<li>Stop-on-failure option</li>
<li>Detailed iteration reporting</li>
<li>Support for all test types (API, Performance, Security, Web)</li>
<li>CSV header row support</li>
<li>JSON path extraction</li>
<li>Inline data definition</li>
<li>Customizable success thresholds</li>
</ul>
<h3 id="security-testing"><a class="header" href="#security-testing">Security Testing</a></h3>
<ul>
<li>Comprehensive security scanning</li>
<li>Multiple scan types (headers, SSL, vulnerabilities, sensitive data)</li>
<li>Severity-based reporting</li>
<li>Authentication testing</li>
<li>Common vulnerability checks</li>
<li>Security header validation</li>
<li>CSRF and XSS detection</li>
<li>SQL injection testing</li>
<li>JWT security analysis</li>
<li>Access control verification</li>
</ul>
<h3 id="web-testing"><a class="header" href="#web-testing">Web Testing</a></h3>
<ul>
<li>Headless browser automation</li>
<li>Viewport configuration</li>
<li>Screenshot capture</li>
<li>Element assertions</li>
<li>Text content validation</li>
<li>URL and title validation</li>
<li>Action simulation (click, type, wait, navigate)</li>
<li>Custom user agent configuration</li>
</ul>
<h3 id="ai-powered-features"><a class="header" href="#ai-powered-features">AI-Powered Features</a></h3>
<ul>
<li>
<p><strong>Test Configuration Generation</strong>: Create test configurations from natural language descriptions</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output github_test.json
</code></pre>
</li>
<li>
<p><strong>Test Results Analysis</strong>: Analyze test results to identify patterns and issues</p>
<pre><code class="language-bash">qitops analyze --results test_results.json --output analysis.md
</code></pre>
</li>
<li>
<p><strong>Improvement Suggestions</strong>: Get actionable suggestions to improve your tests</p>
<pre><code class="language-bash">qitops improve --results test_results.json --output improvements.md
</code></pre>
</li>
<li>
<p><strong>Local LLM Support</strong>: Works with various local models (LLaMA, Mistral, GPT-J, Phi)</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --model custom --model-path "ollama:phi"
</code></pre>
</li>
<li>
<p><strong>Model Parameter Customization</strong>: Configure temperature, context size, and other parameters</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --temperature 0.7 --context-size 4096
</code></pre>
</li>
<li>
<p><strong>Offline Operation</strong>: Run completely offline with no data sent to external services</p>
<pre><code class="language-bash">export QITOPS_OFFLINE=true
export QITOPS_MODEL_PATH="/path/to/model.gguf"
qitops analyze --results test_results.json --output analysis.md
</code></pre>
</li>
</ul>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<h3 id="from-cratesio-recommended"><a class="header" href="#from-cratesio-recommended">From crates.io (Recommended)</a></h3>
<pre><code class="language-bash"># Install directly from crates.io
cargo install qitops

# Run QitOps
qitops --help
</code></pre>
<h3 id="from-github-releases"><a class="header" href="#from-github-releases">From GitHub Releases</a></h3>
<ol>
<li>Download the latest binary for your platform from the <a href="https://github.com/qitops/qitops-cli-tools/releases">GitHub Releases page</a></li>
<li>Make the file executable (Linux/macOS): <code>chmod +x qitops-*</code></li>
<li>Move it to a directory in your PATH:
<ul>
<li>Linux/macOS: <code>sudo mv qitops-* /usr/local/bin/qitops</code></li>
<li>Windows: Add the directory containing the executable to your PATH</li>
</ul>
</li>
</ol>
<h3 id="using-docker"><a class="header" href="#using-docker">Using Docker</a></h3>
<pre><code class="language-bash"># Pull the Docker image
docker pull qitops/qitops:latest

# Run QitOps
docker run --rm qitops/qitops:latest --help

# Run with mounted volumes for configs and results
docker run --rm -v $(pwd)/configs:/workspace/configs -v $(pwd)/results:/workspace/results qitops/qitops:latest api -c /workspace/configs/api_test.json
</code></pre>
<h3 id="from-source"><a class="header" href="#from-source">From Source</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/qitops/qitops-cli-tools.git
cd qitops-cli-tools

# Build the project
cargo build --release

# Install the binary (optional)
cargo install --path .
</code></pre>
<h3 id="with-ai-features-optional"><a class="header" href="#with-ai-features-optional">With AI Features (Optional)</a></h3>
<pre><code class="language-bash"># Install with AI features enabled
cargo install qitops --features ai
</code></pre>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="api-test-configuration"><a class="header" href="#api-test-configuration">API Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Example API Test",
    "description": "Test description",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "url": "https://api.example.com",
    "method": "GET",
    "headers": {
        "Accept": "application/json",
        "User-Agent": "QitOps-Test"
    },
    "expected_status": 200,
    "expected_body": {
        "field1": "value1",
        "field2": "value2"
    },
    "max_response_time": 2,
    "expected_headers": {
        "content-type": "application/json",
        "cache-control": "no-cache"
    },
    "retry": {
        "max_retries": 3,
        "initial_delay_ms": 100,
        "max_delay_ms": 1000,
        "retry_status_codes": [408, 429, 500, 502, 503, 504],
        "retry_on_timeout": true,
        "retry_on_connection_error": true
    }
}
</code></pre>
<h3 id="api-collection-configuration"><a class="header" href="#api-collection-configuration">API Collection Configuration</a></h3>
<pre><code class="language-json">{
    "name": "GitHub API Collection",
    "description": "A collection of GitHub API tests",
    "version": "1.0.0",
    "variables": {
        "base_url": "https://api.github.com",
        "username": "octocat",
        "repo": "Hello-World"
    },
    "auth": {
        "type": "bearer",
        "token": "{{GITHUB_TOKEN}}"
    },
    "defaults": {
        "headers": {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "QitOps-Test"
        },
        "timeout": 30,
        "retries": 3
    },
    "requests": [
        {
            "name": "Get User",
            "description": "Get a GitHub user",
            "id": "get-user",
            "url": "{{base_url}}/users/{{username}}",
            "method": "GET",
            "expected_status": 200,
            "expected_body": {
                "login": "{{username}}",
                "type": "User"
            },
            "capture": {
                "user_id": "$.id",
                "user_url": "$.url"
            }
        },
        {
            "name": "Get User Repos",
            "description": "Get repositories for a user",
            "id": "get-user-repos",
            "url": "{{user_url}}/repos",
            "method": "GET",
            "depends_on": ["get-user"],
            "expected_status": 200
        }
    ],
    "environments": {
        "production": {
            "base_url": "https://api.github.com"
        },
        "staging": {
            "base_url": "https://api.staging.github.com"
        }
    },
    "run_options": {
        "sequential": true,
        "stop_on_failure": true,
        "delay_between_requests_ms": 500
    }
}
</code></pre>
<h3 id="performance-test-configuration"><a class="header" href="#performance-test-configuration">Performance Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Sample Performance Test",
    "description": "Load testing a public API endpoint",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com/endpoint",
    "method": "GET",
    "headers": {
        "Accept": "application/json"
    },
    "success_threshold": 95.0,
    "ramp_up_time_secs": 5
}
</code></pre>
<h3 id="enhanced-performance-test-configuration"><a class="header" href="#enhanced-performance-test-configuration">Enhanced Performance Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Enhanced Performance Test",
    "description": "Testing API performance with multiple scenarios and load profiles",
    "timeout": 60,
    "retries": 0,
    "environment": "production",
    "load_profile": {
        "type": "ramping_vus",
        "initial": 1,
        "stages": [
            {
                "duration_secs": 30,
                "target": 10
            },
            {
                "duration_secs": 60,
                "target": 20
            },
            {
                "duration_secs": 30,
                "target": 0
            }
        ]
    },
    "scenarios": [
        {
            "name": "Get Request",
            "target_url": "https://httpbin.org/get",
            "method": "GET",
            "headers": {
                "Accept": "application/json",
                "User-Agent": "QitOps-Test/1.0"
            },
            "weight": 3,
            "tags": {
                "endpoint": "get",
                "category": "read"
            }
        },
        {
            "name": "Post Request",
            "target_url": "https://httpbin.org/post",
            "method": "POST",
            "headers": {
                "Content-Type": "application/json",
                "Accept": "application/json"
            },
            "body": {
                "test": "data",
                "number": 123
            },
            "weight": 1,
            "tags": {
                "endpoint": "post",
                "category": "write"
            }
        }
    ],
    "thresholds": [
        {
            "metric": "response_time.avg",
            "expression": "&lt; 0.5",
            "abort_on_fail": false
        },
        {
            "metric": "response_time.p95",
            "expression": "&lt; 1.0",
            "abort_on_fail": false
        },
        {
            "metric": "success.avg",
            "expression": "&gt; 0.95",
            "abort_on_fail": true
        }
    ],
    "success_threshold": 95.0,
    "stream_metrics": true,
    "metrics_interval_secs": 5
}
</code></pre>
<h3 id="security-test-configuration"><a class="header" href="#security-test-configuration">Security Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Security Scan",
    "description": "Comprehensive security scan of the API",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com",
    "headers": {
        "Accept": "application/json"
    },
    "auth": {
        "type": "bearer",
        "token": "your-token"
    },
    "scan_types": [
        "headers",
        "ssl",
        "vulnerabilities",
        "sensitive-data"
    ],
    "max_high_severity_findings": 0
}
</code></pre>
<h3 id="web-test-configuration"><a class="header" href="#web-test-configuration">Web Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Sample Web Test",
    "description": "Testing a public website",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://example.com",
    "viewport": {
        "width": 1280,
        "height": 800,
        "device_scale_factor": 1.0,
        "is_mobile": false
    },
    "wait_for_selector": "body",
    "wait_timeout_secs": 10,
    "screenshots": true,
    "user_agent": "QitOps-WebTester/1.0",
    "assertions": [
        {
            "assertion_type": "title",
            "expected_value": "Example Domain",
            "comparison": "contains"
        },
        {
            "assertion_type": "element",
            "selector": "h1",
            "expected_value": "true"
        }
    ],
    "actions": [
        {
            "action_type": "wait",
            "wait_time_ms": 1000
        },
        {
            "action_type": "click",
            "selector": "a"
        }
    ]
}
</code></pre>
<h3 id="ai-configuration"><a class="header" href="#ai-configuration">AI Configuration</a></h3>
<pre><code class="language-json">{
    "model_type": "llama",
    "model_path": "/usr/local/share/models/llama-2-7b-chat.gguf",
    "context_size": 4096,
    "temperature": 0.7,
    "max_tokens": 2048,
    "system_prompt": "You are an AI assistant specialized in software testing. Your task is to help generate test configurations, analyze test results, and suggest improvements."
}
</code></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<h3 id="api-testing-1"><a class="header" href="#api-testing-1">API Testing</a></h3>
<pre><code class="language-bash"># Run a single API test
qitops api -c tests/configs/api_test.json

# Run tests in a specific environment
qitops api -c tests/configs/api_test.json -e production
</code></pre>
<p>Example output:</p>
<pre><code>Test Results:
Name: Sample API Test
Status: passed
Duration: 0.90s
Details: {
  "headers": {
    "content-type": "application/json",
    "cache-control": "no-cache",
    ...
  },
  "response_time": 0.903123787,
  "status_code": 200
}
Timestamp: 2025-05-09T21:06:33.923402733+00:00
</code></pre>
<h3 id="api-collections-1"><a class="header" href="#api-collections-1">API Collections</a></h3>
<pre><code class="language-bash"># Run an API collection
qitops collection -c tests/configs/api_collection.json

# Run in a specific environment
qitops collection -c tests/configs/api_collection.json -e staging

# Output in JSON format
qitops collection -c tests/configs/api_collection.json -f json
</code></pre>
<p>Example output:</p>
<pre><code>Collection Results:
Name: HTTPBin API Collection
Status: passed
Duration: 2.35s
Timestamp: 2025-05-09T21:07:05.165804274+00:00

Request Results:
  1. Get IP Address - passed
  2. Post with JSON - passed
  3. Get with Headers - passed
  4. Get with Query Parameters - passed

Captured Variables:
  client_ip: 203.0.113.1
  request_id: 97e5b974-e2c3-4073-b45e-5bf5a7f3f0b2
  posted_data: {"test_value":"qitops_test_value","client_ip":"203.0.113.1"}
</code></pre>
<p>The API collections feature supports:</p>
<ul>
<li>Variable interpolation using <code>{{variable}}</code> syntax</li>
<li>Capturing data from responses using JSONPath expressions</li>
<li>Request dependencies to ensure proper execution order</li>
<li>Environment-specific configurations</li>
<li>Shared authentication and default headers</li>
</ul>
<h3 id="performance-testing-1"><a class="header" href="#performance-testing-1">Performance Testing</a></h3>
<pre><code class="language-bash"># Run performance test with default settings
qitops performance -c tests/configs/performance_test.json

# Run with custom concurrent users and duration
qitops performance -c tests/configs/performance_test.json -u 50 -d 120
</code></pre>
<p>Example output:</p>
<pre><code>Performance Test Results:
Name: Sample Performance Test
Status: passed
Duration: 10.04s
Details: {
  "average_response_time": 0.11007347446511631,
  "error_count": 0,
  "max_response_time": 0.521383212,
  "min_response_time": 0.057222978,
  "success_count": 215,
  "success_rate": 100.0,
  "total_requests": 215
}
Timestamp: 2025-05-09T21:06:50.438713024+00:00
</code></pre>
<h3 id="enhanced-performance-testing-1"><a class="header" href="#enhanced-performance-testing-1">Enhanced Performance Testing</a></h3>
<pre><code class="language-bash"># Run enhanced performance test with load profiles and scenarios
qitops performance-enhanced -c tests/configs/enhanced_performance_test.json

# Run in a specific environment
qitops performance-enhanced -c tests/configs/enhanced_performance_test.json -e staging
</code></pre>
<p>Example output:</p>
<pre><code>Enhanced Performance Test Results:
Name: Enhanced Performance Test
Status: passed
Duration: 120.35s

Metrics Summary:
  Total Requests: 1250
  Success Count: 1245
  Error Count: 5
  Success Rate: 99.60%

Response Time:
  Average: 125.32ms
  Min: 57.89ms
  Max: 521.45ms
  p50: 115.67ms
  p90: 198.34ms
  p95: 245.78ms
  p99: 378.91ms

Scenario Results:
  Get Request: 937/940 requests successful (99.68%)
  Post Request: 308/310 requests successful (99.35%)

Thresholds:
  response_time.avg: &lt; 0.5 - PASSED
  response_time.p95: &lt; 1.0 - PASSED
  success.avg: &gt; 0.95 - PASSED

For full details, use the --report option to generate a JSON report.
Timestamp: 2025-05-09T21:08:15.723654912+00:00
</code></pre>
<p>The enhanced performance testing feature supports:</p>
<ul>
<li>Multiple load profiles (constant, ramping, spike)</li>
<li>Multi-stage test execution</li>
<li>Multiple scenarios with weighted distribution</li>
<li>Custom thresholds with pass/fail criteria</li>
<li>Real-time metrics streaming</li>
<li>Detailed metrics with percentiles</li>
</ul>
<h3 id="data-driven-testing-1"><a class="header" href="#data-driven-testing-1">Data-Driven Testing</a></h3>
<pre><code class="language-bash"># Run data-driven API tests with CSV data
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv

# Run with JSON data
qitops data-driven -c tests/configs/data_driven_collection.json -d tests/data/products.json -t json

# Limit the number of iterations
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -m 3

# Stop on first failure
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -s
</code></pre>
<p>Example output:</p>
<pre><code>Iteration 1 Results:
Name: User API Test for johndoe
Status: passed
Duration: 0.52s
Details: {
  "headers": {
    "content-type": "application/json",
    ...
  },
  "response_time": 0.523456,
  "status_code": 200
}
Timestamp: 2025-05-09T21:07:05.165804274+00:00

Data Row:
  username: johndoe
  email: john.doe@example.com
  user_id: 1001
  role: admin

...

Data-Driven Test Summary:
Total Iterations: 5
Successful: 5
Failed: 0
Success Rate: 100.00%
</code></pre>
<p>The data-driven testing feature supports:</p>
<ul>
<li>Parameterizing tests with CSV and JSON datasets</li>
<li>Variable interpolation using <code>{{placeholder}}</code> syntax</li>
<li>Running multiple iterations of the same test with different data</li>
<li>Configurable iteration limits and stop-on-failure options</li>
<li>Detailed reporting for each iteration</li>
</ul>
<h3 id="security-testing-1"><a class="header" href="#security-testing-1">Security Testing</a></h3>
<pre><code class="language-bash"># Run security scan with default settings
qitops security -c tests/configs/security_test.json

# Run with custom scan depth and passive scanning
qitops security -c tests/configs/security_test.json -d 4 -p
</code></pre>
<p>Example output:</p>
<pre><code>Security Test Results:
Name: API Security Test
Status: passed
Duration: 0.00s
Details: {
  "findings": [],
  "summary": {
    "critical_findings": 0,
    "high_findings": 0,
    "low_findings": 0,
    "medium_findings": 0,
    "total_findings": 0
  }
}
Timestamp: 2025-05-09T21:07:05.165804274+00:00
</code></pre>
<h3 id="web-testing-1"><a class="header" href="#web-testing-1">Web Testing</a></h3>
<pre><code class="language-bash"># Run web test with default settings
qitops web -c tests/configs/web_test.json

# Run with headless mode disabled and custom screenshot directory
qitops web -c tests/configs/web_test.json -h false -s ./screenshots
</code></pre>
<p>Example output:</p>
<pre><code>Web Test Results:
Name: Sample Web Test
Status: passed
Duration: 1.25s
Details: {
  "action_results": [
    {
      "duration_ms": 1000,
      "success": true,
      "type": "wait"
    },
    {
      "selector": "a",
      "success": true,
      "type": "click"
    }
  ],
  "assertion_results": [
    {
      "details": "Title: Simulated Page Title",
      "passed": true,
      "type": "title"
    },
    {
      "details": "Element with selector 'h1' exists: true",
      "passed": true,
      "type": "element"
    }
  ],
  "content_length": 1256,
  "page_title": "Simulated Page Title",
  "screenshot": "./screenshots/screenshot_1715284025.png",
  "status_code": 200
}
Timestamp: 2025-05-09T21:07:05.165804274+00:00
</code></pre>
<h3 id="output-formats"><a class="header" href="#output-formats">Output Formats</a></h3>
<p>QitOps provides both human-readable and machine-readable output formats to support both interactive use and CI integration:</p>
<pre><code class="language-bash"># Default human-readable output to stdout
qitops api -c tests/configs/api_test.json

# Generate machine-readable JSON report for CI integration
qitops -r json -o report.json api -c tests/configs/api_test.json

# Generate XML report (JUnit format for CI integration)
qitops -r xml -o report.xml security -c tests/configs/security_test.json

# Generate HTML report for visual inspection
qitops -r html -o report.html performance -c tests/configs/performance_test.json

# Generate CSV report for data analysis
qitops -r csv -o report.csv web -c tests/configs/web_test.json
</code></pre>
<p>All outputs include consistent timestamping for audit trails and traceability.</p>
<h3 id="ai-powered-features-1"><a class="header" href="#ai-powered-features-1">AI-Powered Features</a></h3>
<pre><code class="language-bash"># Generate an API test configuration from a description
qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output tests/configs/github_api_test.json

# Generate a web test configuration from a description
qitops generate --test-type web --description "Test the login form on example.com with valid credentials" --output tests/configs/login_test.json

# Analyze test results
qitops analyze --results results/api_test_result.json --output analysis.md

# Get improvement suggestions based on test results
qitops improve --results results/performance_test_result.json --output improvements.md

# Use a specific AI model
qitops generate --test-type security --description "Test for SQL injection vulnerabilities" --output tests/configs/sql_injection_test.json --model mistral

# Use a custom model
qitops analyze --results results/security_test_result.json --output analysis.md --model custom --model-path /path/to/custom/model.gguf

# Use Ollama for local LLM inference
qitops generate --test-type api --description "Test the Twitter API" --output twitter_test.json --model custom --model-path "ollama:phi"
</code></pre>
<h3 id="testing-ai-features"><a class="header" href="#testing-ai-features">Testing AI Features</a></h3>
<pre><code class="language-bash"># Run the test script to verify AI features
./test_ai_features.sh

# Test with a real local LLM using Ollama
# 1. Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Pull a model
ollama pull phi

# 3. Test with Ollama
cargo run --features ai -- generate --test-type api --description "Test description" --model custom --model-path "ollama:phi"

# For more detailed instructions, see docs/testing-ai-features.md
</code></pre>
<h2 id="command-line-options"><a class="header" href="#command-line-options">Command Line Options</a></h2>
<h3 id="global-options"><a class="header" href="#global-options">Global Options</a></h3>
<ul>
<li><code>-r, --report</code>: Generate report in specified format (json, xml, html, csv)</li>
<li><code>-o, --output</code>: Output path for the report</li>
<li><code>--ci-mode</code>: Run in CI mode (reduced output, exit code based on test results)</li>
</ul>
<h3 id="api-testing-2"><a class="header" href="#api-testing-2">API Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
</ul>
<h3 id="api-collections-2"><a class="header" href="#api-collections-2">API Collections</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the collection configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-f, --format</code>: Output format (human, json) (default: “human”)</li>
</ul>
<h3 id="performance-testing-2"><a class="header" href="#performance-testing-2">Performance Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-u, --users</code>: Number of concurrent users (default: 10)</li>
<li><code>-d, --duration</code>: Test duration in seconds (default: 60)</li>
</ul>
<h3 id="enhanced-performance-testing-2"><a class="header" href="#enhanced-performance-testing-2">Enhanced Performance Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
</ul>
<h3 id="data-driven-testing-2"><a class="header" href="#data-driven-testing-2">Data-Driven Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-d, --data</code>: Path to the data source file (CSV or JSON)</li>
<li><code>-t, --data-type</code>: Data source type (csv, json) (default: “csv”)</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-m, --max-iterations</code>: Maximum number of iterations to run</li>
<li><code>-s, --stop-on-failure</code>: Stop on first failure</li>
</ul>
<h3 id="security-testing-2"><a class="header" href="#security-testing-2">Security Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-d, --depth</code>: Scan depth (1-5, default: 3)
<ul>
<li>Level 1: Basic security checks (headers, SSL)</li>
<li>Level 2: Common vulnerabilities</li>
<li>Level 3: Authentication and authorization</li>
<li>Level 4: Advanced vulnerability scanning</li>
<li>Level 5: Comprehensive security audit</li>
</ul>
</li>
<li><code>-p, --passive</code>: Include passive scanning</li>
</ul>
<h3 id="web-testing-2"><a class="header" href="#web-testing-2">Web Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-h, --headless</code>: Run in headless mode (default: true)</li>
<li><code>-s, --screenshot_dir</code>: Directory to save screenshots</li>
</ul>
<h3 id="ai-test-generation"><a class="header" href="#ai-test-generation">AI Test Generation</a></h3>
<ul>
<li><code>-t, --test_type</code>: Type of test to generate (api, performance, security, web)</li>
<li><code>-d, --description</code>: Description of the test to generate</li>
<li><code>-o, --output</code>: Output file path for the generated configuration</li>
<li><code>-m, --model</code>: AI model to use (llama, mistral, gptj, phi, custom)</li>
<li><code>-p, --model_path</code>: Path to model weights (required for custom models)</li>
</ul>
<h3 id="ai-test-analysis"><a class="header" href="#ai-test-analysis">AI Test Analysis</a></h3>
<ul>
<li><code>-r, --results</code>: Path to test results file(s)</li>
<li><code>-o, --output</code>: Output file path for the analysis</li>
<li><code>-m, --model</code>: AI model to use (llama, mistral, gptj, phi, custom)</li>
<li><code>-p, --model_path</code>: Path to model weights (required for custom models)</li>
</ul>
<h3 id="ai-improvement-suggestions"><a class="header" href="#ai-improvement-suggestions">AI Improvement Suggestions</a></h3>
<ul>
<li><code>-r, --results</code>: Path to test results file(s)</li>
<li><code>-o, --output</code>: Output file path for the suggestions</li>
<li><code>-m, --model</code>: AI model to use (llama, mistral, gptj, phi, custom)</li>
<li><code>-p, --model_path</code>: Path to model weights (required for custom models)</li>
</ul>
<h2 id="test-results"><a class="header" href="#test-results">Test Results</a></h2>
<h3 id="api-test-results"><a class="header" href="#api-test-results">API Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Response details:
<ul>
<li>Status code</li>
<li>Response time</li>
<li>Headers</li>
<li>Retry attempts (if any)</li>
</ul>
</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="api-collection-results"><a class="header" href="#api-collection-results">API Collection Results</a></h3>
<ul>
<li>Collection name and status</li>
<li>Overall duration</li>
<li>Individual request results:
<ul>
<li>Request name</li>
<li>Status</li>
<li>Duration</li>
<li>Response details</li>
</ul>
</li>
<li>Captured variables</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="performance-test-results"><a class="header" href="#performance-test-results">Performance Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Performance metrics:
<ul>
<li>Total requests</li>
<li>Success/error counts</li>
<li>Success rate</li>
<li>Average response time</li>
<li>Minimum response time</li>
<li>Maximum response time</li>
</ul>
</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="enhanced-performance-test-results"><a class="header" href="#enhanced-performance-test-results">Enhanced Performance Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Detailed metrics:
<ul>
<li>Total requests</li>
<li>Success/error counts</li>
<li>Success rate</li>
<li>Response time statistics (avg, min, max)</li>
<li>Percentile measurements (p50, p90, p95, p99)</li>
</ul>
</li>
<li>Scenario-specific metrics:
<ul>
<li>Per-scenario success rates</li>
<li>Per-scenario request counts</li>
</ul>
</li>
<li>Threshold evaluations:
<ul>
<li>Metric name</li>
<li>Expression</li>
<li>Pass/fail status</li>
</ul>
</li>
<li>Tagged metrics for detailed analysis</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="security-test-results"><a class="header" href="#security-test-results">Security Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Security findings:
<ul>
<li>Critical findings</li>
<li>High severity findings</li>
<li>Medium severity findings</li>
<li>Low severity findings</li>
<li>Total findings</li>
</ul>
</li>
<li>Detailed findings with:
<ul>
<li>Severity level</li>
<li>Category</li>
<li>Description</li>
<li>Recommendation</li>
</ul>
</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="web-test-results"><a class="header" href="#web-test-results">Web Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Page information:
<ul>
<li>Page title</li>
<li>Status code</li>
<li>Content length</li>
</ul>
</li>
<li>Assertion results:
<ul>
<li>Type (title, url, element, text)</li>
<li>Pass/fail status</li>
<li>Details</li>
</ul>
</li>
<li>Action results:
<ul>
<li>Type (click, type, wait, navigate)</li>
<li>Success status</li>
<li>Details</li>
</ul>
</li>
<li>Screenshot path (if enabled)</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="api-testing-3"><a class="header" href="#api-testing-3">API Testing</a></h3>
<ul>
<li>Use environment-specific configurations for different deployment stages</li>
<li>Set appropriate timeouts based on your API’s expected response times</li>
<li>Configure retry mechanisms for transient failures</li>
<li>Validate both success and error responses</li>
<li>Use JSON Schema validation for complex response structures</li>
<li>Monitor response times to catch performance degradation</li>
</ul>
<h3 id="api-collections-3"><a class="header" href="#api-collections-3">API Collections</a></h3>
<ul>
<li>Organize related requests into logical collections</li>
<li>Use meaningful request IDs for better readability and dependencies</li>
<li>Leverage JSONPath for precise data extraction from responses</li>
<li>Use variable capture and reuse for efficient testing</li>
<li>Define environment-specific variables for different deployment stages</li>
<li>Use sequential execution for dependent requests</li>
<li>Set appropriate delays between requests to avoid rate limiting</li>
<li>Define shared authentication at the collection level</li>
<li>Use defaults for common configuration across requests</li>
<li>Structure collections to follow user journeys or business processes</li>
<li>Use request dependencies to ensure proper execution order</li>
<li>Keep collections focused on a specific testing goal</li>
</ul>
<h3 id="performance-testing-3"><a class="header" href="#performance-testing-3">Performance Testing</a></h3>
<ul>
<li>Start with a small number of concurrent users and gradually increase</li>
<li>Use appropriate ramp-up times to avoid overwhelming the system</li>
<li>Set realistic success thresholds based on your requirements</li>
<li>Monitor system resources during tests</li>
<li>Run tests in a controlled environment</li>
<li>Consider network latency in your test environment</li>
</ul>
<h3 id="enhanced-performance-testing-3"><a class="header" href="#enhanced-performance-testing-3">Enhanced Performance Testing</a></h3>
<ul>
<li>Design multi-stage tests to simulate realistic user behavior</li>
<li>Use different load profiles for different testing scenarios</li>
<li>Define multiple scenarios to test different API endpoints</li>
<li>Use weighted scenarios to simulate real-world usage patterns</li>
<li>Set appropriate thresholds based on SLAs and performance requirements</li>
<li>Use tags to categorize and analyze metrics</li>
<li>Monitor real-time metrics during test execution</li>
<li>Analyze percentile measurements for a better understanding of performance</li>
<li>Use custom thresholds to catch performance regressions early</li>
<li>Run tests in different environments to compare performance</li>
</ul>
<h3 id="data-driven-testing-3"><a class="header" href="#data-driven-testing-3">Data-Driven Testing</a></h3>
<ul>
<li>Organize test data in CSV or JSON format based on complexity</li>
<li>Use CSV for simple tabular data with a consistent structure</li>
<li>Use JSON for complex nested data structures</li>
<li>Include a header row in CSV files for better readability</li>
<li>Use meaningful placeholder names that match data column names</li>
<li>Keep test configurations generic with placeholders</li>
<li>Use stop-on-failure for dependent test iterations</li>
<li>Set appropriate max iterations for large datasets</li>
<li>Validate data files before running tests</li>
<li>Use environment-specific configurations with data-driven tests</li>
<li>Combine data-driven testing with API collections for complex workflows</li>
</ul>
<h3 id="security-testing-3"><a class="header" href="#security-testing-3">Security Testing</a></h3>
<ul>
<li>Start with passive scanning before active scanning</li>
<li>Use appropriate scan depth based on your security requirements</li>
<li>Review and address high-severity findings immediately</li>
<li>Keep authentication tokens secure</li>
<li>Run security tests in a controlled environment</li>
<li>Regularly update security test configurations</li>
</ul>
<h3 id="web-testing-3"><a class="header" href="#web-testing-3">Web Testing</a></h3>
<ul>
<li>Use headless mode for CI/CD pipelines</li>
<li>Configure appropriate viewport sizes for different devices</li>
<li>Keep assertions focused and specific</li>
<li>Use explicit waits for dynamic content</li>
<li>Capture screenshots for visual verification</li>
<li>Test across different browsers in production</li>
<li>Organize tests by user journey or feature</li>
<li>Use custom user agents when needed</li>
</ul>
<h3 id="ai-powered-testing"><a class="header" href="#ai-powered-testing">AI-Powered Testing</a></h3>
<ul>
<li>Use specific, detailed descriptions when generating tests</li>
<li>Review and refine AI-generated test configurations before use</li>
<li>Provide context in your descriptions (e.g., authentication requirements)</li>
<li>Use lower temperature values (0.1-0.3) for more deterministic outputs</li>
<li>Use higher temperature values (0.7-0.9) for more creative test scenarios</li>
<li>Analyze test results regularly to identify patterns and issues</li>
<li>Combine AI suggestions with human expertise for best results</li>
<li>Keep model weights updated for best performance</li>
</ul>
<h3 id="cicd-integration-1"><a class="header" href="#cicd-integration-1">CI/CD Integration</a></h3>
<ul>
<li>Use <code>--ci-mode</code> for reduced output and exit codes in CI pipelines</li>
<li>Generate JSON reports for machine-readable results</li>
<li>Use GitHub Actions templates for quick setup</li>
<li>Run different test types in parallel for faster feedback</li>
<li>Set up scheduled runs for regular testing</li>
<li>Use environment-specific configurations for different stages</li>
<li>Store test results as artifacts for historical analysis</li>
<li>Set appropriate timeouts for CI environments</li>
<li>Use exit codes to gate deployments</li>
<li>Integrate with notification systems for test failures</li>
</ul>
<h2 id="configuration-reference"><a class="header" href="#configuration-reference">Configuration Reference</a></h2>
<h3 id="api-test-configuration-1"><a class="header" href="#api-test-configuration-1">API Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>method</td><td>string</td><td>HTTP method</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>expected_status</td><td>number</td><td>Expected HTTP status code</td><td>Optional</td></tr>
<tr><td>expected_body</td><td>object</td><td>Expected response body</td><td>Optional</td></tr>
<tr><td>max_response_time</td><td>number</td><td>Maximum allowed response time in seconds</td><td>Optional</td></tr>
<tr><td>expected_headers</td><td>object</td><td>Expected response headers</td><td>Optional</td></tr>
<tr><td>retry</td><td>object</td><td>Retry configuration</td><td>See below</td></tr>
</tbody></table>
</div>
<h4 id="retry-configuration"><a class="header" href="#retry-configuration">Retry Configuration</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>max_retries</td><td>number</td><td>Maximum number of retry attempts</td><td>3</td></tr>
<tr><td>initial_delay_ms</td><td>number</td><td>Initial delay between retries in milliseconds</td><td>100</td></tr>
<tr><td>max_delay_ms</td><td>number</td><td>Maximum delay between retries in milliseconds</td><td>1000</td></tr>
<tr><td>retry_status_codes</td><td>array</td><td>HTTP status codes that trigger retries</td><td>[408, 429, 500, 502, 503, 504]</td></tr>
<tr><td>retry_on_timeout</td><td>boolean</td><td>Whether to retry on timeout</td><td>true</td></tr>
<tr><td>retry_on_connection_error</td><td>boolean</td><td>Whether to retry on connection errors</td><td>true</td></tr>
</tbody></table>
</div>
<h3 id="api-collection-configuration-1"><a class="header" href="#api-collection-configuration-1">API Collection Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Collection name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Collection description</td><td>Optional</td></tr>
<tr><td>version</td><td>string</td><td>Collection version</td><td>Optional</td></tr>
<tr><td>variables</td><td>object</td><td>Collection variables</td><td>Optional</td></tr>
<tr><td>auth</td><td>object</td><td>Collection authentication</td><td>Optional</td></tr>
<tr><td>defaults</td><td>object</td><td>Default request configuration</td><td>Optional</td></tr>
<tr><td>requests</td><td>array</td><td>Collection requests</td><td>Required</td></tr>
<tr><td>environments</td><td>object</td><td>Environment-specific variables</td><td>Optional</td></tr>
<tr><td>run_options</td><td>object</td><td>Run options</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="collection-auth"><a class="header" href="#collection-auth">Collection Auth</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>type</td><td>string</td><td>Authentication type (basic, bearer, api_key)</td><td>Required</td></tr>
<tr><td>username</td><td>string</td><td>Username for basic auth</td><td>Optional</td></tr>
<tr><td>password</td><td>string</td><td>Password for basic auth</td><td>Optional</td></tr>
<tr><td>token</td><td>string</td><td>Token for bearer auth</td><td>Optional</td></tr>
<tr><td>key_name</td><td>string</td><td>Key name for API key auth</td><td>Optional</td></tr>
<tr><td>key_value</td><td>string</td><td>Key value for API key auth</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="collection-defaults"><a class="header" href="#collection-defaults">Collection Defaults</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>headers</td><td>object</td><td>Default headers for all requests</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Default timeout in seconds</td><td>Optional</td></tr>
<tr><td>retries</td><td>number</td><td>Default number of retries</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="collection-request"><a class="header" href="#collection-request">Collection Request</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Request name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Request description</td><td>Optional</td></tr>
<tr><td>id</td><td>string</td><td>Request ID (used for dependencies)</td><td>Optional</td></tr>
<tr><td>url</td><td>string</td><td>Request URL</td><td>Required</td></tr>
<tr><td>method</td><td>string</td><td>HTTP method</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>body</td><td>object</td><td>Request body</td><td>Optional</td></tr>
<tr><td>expected_status</td><td>number</td><td>Expected HTTP status code</td><td>Optional</td></tr>
<tr><td>expected_body</td><td>object</td><td>Expected response body</td><td>Optional</td></tr>
<tr><td>expected_body_type</td><td>string</td><td>Expected response body type</td><td>Optional</td></tr>
<tr><td>depends_on</td><td>array</td><td>Request dependencies</td><td>Optional</td></tr>
<tr><td>capture</td><td>object</td><td>Variables to capture from response</td><td>Optional</td></tr>
</tbody></table>
</div>
<h3 id="data-driven-testing-configuration"><a class="header" href="#data-driven-testing-configuration">Data-Driven Testing Configuration</a></h3>
<h4 id="csv-data-file"><a class="header" href="#csv-data-file">CSV Data File</a></h4>
<pre><code class="language-csv">username,email,user_id,role
johndoe,john.doe@example.com,1001,admin
janedoe,jane.doe@example.com,1002,user
bobsmith,bob.smith@example.com,1003,user
</code></pre>
<h4 id="json-data-file"><a class="header" href="#json-data-file">JSON Data File</a></h4>
<pre><code class="language-json">[
  {
    "product_id": "P001",
    "name": "Smartphone",
    "price": 599.99,
    "category": "Electronics",
    "in_stock": true
  },
  {
    "product_id": "P002",
    "name": "Laptop",
    "price": 1299.99,
    "category": "Electronics",
    "in_stock": true
  }
]
</code></pre>
<h4 id="test-configuration-with-placeholders"><a class="header" href="#test-configuration-with-placeholders">Test Configuration with Placeholders</a></h4>
<pre><code class="language-json">{
  "name": "User API Test for {{username}}",
  "description": "Test the user API for {{username}}",
  "url": "https://api.example.com/users/{{user_id}}",
  "method": "GET",
  "headers": {
    "Accept": "application/json",
    "X-User-Email": "{{email}}"
  },
  "expected_status": 200,
  "expected_body": {
    "id": "{{user_id}}",
    "role": "{{role}}"
  }
}
</code></pre>
<h4 id="run-options"><a class="header" href="#run-options">Run Options</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>sequential</td><td>boolean</td><td>Run requests sequentially</td><td>true</td></tr>
<tr><td>stop_on_failure</td><td>boolean</td><td>Stop on first failure</td><td>true</td></tr>
<tr><td>delay_between_requests_ms</td><td>number</td><td>Delay between requests in milliseconds</td><td>0</td></tr>
</tbody></table>
</div>
<h3 id="performance-test-configuration-1"><a class="header" href="#performance-test-configuration-1">Performance Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>target_url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>method</td><td>string</td><td>HTTP method</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>success_threshold</td><td>number</td><td>Minimum success rate percentage</td><td>95.0</td></tr>
<tr><td>ramp_up_time_secs</td><td>number</td><td>Time to ramp up to full load in seconds</td><td>5</td></tr>
</tbody></table>
</div>
<h3 id="security-test-configuration-1"><a class="header" href="#security-test-configuration-1">Security Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>target_url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>auth</td><td>object</td><td>Authentication configuration</td><td>Optional</td></tr>
<tr><td>scan_types</td><td>array</td><td>Types of security scans to perform</td><td>[“headers”, “ssl”, “vulnerabilities”, “sensitive-data”]</td></tr>
<tr><td>max_high_severity_findings</td><td>number</td><td>Maximum allowed high severity findings</td><td>0</td></tr>
</tbody></table>
</div>
<h3 id="web-test-configuration-1"><a class="header" href="#web-test-configuration-1">Web Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>target_url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>viewport</td><td>object</td><td>Browser viewport configuration</td><td>Optional</td></tr>
<tr><td>wait_for_selector</td><td>string</td><td>Selector to wait for before starting test</td><td>Optional</td></tr>
<tr><td>wait_timeout_secs</td><td>number</td><td>Timeout for waiting for selector</td><td>30</td></tr>
<tr><td>screenshots</td><td>boolean</td><td>Whether to capture screenshots</td><td>false</td></tr>
<tr><td>user_agent</td><td>string</td><td>Custom user agent string</td><td>“QitOps-WebTester/1.0”</td></tr>
<tr><td>assertions</td><td>array</td><td>List of assertions to perform</td><td>Optional</td></tr>
<tr><td>actions</td><td>array</td><td>List of actions to perform</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="viewport-configuration"><a class="header" href="#viewport-configuration">Viewport Configuration</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>width</td><td>number</td><td>Viewport width in pixels</td><td>Required</td></tr>
<tr><td>height</td><td>number</td><td>Viewport height in pixels</td><td>Required</td></tr>
<tr><td>device_scale_factor</td><td>number</td><td>Device scale factor</td><td>1.0</td></tr>
<tr><td>is_mobile</td><td>boolean</td><td>Whether to emulate a mobile device</td><td>false</td></tr>
</tbody></table>
</div>
<h4 id="web-assertion"><a class="header" href="#web-assertion">Web Assertion</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>assertion_type</td><td>string</td><td>Type of assertion (title, url, element, text, attribute)</td><td>Required</td></tr>
<tr><td>selector</td><td>string</td><td>CSS selector for element assertions</td><td>Optional</td></tr>
<tr><td>attribute</td><td>string</td><td>Attribute name for attribute assertions</td><td>Optional</td></tr>
<tr><td>expected_value</td><td>string</td><td>Expected value to compare against</td><td>Required</td></tr>
<tr><td>comparison</td><td>string</td><td>Comparison type (equals, contains, startsWith, endsWith, matches)</td><td>“equals”</td></tr>
</tbody></table>
</div>
<h4 id="web-action"><a class="header" href="#web-action">Web Action</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>action_type</td><td>string</td><td>Type of action (click, type, wait, navigate)</td><td>Required</td></tr>
<tr><td>selector</td><td>string</td><td>CSS selector for element actions</td><td>Optional</td></tr>
<tr><td>value</td><td>string</td><td>Value for type actions or URL for navigate actions</td><td>Optional</td></tr>
<tr><td>wait_time_ms</td><td>number</td><td>Wait time in milliseconds for wait actions</td><td>1000</td></tr>
</tbody></table>
</div>
<h3 id="ai-configuration-1"><a class="header" href="#ai-configuration-1">AI Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>model_type</td><td>string</td><td>Type of AI model (llama, mistral, gptj, phi, custom)</td><td>Required</td></tr>
<tr><td>model_path</td><td>string</td><td>Path to the model weights</td><td>Optional</td></tr>
<tr><td>context_size</td><td>number</td><td>Context window size</td><td>2048</td></tr>
<tr><td>temperature</td><td>number</td><td>Temperature for generation (0.0-1.0)</td><td>0.7</td></tr>
<tr><td>max_tokens</td><td>number</td><td>Maximum tokens to generate</td><td>1024</td></tr>
<tr><td>system_prompt</td><td>string</td><td>System prompt to use</td><td>Optional</td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h3>
<h4 id="api-testing-4"><a class="header" href="#api-testing-4">API Testing</a></h4>
<ul>
<li><strong>Timeout Errors</strong>: Increase the timeout value in your configuration</li>
<li><strong>Connection Errors</strong>: Check network connectivity and retry settings</li>
<li><strong>Validation Failures</strong>: Verify expected response format and values</li>
<li><strong>Retry Loop</strong>: Check retry configuration and target system status</li>
</ul>
<h4 id="api-collections-4"><a class="header" href="#api-collections-4">API Collections</a></h4>
<ul>
<li><strong>Dependency Errors</strong>: Ensure dependent requests are correctly defined and executed</li>
<li><strong>Variable Capture Failures</strong>: Check JSONPath expressions and response structure</li>
<li><strong>Variable Interpolation Issues</strong>: Verify variable names and syntax ({{variable}})</li>
<li><strong>Authentication Failures</strong>: Check auth configuration and token validity</li>
<li><strong>Sequential Execution Problems</strong>: Verify run_options and dependencies</li>
<li><strong>JSONPath Errors</strong>: Validate JSONPath expressions against actual response structure</li>
<li><strong>Missing Variables</strong>: Ensure all referenced variables are defined or captured</li>
<li><strong>Request Chaining Issues</strong>: Check that dependent requests are capturing the expected data</li>
<li><strong>Environment Configuration</strong>: Verify environment-specific variables are correctly set</li>
</ul>
<h4 id="performance-testing-4"><a class="header" href="#performance-testing-4">Performance Testing</a></h4>
<ul>
<li><strong>High Error Rate</strong>: Reduce concurrent users or increase ramp-up time</li>
<li><strong>Slow Response Times</strong>: Check network latency and target system load</li>
<li><strong>Resource Exhaustion</strong>: Monitor system resources and adjust test parameters</li>
<li><strong>Inconsistent Results</strong>: Ensure test environment stability</li>
</ul>
<h4 id="enhanced-performance-testing-4"><a class="header" href="#enhanced-performance-testing-4">Enhanced Performance Testing</a></h4>
<ul>
<li><strong>Stage Transition Issues</strong>: Check stage durations and target values</li>
<li><strong>Threshold Failures</strong>: Verify threshold expressions and metric names</li>
<li><strong>Scenario Distribution Problems</strong>: Check scenario weights and total count</li>
<li><strong>Metric Collection Issues</strong>: Ensure metrics are being properly captured</li>
<li><strong>High Resource Usage</strong>: Reduce the number of concurrent VUs or increase stage duration</li>
<li><strong>Percentile Calculation Errors</strong>: Ensure enough samples for accurate percentiles</li>
<li><strong>Tagged Metrics Missing</strong>: Verify tag names and values in scenario configuration</li>
</ul>
<h4 id="cicd-integration-2"><a class="header" href="#cicd-integration-2">CI/CD Integration</a></h4>
<ul>
<li><strong>Exit Code Issues</strong>: Ensure test status is correctly reported</li>
<li><strong>GitHub Actions Failures</strong>: Check workflow YAML syntax and permissions</li>
<li><strong>Report Generation Failures</strong>: Verify output directory exists and is writable</li>
<li><strong>Parallel Test Conflicts</strong>: Ensure tests don’t interfere with each other</li>
<li><strong>Timeout Errors</strong>: Increase CI job timeout or reduce test duration</li>
<li><strong>Environment Variable Issues</strong>: Check environment variable configuration</li>
<li><strong>Artifact Storage Problems</strong>: Verify artifact paths and retention settings</li>
</ul>
<h4 id="data-driven-testing-4"><a class="header" href="#data-driven-testing-4">Data-Driven Testing</a></h4>
<ul>
<li><strong>CSV Parsing Errors</strong>: Check CSV format and delimiter settings</li>
<li><strong>JSON Parsing Errors</strong>: Validate JSON syntax and structure</li>
<li><strong>Placeholder Not Found</strong>: Ensure placeholder names match data column names</li>
<li><strong>Missing Data Columns</strong>: Verify data file contains all required columns</li>
<li><strong>Iteration Failures</strong>: Check if stop-on-failure is appropriate for your test</li>
<li><strong>Performance Issues</strong>: Reduce max iterations for large datasets</li>
<li><strong>File Not Found Errors</strong>: Verify data file paths</li>
<li><strong>JSON Path Errors</strong>: Check JSON path syntax for complex data structures</li>
<li><strong>Type Conversion Issues</strong>: Ensure data types match expected values</li>
<li><strong>Empty Data Sets</strong>: Verify data files contain valid test data</li>
</ul>
<h4 id="security-testing-4"><a class="header" href="#security-testing-4">Security Testing</a></h4>
<ul>
<li><strong>False Positives</strong>: Review and adjust scan depth and types</li>
<li><strong>Authentication Failures</strong>: Verify auth configuration</li>
<li><strong>Scan Timeouts</strong>: Adjust timeout settings for complex scans</li>
<li><strong>Missing Findings</strong>: Check scan depth and types configuration</li>
</ul>
<h4 id="web-testing-4"><a class="header" href="#web-testing-4">Web Testing</a></h4>
<ul>
<li><strong>Element Not Found</strong>: Check selectors and wait conditions</li>
<li><strong>Timeout Errors</strong>: Increase wait timeout for dynamic content</li>
<li><strong>Screenshot Issues</strong>: Verify screenshot directory permissions</li>
<li><strong>Assertion Failures</strong>: Check expected values and comparison types</li>
<li><strong>Action Failures</strong>: Verify element visibility and interactability</li>
</ul>
<h4 id="ai-features"><a class="header" href="#ai-features">AI Features</a></h4>
<ul>
<li><strong>Model Loading Errors</strong>: Verify model path and format compatibility</li>
<li><strong>Out of Memory</strong>: Reduce context size or use a smaller model</li>
<li><strong>Poor Quality Output</strong>: Adjust temperature or provide more detailed prompts</li>
<li><strong>Slow Generation</strong>: Use a smaller model or reduce max tokens</li>
<li><strong>Missing Dependencies</strong>: Install AI dependencies with <code>cargo build --features ai</code></li>
</ul>
<h2 id="development"><a class="header" href="#development">Development</a></h2>
<h3 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h3>
<ul>
<li>Rust 1.70 or higher</li>
<li>Cargo</li>
<li>Git</li>
</ul>
<h3 id="constraints"><a class="header" href="#constraints">Constraints</a></h3>
<p>QitOps is designed with the following constraints in mind:</p>
<ul>
<li><strong>Minimal dependencies</strong>: Uses only the Rust standard library and well-known crates</li>
<li><strong>Static binary compilation</strong>: Can be compiled to a static binary for Linux</li>
<li><strong>CLI-only interface</strong>: All functionality is accessible via CLI flags with no UI dependencies</li>
<li><strong>Terminal-friendly output</strong>: Human-readable output for direct terminal use</li>
<li><strong>Machine-readable formats</strong>: Structured output for CI/CD integration</li>
</ul>
<h3 id="building-from-source"><a class="header" href="#building-from-source">Building from Source</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/yourusername/qitops.git
cd qitops

# Build the project
cargo build

# Run tests
cargo test

# Build documentation
cargo doc --no-deps

# Build static binary for Linux
cargo build --release --target x86_64-unknown-linux-musl
</code></pre>
<h3 id="architecture--project-structure"><a class="header" href="#architecture--project-structure">Architecture &amp; Project Structure</a></h3>
<p>QitOps follows a modular architecture with clear boundaries between components:</p>
<pre><code>qitops/
├── src/
│   ├── main.rs        # CLI parsing using clap
│   ├── api.rs         # API testing implementation
│   ├── performance.rs # Performance testing implementation
│   ├── security.rs    # Security testing implementation
│   ├── web.rs         # Web testing implementation (extension)
│   ├── ai.rs          # AI-powered test generation (extension)
│   ├── reporting.rs   # Report generation (extension)
│   ├── common.rs      # Shared functionality and interfaces
│   └── error.rs       # Error handling
├── tests/
│   └── configs/       # JSON test configuration files
│       ├── api_test.json
│       ├── performance_test.json
│       ├── security_test.json
│       ├── web_test.json
│       └── ai_config.json
├── .github/
│   └── workflows/     # CI configuration
├── Dockerfile         # Container definition
├── docker-compose.yml # Container orchestration
└── Cargo.toml         # Dependencies (minimal and native)
</code></pre>
<p>The architecture is designed with the following principles:</p>
<ul>
<li><strong>Clear module boundaries</strong>: Each testing type has its own module</li>
<li><strong>Common interfaces</strong>: All test runners implement the <code>TestRunner</code> trait</li>
<li><strong>JSON-based configuration</strong>: Tests are defined using structured JSON files</li>
<li><strong>Minimal dependencies</strong>: Uses Rust standard library and well-known crates</li>
<li><strong>CLI-first approach</strong>: All functionality accessible via command-line flags</li>
<li><strong>Extensibility</strong>: Designed for future expansion (TUI, AI integration)</li>
</ul>
<h3 id="cicd-integration-3"><a class="header" href="#cicd-integration-3">CI/CD Integration</a></h3>
<p>QitOps is designed to be CI/CD ready and can be easily integrated into your CI/CD pipeline:</p>
<h4 id="github-actions"><a class="header" href="#github-actions">GitHub Actions</a></h4>
<p>The included GitHub Actions workflow (<code>ci.yml</code>) automatically:</p>
<ul>
<li>Builds and tests the project</li>
<li>Runs linting and formatting checks</li>
<li>Executes sample tests for each test type</li>
<li>Creates release artifacts</li>
</ul>
<h4 id="docker-integration"><a class="header" href="#docker-integration">Docker Integration</a></h4>
<p>The included Dockerfile and docker-compose.yml allow you to:</p>
<ul>
<li>Build a containerized version of QitOps</li>
<li>Run tests in isolated containers</li>
<li>Mount configuration and result volumes</li>
<li>Set environment variables for different environments</li>
</ul>
<h4 id="junit-xml-reports"><a class="header" href="#junit-xml-reports">JUnit XML Reports</a></h4>
<p>Generate JUnit XML reports for integration with CI/CD tools:</p>
<pre><code class="language-bash">qitops -r xml -o test-results.xml api -c tests/configs/api_test.json
</code></pre>
<p>Most CI/CD platforms (Jenkins, GitHub Actions, GitLab CI, etc.) can automatically parse these reports to display test results.</p>
<h3 id="adding-new-features"><a class="header" href="#adding-new-features">Adding New Features</a></h3>
<ol>
<li>Create a new module in <code>src/</code></li>
<li>Implement the <code>TestRunner</code> trait</li>
<li>Add CLI commands in <code>main.rs</code></li>
<li>Add configuration structures</li>
<li>Write tests</li>
<li>Update documentation</li>
</ol>
<h2 id="qitops-os-integration"><a class="header" href="#qitops-os-integration">QitOps OS Integration</a></h2>
<p>QitOps CLI is designed to be bundled into QitOps OS, a custom bootable Linux distribution for QA professionals. When integrated into QitOps OS, the tool will be:</p>
<ul>
<li>Pre-installed in <code>/usr/local/bin</code> as a static binary</li>
<li>Configured with default test configurations in <code>/etc/qitops/configs</code></li>
<li>Available directly from the terminal without additional setup</li>
<li>Optimized for the QitOps OS environment</li>
</ul>
<p>QA professionals can boot directly into QitOps OS and run tests from the terminal without any additional installation or configuration steps.</p>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.</p>
<p>When contributing, please keep in mind the core principles of the project:</p>
<ul>
<li>Maintain CLI-first approach with no UI dependencies</li>
<li>Keep dependencies minimal and native</li>
<li>Ensure compatibility with static binary compilation</li>
<li>Preserve clear module boundaries</li>
<li>Design for extensibility</li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="why-qitops"><a class="header" href="#why-qitops">Why QitOps?</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation-1"><a class="header" href="#installation-1">Installation</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="features-1"><a class="header" href="#features-1">Features</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-testing-5"><a class="header" href="#api-testing-5">API Testing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-collections-5"><a class="header" href="#api-collections-5">API Collections</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-testing-5"><a class="header" href="#performance-testing-5">Performance Testing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="security-testing-5"><a class="header" href="#security-testing-5">Security Testing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="web-testing-5"><a class="header" href="#web-testing-5">Web Testing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ai-features-1"><a class="header" href="#ai-features-1">AI Features</a></h1>
<p>QitOps includes powerful AI features that can help you generate test configurations, analyze test results, and suggest improvements to your tests. These features are designed to work completely offline with local LLM models, ensuring your data never leaves your machine.</p>
<h2 id="installation-2"><a class="header" href="#installation-2">Installation</a></h2>
<p>To use the AI features, you need to install QitOps with the <code>ai</code> feature flag:</p>
<pre><code class="language-bash"># Install from crates.io with AI features
cargo install qitops --features ai

# Or build from source with AI features
cargo build --features ai
</code></pre>
<h2 id="supported-llm-models"><a class="header" href="#supported-llm-models">Supported LLM Models</a></h2>
<p>QitOps supports a variety of local LLM models:</p>
<ul>
<li><strong>LLaMA</strong>: Versions 1, 2, and 3</li>
<li><strong>Mistral</strong>: 7B and 8x7B models</li>
<li><strong>GPT-J</strong>: All versions</li>
<li><strong>Phi</strong>: Versions 1, 2, and 3</li>
<li><strong>Any GGUF-compatible model</strong>: Models in GGUF format</li>
</ul>
<h2 id="local-llm-integration-options"><a class="header" href="#local-llm-integration-options">Local LLM Integration Options</a></h2>
<p>QitOps provides several ways to integrate with local LLMs:</p>
<h3 id="1-direct-model-loading"><a class="header" href="#1-direct-model-loading">1. Direct Model Loading</a></h3>
<p>Load models directly from local files:</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --model llama --model-path /path/to/model.gguf
</code></pre>
<h3 id="2-ollama-integration"><a class="header" href="#2-ollama-integration">2. Ollama Integration</a></h3>
<p>Connect to Ollama for local model inference:</p>
<pre><code class="language-bash"># Start Ollama server
ollama serve

# Pull a model
ollama pull llama2

# Use Ollama with QitOps
export QITOPS_OLLAMA_URL="http://localhost:11434"
qitops generate --test-type api --description "Test description" --model ollama:llama2
</code></pre>
<h3 id="3-custom-model-path"><a class="header" href="#3-custom-model-path">3. Custom Model Path</a></h3>
<p>Specify a custom path to your model files:</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --model custom --model-path /path/to/custom/model.gguf
</code></pre>
<h2 id="offline-operation"><a class="header" href="#offline-operation">Offline Operation</a></h2>
<p>QitOps AI features can work completely offline:</p>
<pre><code class="language-bash"># Set environment variables for offline mode
export QITOPS_OFFLINE=true
export QITOPS_MODEL_PATH="/path/to/model.gguf"

# Run AI features offline
qitops analyze --results test_results.json --output analysis.md
</code></pre>
<h2 id="ai-features-2"><a class="header" href="#ai-features-2">AI Features</a></h2>
<h3 id="test-configuration-generation"><a class="header" href="#test-configuration-generation">Test Configuration Generation</a></h3>
<p>Generate test configurations from natural language descriptions:</p>
<pre><code class="language-bash"># Generate an API test configuration
qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output github_test.json

# Generate a performance test configuration
qitops generate --test-type performance --description "Load test for an e-commerce checkout API with 100 concurrent users" --output perf_test.json

# Generate a security test configuration
qitops generate --test-type security --description "Security scan for a banking API" --output security_test.json

# Generate a web test configuration
qitops generate --test-type web --description "Test the checkout flow of an e-commerce website" --output web_test.json
</code></pre>
<h3 id="test-results-analysis"><a class="header" href="#test-results-analysis">Test Results Analysis</a></h3>
<p>Analyze test results to identify patterns and issues:</p>
<pre><code class="language-bash"># Analyze test results
qitops analyze --results test_results.json --output analysis.md

# Analyze with a specific model
qitops analyze --results test_results.json --output analysis.md --model llama --model-path /path/to/model.gguf
</code></pre>
<p>The analysis includes:</p>
<ul>
<li>Overview of test results</li>
<li>Detailed breakdown of successes and failures</li>
<li>Performance metrics</li>
<li>Recommendations for improvement</li>
</ul>
<h3 id="improvement-suggestions"><a class="header" href="#improvement-suggestions">Improvement Suggestions</a></h3>
<p>Get actionable suggestions to improve your tests:</p>
<pre><code class="language-bash"># Generate improvement suggestions
qitops improve --results test_results.json --output improvements.md

# Generate suggestions with a specific model
qitops improve --results test_results.json --output improvements.md --model llama --model-path /path/to/model.gguf
</code></pre>
<p>Improvement suggestions cover:</p>
<ul>
<li>Performance optimizations</li>
<li>Reliability enhancements</li>
<li>Coverage improvements</li>
<li>Best practices</li>
</ul>
<h2 id="model-parameter-customization"><a class="header" href="#model-parameter-customization">Model Parameter Customization</a></h2>
<p>Customize model parameters to fine-tune the AI behavior:</p>
<pre><code class="language-bash"># Set temperature (controls randomness, 0.0-1.0)
qitops generate --test-type api --description "Test description" --temperature 0.7

# Set context size (in tokens)
qitops generate --test-type api --description "Test description" --context-size 4096

# Set maximum tokens for generation
qitops generate --test-type api --description "Test description" --max-tokens 2048

# Set system prompt
qitops generate --test-type api --description "Test description" --system-prompt "You are a testing expert."
</code></pre>
<h2 id="testing-ai-features-1"><a class="header" href="#testing-ai-features-1">Testing AI Features</a></h2>
<p>You can test the AI features using the provided test script:</p>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/qitops/qitops-cli-tools.git
cd qitops-cli-tools

# Build with AI features
cargo build --features ai

# Run the test script
./test_local_ai.sh
</code></pre>
<p>The test script will:</p>
<ol>
<li>Set up environment variables for offline mode</li>
<li>Create a directory for test outputs</li>
<li>Test all AI features (generation, analysis, improvement)</li>
<li>Show the generated files</li>
</ol>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="model-loading-issues"><a class="header" href="#model-loading-issues">Model Loading Issues</a></h3>
<p>If you encounter issues loading a model:</p>
<pre><code class="language-bash"># Check if the model file exists
ls -la /path/to/model.gguf

# Try a different model format
qitops generate --test-type api --description "Test description" --model llama --model-path /path/to/different/model.gguf
</code></pre>
<h3 id="ollama-connection-issues"><a class="header" href="#ollama-connection-issues">Ollama Connection Issues</a></h3>
<p>If you have trouble connecting to Ollama:</p>
<pre><code class="language-bash"># Check if Ollama is running
curl http://localhost:11434/api/version

# Check available models
ollama list

# Pull the model if it's not available
ollama pull llama2
</code></pre>
<h3 id="memory-issues"><a class="header" href="#memory-issues">Memory Issues</a></h3>
<p>If you encounter memory issues with large models:</p>
<pre><code class="language-bash"># Use a smaller model
qitops generate --test-type api --description "Test description" --model phi --model-path /path/to/phi-2.gguf

# Reduce context size
qitops generate --test-type api --description "Test description" --context-size 2048
</code></pre>
<h2 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h2>
<p>QitOps supports the following environment variables for AI features:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td><code>QITOPS_OFFLINE</code></td><td>Run in offline mode</td><td><code>false</code></td></tr>
<tr><td><code>QITOPS_MODEL_PATH</code></td><td>Path to the model file</td><td>None</td></tr>
<tr><td><code>QITOPS_OLLAMA_URL</code></td><td>URL for Ollama server</td><td><code>http://localhost:11434</code></td></tr>
<tr><td><code>QITOPS_TEMPERATURE</code></td><td>Temperature for generation</td><td><code>0.7</code></td></tr>
<tr><td><code>QITOPS_CONTEXT_SIZE</code></td><td>Context size in tokens</td><td><code>4096</code></td></tr>
<tr><td><code>QITOPS_MAX_TOKENS</code></td><td>Maximum tokens for generation</td><td><code>2048</code></td></tr>
<tr><td><code>QITOPS_SYSTEM_PROMPT</code></td><td>System prompt for the model</td><td>Default system prompt</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="test-generation"><a class="header" href="#test-generation">Test Generation</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="results-analysis"><a class="header" href="#results-analysis">Results Analysis</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="improvement-suggestions-1"><a class="header" href="#improvement-suggestions-1">Improvement Suggestions</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="local-llm-support"><a class="header" href="#local-llm-support">Local LLM Support</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-ai-features-2"><a class="header" href="#testing-ai-features-2">Testing AI Features</a></h1>
<p>This guide provides detailed instructions on how to test the AI features of QitOps locally. These features include test configuration generation, test results analysis, and improvement suggestions.</p>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<p>Before testing the AI features, make sure you have:</p>
<ol>
<li>
<p><strong>QitOps built with AI features</strong>:</p>
<pre><code class="language-bash">cargo build --features ai
</code></pre>
</li>
<li>
<p><strong>A local LLM setup</strong> (one of the following):</p>
<ul>
<li><strong>Ollama</strong>: For easy local LLM management</li>
<li><strong>Direct model files</strong>: GGUF format models</li>
<li><strong>Mock implementation</strong>: For testing without a real model</li>
</ul>
</li>
</ol>
<h2 id="option-1-testing-with-ollama"><a class="header" href="#option-1-testing-with-ollama">Option 1: Testing with Ollama</a></h2>
<p><a href="https://ollama.ai/">Ollama</a> provides an easy way to run local LLMs. It’s recommended for testing as it handles model management and provides a simple API.</p>
<h3 id="step-1-install-ollama"><a class="header" href="#step-1-install-ollama">Step 1: Install Ollama</a></h3>
<pre><code class="language-bash"># Linux
curl -fsSL https://ollama.ai/install.sh | sh

# macOS
brew install ollama

# Windows
# Download from https://ollama.ai/download
</code></pre>
<h3 id="step-2-start-ollama-server"><a class="header" href="#step-2-start-ollama-server">Step 2: Start Ollama Server</a></h3>
<pre><code class="language-bash">ollama serve
</code></pre>
<h3 id="step-3-pull-a-model"><a class="header" href="#step-3-pull-a-model">Step 3: Pull a Model</a></h3>
<p>Pull a small model for testing:</p>
<pre><code class="language-bash"># Pull a small model (recommended for testing)
ollama pull phi

# Or pull a larger model for better results
ollama pull llama2
</code></pre>
<h3 id="step-4-test-ai-features-with-ollama"><a class="header" href="#step-4-test-ai-features-with-ollama">Step 4: Test AI Features with Ollama</a></h3>
<pre><code class="language-bash"># Test configuration generation
cargo run --features ai -- generate --test-type api --description "Test the Twitter API to fetch user timeline" --output twitter_api_test.json --model ollama:phi

# Test results analysis
cargo run --features ai -- analyze --results sample_test_results.json --output test_analysis.md --model ollama:phi

# Test improvement suggestions
cargo run --features ai -- improve --results sample_test_results.json --output test_improvements.md --model ollama:phi
</code></pre>
<h2 id="option-2-testing-with-direct-model-files"><a class="header" href="#option-2-testing-with-direct-model-files">Option 2: Testing with Direct Model Files</a></h2>
<p>If you prefer to use model files directly, you can download GGUF format models and use them with QitOps.</p>
<h3 id="step-1-download-a-model"><a class="header" href="#step-1-download-a-model">Step 1: Download a Model</a></h3>
<p>Download a GGUF model from Hugging Face or other sources:</p>
<pre><code class="language-bash"># Create a models directory
mkdir -p models

# Download a model (example using wget)
wget https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf -O models/phi-2.gguf
</code></pre>
<h3 id="step-2-test-ai-features-with-direct-model-files"><a class="header" href="#step-2-test-ai-features-with-direct-model-files">Step 2: Test AI Features with Direct Model Files</a></h3>
<pre><code class="language-bash"># Test configuration generation
cargo run --features ai -- generate --test-type api --description "Test the Twitter API to fetch user timeline" --output twitter_api_test.json --model custom --model-path models/phi-2.gguf

# Test results analysis
cargo run --features ai -- analyze --results sample_test_results.json --output test_analysis.md --model custom --model-path models/phi-2.gguf

# Test improvement suggestions
cargo run --features ai -- improve --results sample_test_results.json --output test_improvements.md --model custom --model-path models/phi-2.gguf
</code></pre>
<h2 id="option-3-testing-with-mock-implementation"><a class="header" href="#option-3-testing-with-mock-implementation">Option 3: Testing with Mock Implementation</a></h2>
<p>For quick testing without a real model, you can use the built-in mock implementation.</p>
<h3 id="step-1-create-sample-test-results"><a class="header" href="#step-1-create-sample-test-results">Step 1: Create Sample Test Results</a></h3>
<p>Create a sample test results file for testing analysis and improvement features:</p>
<pre><code class="language-bash">cat &gt; sample_test_results.json &lt;&lt; EOF
[
  {
    "test_id": "api-test-1",
    "name": "GitHub User API Test",
    "description": "Test the GitHub API to fetch user information",
    "timestamp": "2025-05-10T21:15:00Z",
    "duration_ms": 190,
    "status": "success",
    "url": "https://api.github.com/users/octocat",
    "method": "GET",
    "request_headers": {
      "Accept": "application/vnd.github.v3+json",
      "User-Agent": "QitOps-Test"
    },
    "response_status": 200,
    "response_headers": {
      "content-type": "application/json; charset=utf-8",
      "cache-control": "public, max-age=60, s-maxage=60"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 200,
        "result": "pass"
      },
      {
        "type": "json",
        "path": "$.login",
        "expected": "octocat",
        "actual": "octocat",
        "result": "pass"
      }
    ]
  },
  {
    "test_id": "api-test-2",
    "name": "GitHub Non-existent User Test",
    "description": "Test the GitHub API with a non-existent user",
    "timestamp": "2025-05-10T21:15:02Z",
    "duration_ms": 180,
    "status": "failure",
    "url": "https://api.github.com/users/non-existent-user-12345",
    "method": "GET",
    "request_headers": {
      "Accept": "application/vnd.github.v3+json",
      "User-Agent": "QitOps-Test"
    },
    "response_status": 404,
    "response_headers": {
      "content-type": "application/json; charset=utf-8",
      "cache-control": "public, max-age=60, s-maxage=60"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 404,
        "result": "fail"
      }
    ],
    "error": "Expected status 200 but got 404"
  }
]
EOF
</code></pre>
<h3 id="step-2-test-ai-features-with-mock-implementation"><a class="header" href="#step-2-test-ai-features-with-mock-implementation">Step 2: Test AI Features with Mock Implementation</a></h3>
<pre><code class="language-bash"># Test configuration generation
cargo run --features ai -- generate --test-type api --description "Test the Twitter API to fetch user timeline" --output twitter_api_test.json

# Test results analysis
cargo run --features ai -- analyze --results sample_test_results.json --output test_analysis.md

# Test improvement suggestions
cargo run --features ai -- improve --results sample_test_results.json --output test_improvements.md
</code></pre>
<h2 id="automated-testing-script"><a class="header" href="#automated-testing-script">Automated Testing Script</a></h2>
<p>For convenience, you can use the provided test script to test all AI features at once:</p>
<pre><code class="language-bash"># Download the test script
curl -O https://raw.githubusercontent.com/qitops/qitops-cli-tools/master/test_local_ai.sh
chmod +x test_local_ai.sh

# Run the test script
./test_local_ai.sh
</code></pre>
<p>The test script will:</p>
<ol>
<li>Set up environment variables for offline mode</li>
<li>Create a directory for test outputs</li>
<li>Test all AI features (generation, analysis, improvement)</li>
<li>Show the generated files</li>
</ol>
<h2 id="verifying-test-results"><a class="header" href="#verifying-test-results">Verifying Test Results</a></h2>
<p>After running the tests, you should check the generated files:</p>
<pre><code class="language-bash"># Check the generated API test configuration
cat twitter_api_test.json

# Check the test analysis
cat test_analysis.md

# Check the improvement suggestions
cat test_improvements.md
</code></pre>
<p>The generated files should contain:</p>
<ol>
<li>
<p><strong>API Test Configuration</strong>:</p>
<ul>
<li>URL, method, headers, and assertions</li>
<li>Properly formatted JSON</li>
</ul>
</li>
<li>
<p><strong>Test Analysis</strong>:</p>
<ul>
<li>Overview of test results</li>
<li>Details about performance and status codes</li>
<li>Recommendations for improvement</li>
</ul>
</li>
<li>
<p><strong>Improvement Suggestions</strong>:</p>
<ul>
<li>Performance optimizations</li>
<li>Reliability enhancements</li>
<li>Coverage improvements</li>
</ul>
</li>
</ol>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="model-loading-issues-1"><a class="header" href="#model-loading-issues-1">Model Loading Issues</a></h3>
<p>If you encounter issues loading a model:</p>
<pre><code class="language-bash"># Check if the model file exists
ls -la models/phi-2.gguf

# Try with verbose logging
RUST_LOG=debug cargo run --features ai -- generate --test-type api --description "Test description" --model custom --model-path models/phi-2.gguf
</code></pre>
<h3 id="ollama-connection-issues-1"><a class="header" href="#ollama-connection-issues-1">Ollama Connection Issues</a></h3>
<p>If you have trouble connecting to Ollama:</p>
<pre><code class="language-bash"># Check if Ollama is running
curl http://localhost:11434/api/version

# Check available models
ollama list

# Pull the model if it's not available
ollama pull phi
</code></pre>
<h3 id="memory-issues-1"><a class="header" href="#memory-issues-1">Memory Issues</a></h3>
<p>If you encounter memory issues with large models:</p>
<pre><code class="language-bash"># Use a smaller model
ollama pull tinyllama
cargo run --features ai -- generate --test-type api --description "Test description" --model ollama:tinyllama

# Or reduce context size
cargo run --features ai -- generate --test-type api --description "Test description" --context-size 2048
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="usage-guide"><a class="header" href="#usage-guide">Usage Guide</a></h1>
<p>This page provides detailed information on using QitOps for different testing scenarios.</p>
<h2 id="command-line-interface"><a class="header" href="#command-line-interface">Command Line Interface</a></h2>
<p>QitOps provides a unified command-line interface for all testing types:</p>
<pre><code class="language-bash">qitops [global options] &lt;command&gt; [command options]
</code></pre>
<h3 id="global-options-1"><a class="header" href="#global-options-1">Global Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td>-r, –report <FORMAT></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td>-o, –output <FILE></td><td>Output file for the report</td></tr>
<tr><td>–ci-mode</td><td>Run in CI mode (reduced output, exit code based on test results)</td></tr>
<tr><td>-e, –environment <ENV></td><td>Environment to use (default: production)</td></tr>
<tr><td>-v, –verbose</td><td>Enable verbose output</td></tr>
<tr><td>-h, –help</td><td>Show help</td></tr>
<tr><td>-V, –version</td><td>Show version</td></tr>
</tbody></table>
</div>
<h3 id="commands"><a class="header" href="#commands">Commands</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Command</th><th>Description</th></tr></thead><tbody>
<tr><td>api</td><td>Run API tests</td></tr>
<tr><td>collection</td><td>Run API collection tests</td></tr>
<tr><td>performance</td><td>Run performance tests</td></tr>
<tr><td>security</td><td>Run security tests</td></tr>
<tr><td>web</td><td>Run web tests</td></tr>
<tr><td>data-driven</td><td>Run data-driven tests</td></tr>
<tr><td>generate</td><td>Generate test configurations using AI</td></tr>
<tr><td>analyze</td><td>Analyze test results using AI</td></tr>
<tr><td>improve</td><td>Generate improvement suggestions using AI</td></tr>
</tbody></table>
</div>
<h2 id="api-testing-6"><a class="header" href="#api-testing-6">API Testing</a></h2>
<pre><code class="language-bash"># Run a single API test
qitops api -c tests/configs/api_test.json

# Run tests in a specific environment
qitops api -c tests/configs/api_test.json -e production

# Run with custom variables
qitops api -c tests/configs/api_test.json -v base_url=https://api.example.com -v api_key=12345
</code></pre>
<h2 id="api-collection-testing"><a class="header" href="#api-collection-testing">API Collection Testing</a></h2>
<pre><code class="language-bash"># Run an API collection
qitops collection -c tests/configs/api_collection.json

# Run with environment variables
qitops collection -c tests/configs/api_collection.json -v API_KEY=your-api-key

# Run with a specific environment
qitops collection -c tests/configs/api_collection.json -e staging
</code></pre>
<h2 id="performance-testing-6"><a class="header" href="#performance-testing-6">Performance Testing</a></h2>
<pre><code class="language-bash"># Run a basic performance test
qitops performance -c tests/configs/performance_test.json -u 10 -d 30

# Run with custom users and duration
qitops performance -c tests/configs/performance_test.json -u 20 -d 60

# Run with a specific ramp-up time
qitops performance -c tests/configs/performance_test.json -u 10 -d 30 -r 5
</code></pre>
<h2 id="enhanced-performance-testing-5"><a class="header" href="#enhanced-performance-testing-5">Enhanced Performance Testing</a></h2>
<pre><code class="language-bash"># Run an enhanced performance test with multiple scenarios
qitops performance -c tests/configs/enhanced_performance_test.json

# Run with streaming metrics
qitops performance -c tests/configs/enhanced_performance_test.json --stream-metrics

# Run with custom metrics interval
qitops performance -c tests/configs/enhanced_performance_test.json --metrics-interval 10
</code></pre>
<h2 id="security-testing-6"><a class="header" href="#security-testing-6">Security Testing</a></h2>
<pre><code class="language-bash"># Run a security test
qitops security -c tests/configs/security_test.json

# Run with a specific scan depth
qitops security -c tests/configs/security_test.json -d 3

# Run with specific scan types
qitops security -c tests/configs/security_test.json --scan-types headers,ssl
</code></pre>
<h2 id="web-testing-6"><a class="header" href="#web-testing-6">Web Testing</a></h2>
<pre><code class="language-bash"># Run a web test
qitops web -c tests/configs/web_test.json

# Run in headless mode
qitops web -c tests/configs/web_test.json --headless

# Run with custom viewport
qitops web -c tests/configs/web_test.json --width 1920 --height 1080
</code></pre>
<h2 id="data-driven-testing-5"><a class="header" href="#data-driven-testing-5">Data-Driven Testing</a></h2>
<pre><code class="language-bash"># Run data-driven tests with CSV data
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv

# Run data-driven tests with JSON data
qitops data-driven -c tests/configs/data_driven_collection.json -d tests/data/products.json -t json

# Run with a limit on iterations
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv --limit 10

# Run with stop-on-failure
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv --stop-on-failure
</code></pre>
<h2 id="ai-features-3"><a class="header" href="#ai-features-3">AI Features</a></h2>
<pre><code class="language-bash"># Generate an API test configuration
qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output github_test.json

# Generate a performance test configuration
qitops generate --test-type performance --description "Load test for a web service" --output performance_test.json

# Analyze test results
qitops analyze --results test_result.json --output analysis.md

# Generate improvement suggestions
qitops improve --results test_result.json --output improvements.md

# Use a custom AI model
qitops generate --test-type api --description "Test description" --model custom --model-path /path/to/model.gguf
</code></pre>
<h2 id="cicd-integration-4"><a class="header" href="#cicd-integration-4">CI/CD Integration</a></h2>
<pre><code class="language-bash"># Run in CI mode with JSON report
qitops --ci-mode -r json -o results.json api -c tests/configs/api_test.json

# Run in CI mode with XML report (JUnit format)
qitops --ci-mode -r xml -o test-results.xml api -c tests/configs/api_test.json

# Run in CI mode with HTML report
qitops --ci-mode -r html -o report.html api -c tests/configs/api_test.json
</code></pre>
<h2 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h2>
<p>QitOps supports the following environment variables:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th></tr></thead><tbody>
<tr><td>QITOPS_ENV</td><td>Default environment to use</td></tr>
<tr><td>QITOPS_REPORT_FORMAT</td><td>Default report format</td></tr>
<tr><td>QITOPS_OUTPUT_FILE</td><td>Default output file</td></tr>
<tr><td>QITOPS_CI_MODE</td><td>Run in CI mode if set to “true”</td></tr>
<tr><td>QITOPS_VERBOSE</td><td>Enable verbose output if set to “true”</td></tr>
<tr><td>QITOPS_CONFIG_DIR</td><td>Directory containing configuration files</td></tr>
<tr><td>QITOPS_DATA_DIR</td><td>Directory containing data files</td></tr>
<tr><td>QITOPS_MODEL_PATH</td><td>Path to AI model weights</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-reference-1"><a class="header" href="#configuration-reference-1">Configuration Reference</a></h1>
<p>This page provides detailed information on configuring QitOps for different test types.</p>
<h2 id="api-test-configuration-2"><a class="header" href="#api-test-configuration-2">API Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Example API Test",
    "description": "Test description",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "url": "https://api.example.com",
    "method": "GET",
    "headers": {
        "Accept": "application/json",
        "User-Agent": "QitOps-Test"
    },
    "expected_status": 200,
    "expected_body": {
        "field1": "value1",
        "field2": "value2"
    },
    "max_response_time": 2,
    "expected_headers": {
        "content-type": "application/json",
        "cache-control": "no-cache"
    },
    "retry": {
        "max_retries": 3,
        "initial_delay_ms": 100,
        "max_delay_ms": 1000,
        "retry_status_codes": [408, 429, 500, 502, 503, 504],
        "retry_on_timeout": true,
        "retry_on_connection_error": true
    }
}
</code></pre>
<h3 id="api-test-configuration-fields"><a class="header" href="#api-test-configuration-fields">API Test Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Yes</td><td>Name of the test</td></tr>
<tr><td>description</td><td>string</td><td>No</td><td>Description of the test</td></tr>
<tr><td>timeout</td><td>number</td><td>No</td><td>Request timeout in seconds (default: 30)</td></tr>
<tr><td>retries</td><td>number</td><td>No</td><td>Number of retries (default: 3)</td></tr>
<tr><td>environment</td><td>string</td><td>No</td><td>Environment to use (default: production)</td></tr>
<tr><td>url</td><td>string</td><td>Yes</td><td>URL to test</td></tr>
<tr><td>method</td><td>string</td><td>Yes</td><td>HTTP method (GET, POST, PUT, DELETE, etc.)</td></tr>
<tr><td>headers</td><td>object</td><td>No</td><td>HTTP headers to send</td></tr>
<tr><td>body</td><td>object/string</td><td>No</td><td>Request body (JSON object or string)</td></tr>
<tr><td>expected_status</td><td>number</td><td>No</td><td>Expected HTTP status code (default: 200)</td></tr>
<tr><td>expected_body</td><td>object/string</td><td>No</td><td>Expected response body (JSON object or string)</td></tr>
<tr><td>max_response_time</td><td>number</td><td>No</td><td>Maximum acceptable response time in seconds</td></tr>
<tr><td>expected_headers</td><td>object</td><td>No</td><td>Expected response headers</td></tr>
<tr><td>retry</td><td>object</td><td>No</td><td>Retry configuration</td></tr>
</tbody></table>
</div>
<h2 id="api-collection-configuration-2"><a class="header" href="#api-collection-configuration-2">API Collection Configuration</a></h2>
<pre><code class="language-json">{
    "name": "GitHub API Collection",
    "description": "A collection of GitHub API tests",
    "version": "1.0.0",
    "variables": {
        "base_url": "https://api.github.com",
        "username": "octocat",
        "repo": "Hello-World"
    },
    "auth": {
        "type": "bearer",
        "token": "{{GITHUB_TOKEN}}"
    },
    "defaults": {
        "headers": {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "QitOps-Test"
        },
        "timeout": 30,
        "retries": 3
    },
    "requests": [
        {
            "name": "Get User",
            "description": "Get a GitHub user",
            "id": "get-user",
            "url": "{{base_url}}/users/{{username}}",
            "method": "GET",
            "expected_status": 200,
            "expected_body": {
                "login": "{{username}}",
                "type": "User"
            },
            "capture": {
                "user_id": "$.id",
                "user_url": "$.url"
            }
        },
        {
            "name": "Get User Repos",
            "description": "Get repositories for a user",
            "id": "get-user-repos",
            "url": "{{user_url}}/repos",
            "method": "GET",
            "depends_on": ["get-user"],
            "expected_status": 200
        }
    ],
    "environments": {
        "production": {
            "base_url": "https://api.github.com"
        },
        "staging": {
            "base_url": "https://api.staging.github.com"
        }
    },
    "run_options": {
        "sequential": true,
        "stop_on_failure": true,
        "delay_between_requests_ms": 500
    }
}
</code></pre>
<h2 id="performance-test-configuration-2"><a class="header" href="#performance-test-configuration-2">Performance Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Sample Performance Test",
    "description": "Load testing a public API endpoint",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com/endpoint",
    "method": "GET",
    "headers": {
        "Accept": "application/json"
    },
    "success_threshold": 95.0,
    "ramp_up_time_secs": 5
}
</code></pre>
<h2 id="security-test-configuration-2"><a class="header" href="#security-test-configuration-2">Security Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Security Scan",
    "description": "Comprehensive security scan of the API",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com",
    "headers": {
        "Accept": "application/json"
    },
    "auth": {
        "type": "bearer",
        "token": "your-token"
    },
    "scan_types": [
        "headers",
        "ssl",
        "vulnerabilities",
        "sensitive-data"
    ],
    "max_high_severity_findings": 0
}
</code></pre>
<h2 id="web-test-configuration-2"><a class="header" href="#web-test-configuration-2">Web Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Sample Web Test",
    "description": "Testing a public website",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://example.com",
    "viewport": {
        "width": 1280,
        "height": 800,
        "device_scale_factor": 1.0,
        "is_mobile": false
    },
    "wait_for_selector": "body",
    "wait_timeout_secs": 10,
    "screenshots": true,
    "user_agent": "QitOps-WebTester/1.0",
    "assertions": [
        {
            "assertion_type": "title",
            "expected_value": "Example Domain",
            "comparison": "contains"
        },
        {
            "assertion_type": "element",
            "selector": "h1",
            "expected_value": "true"
        }
    ],
    "actions": [
        {
            "action_type": "wait",
            "wait_time_ms": 1000
        },
        {
            "action_type": "click",
            "selector": "a"
        }
    ]
}
</code></pre>
<h2 id="ai-configuration-2"><a class="header" href="#ai-configuration-2">AI Configuration</a></h2>
<pre><code class="language-json">{
    "model_type": "llama",
    "model_path": "/usr/local/share/models/llama-2-7b-chat.gguf",
    "context_size": 4096,
    "temperature": 0.7,
    "max_tokens": 2048,
    "system_prompt": "You are an AI assistant specialized in software testing. Your task is to help generate test configurations, analyze test results, and suggest improvements."
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h1>
<p>This page provides recommendations on how to use QitOps effectively.</p>
<h2 id="general-best-practices"><a class="header" href="#general-best-practices">General Best Practices</a></h2>
<h3 id="configuration-management"><a class="header" href="#configuration-management">Configuration Management</a></h3>
<ul>
<li><strong>Use Version Control</strong>: Store your test configurations in a version control system like Git.</li>
<li><strong>Environment-Specific Configurations</strong>: Use environment-specific configurations for different environments (development, staging, production).</li>
<li><strong>Parameterize Configurations</strong>: Use variables and environment variables to parameterize your configurations.</li>
<li><strong>Validate Configurations</strong>: Use the JSON schema validation feature to validate your configurations.</li>
</ul>
<h3 id="test-organization"><a class="header" href="#test-organization">Test Organization</a></h3>
<ul>
<li><strong>Group Related Tests</strong>: Group related tests into collections or directories.</li>
<li><strong>Use Descriptive Names</strong>: Use descriptive names for your tests and collections.</li>
<li><strong>Include Descriptions</strong>: Include descriptions for your tests and collections to document their purpose.</li>
<li><strong>Tag Tests</strong>: Use tags to categorize tests for easier filtering and reporting.</li>
</ul>
<h3 id="cicd-integration-5"><a class="header" href="#cicd-integration-5">CI/CD Integration</a></h3>
<ul>
<li><strong>Use CI Mode</strong>: Use the <code>--ci-mode</code> flag when running tests in CI/CD pipelines.</li>
<li><strong>Generate Reports</strong>: Generate reports in a format that can be consumed by your CI/CD system.</li>
<li><strong>Set Exit Codes</strong>: Use exit codes to determine the success or failure of your tests.</li>
<li><strong>Store Artifacts</strong>: Store test results and reports as artifacts for historical analysis.</li>
</ul>
<h2 id="api-testing-best-practices"><a class="header" href="#api-testing-best-practices">API Testing Best Practices</a></h2>
<h3 id="test-design"><a class="header" href="#test-design">Test Design</a></h3>
<ul>
<li><strong>Test Happy Paths</strong>: Test the expected behavior of your API.</li>
<li><strong>Test Edge Cases</strong>: Test edge cases and error conditions.</li>
<li><strong>Test Performance</strong>: Test the performance of your API under different loads.</li>
<li><strong>Test Security</strong>: Test the security of your API.</li>
</ul>
<h3 id="request-configuration"><a class="header" href="#request-configuration">Request Configuration</a></h3>
<ul>
<li><strong>Set Timeouts</strong>: Set appropriate timeouts for your requests.</li>
<li><strong>Configure Retries</strong>: Configure retries for transient failures.</li>
<li><strong>Set Headers</strong>: Set appropriate headers for your requests.</li>
<li><strong>Validate Responses</strong>: Validate response status codes, headers, and bodies.</li>
</ul>
<h3 id="collections"><a class="header" href="#collections">Collections</a></h3>
<ul>
<li><strong>Define Dependencies</strong>: Define dependencies between requests to create test workflows.</li>
<li><strong>Capture Data</strong>: Capture data from responses to use in subsequent requests.</li>
<li><strong>Use Variables</strong>: Use variables to parameterize your requests.</li>
<li><strong>Set Default Headers</strong>: Set default headers for all requests in a collection.</li>
</ul>
<h2 id="performance-testing-best-practices"><a class="header" href="#performance-testing-best-practices">Performance Testing Best Practices</a></h2>
<h3 id="test-design-1"><a class="header" href="#test-design-1">Test Design</a></h3>
<ul>
<li><strong>Define Clear Objectives</strong>: Define clear performance objectives for your tests.</li>
<li><strong>Start Small</strong>: Start with a small number of users and gradually increase.</li>
<li><strong>Test Different Scenarios</strong>: Test different scenarios to understand the performance characteristics of your system.</li>
<li><strong>Monitor System Resources</strong>: Monitor system resources during performance tests.</li>
</ul>
<h3 id="load-profiles"><a class="header" href="#load-profiles">Load Profiles</a></h3>
<ul>
<li><strong>Use Appropriate Load Profiles</strong>: Use appropriate load profiles for your tests (constant, ramping, spike).</li>
<li><strong>Set Realistic Ramp-Up Times</strong>: Set realistic ramp-up times to avoid overwhelming your system.</li>
<li><strong>Define Thresholds</strong>: Define thresholds for pass/fail criteria.</li>
<li><strong>Use Tags</strong>: Use tags to categorize metrics for detailed analysis.</li>
</ul>
<h2 id="security-testing-best-practices"><a class="header" href="#security-testing-best-practices">Security Testing Best Practices</a></h2>
<h3 id="test-design-2"><a class="header" href="#test-design-2">Test Design</a></h3>
<ul>
<li><strong>Define Security Requirements</strong>: Define clear security requirements for your tests.</li>
<li><strong>Test Different Scan Types</strong>: Test different scan types to identify different types of vulnerabilities.</li>
<li><strong>Set Severity Thresholds</strong>: Set severity thresholds for pass/fail criteria.</li>
<li><strong>Regular Testing</strong>: Perform security tests regularly to identify new vulnerabilities.</li>
</ul>
<h3 id="authentication"><a class="header" href="#authentication">Authentication</a></h3>
<ul>
<li><strong>Test Authentication</strong>: Test authentication mechanisms to ensure they are secure.</li>
<li><strong>Test Authorization</strong>: Test authorization to ensure users can only access resources they are authorized to access.</li>
<li><strong>Test Input Validation</strong>: Test input validation to prevent injection attacks.</li>
<li><strong>Test Error Handling</strong>: Test error handling to ensure sensitive information is not leaked.</li>
</ul>
<h2 id="web-testing-best-practices"><a class="header" href="#web-testing-best-practices">Web Testing Best Practices</a></h2>
<h3 id="test-design-3"><a class="header" href="#test-design-3">Test Design</a></h3>
<ul>
<li><strong>Test Different Browsers</strong>: Test your web application in different browsers.</li>
<li><strong>Test Different Devices</strong>: Test your web application on different devices.</li>
<li><strong>Test Responsive Design</strong>: Test your web application’s responsive design.</li>
<li><strong>Test Accessibility</strong>: Test your web application’s accessibility.</li>
</ul>
<h3 id="test-automation"><a class="header" href="#test-automation">Test Automation</a></h3>
<ul>
<li><strong>Use Selectors</strong>: Use selectors to identify elements on the page.</li>
<li><strong>Set Wait Conditions</strong>: Set wait conditions to ensure elements are loaded before interacting with them.</li>
<li><strong>Capture Screenshots</strong>: Capture screenshots to document test results.</li>
<li><strong>Test User Flows</strong>: Test common user flows to ensure they work as expected.</li>
</ul>
<h2 id="ai-features-best-practices"><a class="header" href="#ai-features-best-practices">AI Features Best Practices</a></h2>
<h3 id="test-generation-1"><a class="header" href="#test-generation-1">Test Generation</a></h3>
<ul>
<li><strong>Provide Clear Descriptions</strong>: Provide clear descriptions when generating tests.</li>
<li><strong>Review Generated Tests</strong>: Review generated tests to ensure they meet your requirements.</li>
<li><strong>Customize Generated Tests</strong>: Customize generated tests to fit your specific needs.</li>
<li><strong>Use as Starting Points</strong>: Use generated tests as starting points for more complex tests.</li>
</ul>
<h3 id="test-analysis"><a class="header" href="#test-analysis">Test Analysis</a></h3>
<ul>
<li><strong>Analyze Test Results</strong>: Analyze test results to identify patterns and issues.</li>
<li><strong>Implement Suggestions</strong>: Implement improvement suggestions to enhance your tests.</li>
<li><strong>Combine with Manual Analysis</strong>: Combine AI analysis with manual analysis for comprehensive insights.</li>
<li><strong>Iterate and Improve</strong>: Use analysis results to iterate and improve your tests.</li>
</ul>
<h2 id="data-driven-testing-best-practices"><a class="header" href="#data-driven-testing-best-practices">Data-Driven Testing Best Practices</a></h2>
<h3 id="test-design-4"><a class="header" href="#test-design-4">Test Design</a></h3>
<ul>
<li><strong>Use Appropriate Data Formats</strong>: Use appropriate data formats (CSV, JSON) for your tests.</li>
<li><strong>Structure Data Properly</strong>: Structure your data properly to ensure it can be used effectively.</li>
<li><strong>Include Edge Cases</strong>: Include edge cases in your data to test boundary conditions.</li>
<li><strong>Parameterize Tests</strong>: Parameterize your tests to use data from external sources.</li>
</ul>
<h3 id="test-execution"><a class="header" href="#test-execution">Test Execution</a></h3>
<ul>
<li><strong>Set Iteration Limits</strong>: Set limits on the number of iterations to avoid long-running tests.</li>
<li><strong>Configure Stop-on-Failure</strong>: Configure whether to stop on failure or continue with other iterations.</li>
<li><strong>Generate Detailed Reports</strong>: Generate detailed reports for each iteration.</li>
<li><strong>Analyze Aggregate Results</strong>: Analyze aggregate results to identify patterns and issues.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cicd-integration-6"><a class="header" href="#cicd-integration-6">CI/CD Integration</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-driven-testing-6"><a class="header" href="#data-driven-testing-6">Data-Driven Testing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="qitops-roadmap"><a class="header" href="#qitops-roadmap">QitOps Roadmap</a></h1>
<p>This document outlines the development roadmap for QitOps, positioning it as a compelling alternative to established testing tools like Postman and k6.</p>
<h2 id="vision"><a class="header" href="#vision">Vision</a></h2>
<p>QitOps aims to be the premier CLI-first testing tool for developers and QA professionals, offering a unified interface for API, performance, security, and web testing with minimal dependencies and maximum flexibility.</p>
<h2 id="-phase-0-lock-the-core-current"><a class="header" href="#-phase-0-lock-the-core-current">🔁 Phase 0: Lock the Core (Current)</a></h2>
<p>Before pursuing feature parity with other tools, we’re focusing on making the current implementation rock-solid:</p>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic API testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic performance testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic security testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic web testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Finalize and stabilize all core modules</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement JSON config schema validation in common.rs</li>
<li><input disabled="" type="checkbox"/>
Clean CLI output with –format options (JSON, human)</li>
<li><input disabled="" type="checkbox"/>
Ensure cargo build –release produces a static binary</li>
<li><input disabled="" type="checkbox" checked=""/>
Document the config format for each testing mode</li>
</ul>
<p><strong>Milestone</strong>: CLI MVP — the “Postman/k6 replacement for power users”</p>
<h2 id="-phase-1-parity-foundation-0-2-months"><a class="header" href="#-phase-1-parity-foundation-0-2-months">📦 Phase 1: Parity Foundation (0-2 months)</a></h2>
<h3 id="-api-testing-postman-lite"><a class="header" href="#-api-testing-postman-lite">🧪 API Testing: Postman Lite</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement Collections (array of requests in one config)</li>
<li><input disabled="" type="checkbox" checked=""/>
Add Variable &amp; Environment interpolation</li>
<li><input disabled="" type="checkbox" checked=""/>
Add Request chaining via captured outputs</li>
<li><input disabled="" type="checkbox" checked=""/>
Expand Auth to support OAuth2, JWT, API Key</li>
<li><input disabled="" type="checkbox"/>
Add optional –history logging to a local SQLite file</li>
</ul>
<h3 id="-performance-testing-k6-core"><a class="header" href="#-performance-testing-k6-core">⚙️ Performance Testing: k6 Core</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement load profiles (constant, ramp-up, spike)</li>
<li><input disabled="" type="checkbox" checked=""/>
Support scenarios in one file (multiple endpoints)</li>
<li><input disabled="" type="checkbox" checked=""/>
Track custom metrics (via tags)</li>
<li><input disabled="" type="checkbox" checked=""/>
Add thresholds for pass/fail criteria</li>
<li><input disabled="" type="checkbox" checked=""/>
CLI streaming metrics (real-time bar/line output)</li>
</ul>
<p><strong>Milestone</strong>: “Parity with a Purpose”</p>
<h2 id="-phase-2-differentiators-2-4-months"><a class="header" href="#-phase-2-differentiators-2-4-months">🧑‍💻 Phase 2: Differentiators (2-4 months)</a></h2>
<h3 id="-integrations"><a class="header" href="#-integrations">🔧 Integrations</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Git sync for test configs (qitops sync)</li>
<li><input disabled="" type="checkbox" checked=""/>
GitHub Actions example template</li>
<li><input disabled="" type="checkbox"/>
Dockerfile for CLI-only image</li>
<li><input disabled="" type="checkbox" checked=""/>
Native CI support: –ci-mode</li>
</ul>
<h3 id="-reporting"><a class="header" href="#-reporting">📊 Reporting</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
JSON + HTML reporters (extend with templates)</li>
<li><input disabled="" type="checkbox"/>
Markdown summary logs (for commits)</li>
<li><input disabled="" type="checkbox" checked=""/>
CSV export for audit logs</li>
</ul>
<h3 id="-data-driven-testing"><a class="header" href="#-data-driven-testing">🧪 Data-Driven Testing</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Parametrize tests with CSV/JSON datasets</li>
<li><input disabled="" type="checkbox" checked=""/>
Support template placeholders: {{user_id}}</li>
</ul>
<p><strong>Milestone</strong>: “Beyond Parity”</p>
<h2 id="-phase-3-ai--ecosystem-4-6-months"><a class="header" href="#-phase-3-ai--ecosystem-4-6-months">🧠 Phase 3: AI &amp; Ecosystem (4-6 months)</a></h2>
<h3 id="-plugin-architecture-cli-first"><a class="header" href="#-plugin-architecture-cli-first">🔌 Plugin Architecture (CLI-first)</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Define QitOpsPlugin trait</li>
<li><input disabled="" type="checkbox"/>
Implement dynamic plugin loader (optional shared lib .so or .dll)</li>
</ul>
<h3 id="-ai-integration"><a class="header" href="#-ai-integration">🧠 AI Integration</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Generate tests from OpenAPI files</li>
<li><input disabled="" type="checkbox"/>
Record &amp; replay traffic (CLI proxy + storage)</li>
<li><input disabled="" type="checkbox"/>
Recommend missing edge cases or optimization via LLM</li>
</ul>
<h3 id="-ui-optional"><a class="header" href="#-ui-optional">🖥️ UI (Optional)</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Add TUI with textual or ratatui</li>
<li><input disabled="" type="checkbox"/>
Optional Web UI (if CLI usage + community demand)</li>
</ul>
<p><strong>Milestone</strong>: “Next-Generation Testing Platform”</p>
<h2 id="-strategic-advantages"><a class="header" href="#-strategic-advantages">📈 Strategic Advantages</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Why It Wins</th></tr></thead><tbody>
<tr><td>Unified Tool</td><td>One CLI for API, performance, security, and (later) AI</td></tr>
<tr><td>Rust Static Binary</td><td>No runtime, no nonsense — fast and portable</td></tr>
<tr><td>Open Source CLI-first</td><td>Speaks devops, CI, Git</td></tr>
<tr><td>TestOps as Code</td><td>Config-driven testing becomes auditable, repeatable</td></tr>
<tr><td>QitOps OS-ready</td><td>Tightest vertical integration possible — CLI + OS</td></tr>
</tbody></table>
</div>
<h2 id="contributing-1"><a class="header" href="#contributing-1">Contributing</a></h2>
<p>We welcome contributions to help realize this roadmap! See our <a href="../CONTRIBUTING.html">CONTRIBUTING.md</a> for guidelines on how to get involved.</p>
<h2 id="prioritization"><a class="header" href="#prioritization">Prioritization</a></h2>
<p>This roadmap is subject to change based on community feedback and evolving requirements. The core team will prioritize features based on:</p>
<ol>
<li>Core stability and reliability</li>
<li>Features that enable CI/CD integration</li>
<li>Features that differentiate QitOps from competitors</li>
<li>Features that expand the ecosystem</li>
</ol>
<h2 id="immediate-next-steps"><a class="header" href="#immediate-next-steps">Immediate Next Steps</a></h2>
<ul>
<li>Finalize the README and document config structure per test type</li>
<li>Create a qitops-collections.json sample and scaffold the feature</li>
<li>Start with simple chaining: response.body.token → next.headers.Authorization</li>
<li>Prep plugin.rs with trait + registration model (even before loading logic)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="changelog"><a class="header" href="#changelog">Changelog</a></h1>
<p>All notable changes to QitOps will be documented in this file.</p>
<p>The format is based on <a href="https://keepachangelog.com/en/1.0.0/">Keep a Changelog</a>,
and this project adheres to <a href="https://semver.org/spec/v2.0.0.html">Semantic Versioning</a>.</p>
<h2 id="010---2024-05-10"><a class="header" href="#010---2024-05-10">[0.1.0] - 2024-05-10</a></h2>
<h3 id="added"><a class="header" href="#added">Added</a></h3>
<ul>
<li>Initial release of QitOps CLI</li>
<li>Basic API testing module</li>
<li>Basic performance testing module</li>
<li>Basic security testing module</li>
<li>Basic web testing module</li>
<li>API Collections with variable interpolation and request chaining</li>
<li>Enhanced performance testing with load profiles and scenarios</li>
<li>Data-driven testing with CSV and JSON support</li>
<li>JSON config schema validation</li>
<li>Documentation for all test types</li>
<li>GitHub Actions integration example</li>
</ul>
<h3 id="fixed"><a class="header" href="#fixed">Fixed</a></h3>
<ul>
<li>Dead code warnings in api_collection.rs and performance_enhanced.rs</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributing-to-qitops"><a class="header" href="#contributing-to-qitops">Contributing to QitOps</a></h1>
<p>Thank you for your interest in contributing to QitOps! This document provides guidelines and instructions for contributing to the project.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="../CONTRIBUTING.html#code-of-conduct">Code of Conduct</a></li>
<li><a href="../CONTRIBUTING.html#getting-started">Getting Started</a></li>
<li><a href="../CONTRIBUTING.html#development-environment">Development Environment</a></li>
<li><a href="../CONTRIBUTING.html#project-structure">Project Structure</a></li>
<li><a href="../CONTRIBUTING.html#contribution-workflow">Contribution Workflow</a></li>
<li><a href="../CONTRIBUTING.html#coding-standards">Coding Standards</a></li>
<li><a href="../CONTRIBUTING.html#testing-guidelines">Testing Guidelines</a></li>
<li><a href="../CONTRIBUTING.html#documentation">Documentation</a></li>
<li><a href="../CONTRIBUTING.html#issue-and-pr-labels">Issue and PR Labels</a></li>
<li><a href="../CONTRIBUTING.html#release-process">Release Process</a></li>
</ul>
<h2 id="code-of-conduct"><a class="header" href="#code-of-conduct">Code of Conduct</a></h2>
<p>By participating in this project, you agree to abide by our Code of Conduct. Please be respectful, inclusive, and considerate in all interactions.</p>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<h3 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h3>
<ul>
<li>Rust 1.70 or higher</li>
<li>Cargo</li>
<li>Git</li>
</ul>
<h3 id="setting-up-your-development-environment"><a class="header" href="#setting-up-your-development-environment">Setting Up Your Development Environment</a></h3>
<ol>
<li>Fork the repository on GitHub</li>
<li>Clone your fork locally:
<pre><code class="language-bash">git clone https://github.com/YOUR_USERNAME/qitops-cli-tools.git
cd qitops-cli-tools
</code></pre>
</li>
<li>Add the upstream repository as a remote:
<pre><code class="language-bash">git remote add upstream https://github.com/qitops/qitops-cli-tools.git
</code></pre>
</li>
<li>Build the project:
<pre><code class="language-bash">cargo build
</code></pre>
</li>
<li>Run the tests:
<pre><code class="language-bash">cargo test
</code></pre>
</li>
</ol>
<h2 id="development-environment"><a class="header" href="#development-environment">Development Environment</a></h2>
<h3 id="recommended-tools"><a class="header" href="#recommended-tools">Recommended Tools</a></h3>
<ul>
<li><strong>IDE</strong>: VS Code with rust-analyzer extension or IntelliJ IDEA with Rust plugin</li>
<li><strong>Linting</strong>: Clippy (<code>cargo clippy</code>)</li>
<li><strong>Formatting</strong>: Rustfmt (<code>cargo fmt</code>)</li>
<li><strong>Documentation</strong>: Rustdoc (<code>cargo doc</code>)</li>
</ul>
<h3 id="building-with-features"><a class="header" href="#building-with-features">Building with Features</a></h3>
<p>QitOps supports optional features that can be enabled during build:</p>
<pre><code class="language-bash"># Build with AI features
cargo build --features ai

# Build with all features
cargo build --all-features
</code></pre>
<h2 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h2>
<p>The project follows a modular structure:</p>
<pre><code>qitops/
├── src/
│   ├── main.rs        # CLI parsing using clap
│   ├── api.rs         # API testing implementation
│   ├── performance.rs # Performance testing implementation
│   ├── security.rs    # Security testing implementation
│   ├── web.rs         # Web testing implementation
│   ├── ai.rs          # AI-powered test generation
│   ├── reporting.rs   # Report generation
│   ├── common.rs      # Shared functionality and interfaces
│   └── error.rs       # Error handling
├── tests/
│   └── configs/       # JSON test configuration files
├── .github/
│   └── workflows/     # CI configuration
├── docs/              # Documentation
├── src/templates/     # Template files
└── Cargo.toml         # Dependencies
</code></pre>
<h2 id="contribution-workflow"><a class="header" href="#contribution-workflow">Contribution Workflow</a></h2>
<h3 id="finding-issues-to-work-on"><a class="header" href="#finding-issues-to-work-on">Finding Issues to Work On</a></h3>
<ul>
<li>Check the <a href="https://github.com/qitops/qitops-cli-tools/issues">Issues</a> page</li>
<li>Look for issues labeled <code>good-first-issue</code> or <code>help-wanted</code></li>
<li>Review the <a href="https://github.com/qitops/qitops-cli-tools/projects">Project Board</a> to see current priorities</li>
</ul>
<h3 id="making-changes"><a class="header" href="#making-changes">Making Changes</a></h3>
<ol>
<li>Create a new branch for your changes:
<pre><code class="language-bash">git checkout -b feature/your-feature-name
</code></pre>
</li>
<li>Make your changes</li>
<li>Run tests to ensure your changes don’t break existing functionality:
<pre><code class="language-bash">cargo test
</code></pre>
</li>
<li>Format your code:
<pre><code class="language-bash">cargo fmt
</code></pre>
</li>
<li>Run linting checks:
<pre><code class="language-bash">cargo clippy -- -D warnings
</code></pre>
</li>
<li>Commit your changes with a descriptive commit message:
<pre><code class="language-bash">git commit -m "Add feature: your feature description"
</code></pre>
</li>
<li>Push your changes to your fork:
<pre><code class="language-bash">git push origin feature/your-feature-name
</code></pre>
</li>
<li>Create a Pull Request against the <code>master</code> branch of the main repository</li>
</ol>
<h3 id="pull-request-guidelines"><a class="header" href="#pull-request-guidelines">Pull Request Guidelines</a></h3>
<ul>
<li>Provide a clear description of the changes</li>
<li>Link to any related issues using keywords like “Fixes #123” or “Resolves #456”</li>
<li>Include tests for new functionality</li>
<li>Update documentation as needed</li>
<li>Ensure CI checks pass</li>
<li>Be responsive to feedback and review comments</li>
</ul>
<h2 id="coding-standards"><a class="header" href="#coding-standards">Coding Standards</a></h2>
<h3 id="rust-style-guidelines"><a class="header" href="#rust-style-guidelines">Rust Style Guidelines</a></h3>
<ul>
<li>Follow the <a href="https://rust-lang.github.io/api-guidelines/">Rust API Guidelines</a></li>
<li>Use Rustfmt for consistent formatting</li>
<li>Use Clippy to catch common mistakes and non-idiomatic code</li>
<li>Write clear, descriptive variable and function names</li>
<li>Add comments for complex logic</li>
<li>Use proper error handling with the <code>Result</code> type</li>
</ul>
<h3 id="core-principles"><a class="header" href="#core-principles">Core Principles</a></h3>
<p>When contributing, please keep in mind the core principles of the project:</p>
<ul>
<li>Maintain CLI-first approach with no UI dependencies</li>
<li>Keep dependencies minimal and native</li>
<li>Ensure compatibility with static binary compilation</li>
<li>Preserve clear module boundaries</li>
<li>Design for extensibility</li>
</ul>
<h2 id="testing-guidelines"><a class="header" href="#testing-guidelines">Testing Guidelines</a></h2>
<ul>
<li>Write unit tests for all new functionality</li>
<li>Include integration tests for end-to-end workflows</li>
<li>Test edge cases and error conditions</li>
<li>Use test fixtures in the <code>tests/</code> directory</li>
<li>Mock external dependencies when appropriate</li>
</ul>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<ul>
<li>Update the README.md with any user-facing changes</li>
<li>Add inline documentation using rustdoc comments (<code>///</code>)</li>
<li>Update the user guide in the <code>docs/</code> directory</li>
<li>Include examples for new features</li>
</ul>
<h2 id="issue-and-pr-labels"><a class="header" href="#issue-and-pr-labels">Issue and PR Labels</a></h2>
<p>We use the following label categories:</p>
<h3 id="type"><a class="header" href="#type">Type</a></h3>
<ul>
<li><code>type:bug</code>: Bug fixes</li>
<li><code>type:feature</code>: New features</li>
<li><code>type:enhancement</code>: Improvements to existing features</li>
<li><code>type:documentation</code>: Documentation updates</li>
<li><code>type:refactor</code>: Code refactoring</li>
<li><code>type:test</code>: Test improvements</li>
</ul>
<h3 id="module"><a class="header" href="#module">Module</a></h3>
<ul>
<li><code>module:api</code>: API testing module</li>
<li><code>module:performance</code>: Performance testing module</li>
<li><code>module:security</code>: Security testing module</li>
<li><code>module:web</code>: Web testing module</li>
<li><code>module:ai</code>: AI integration</li>
<li><code>module:common</code>: Common functionality</li>
<li><code>module:cli</code>: Command-line interface</li>
<li><code>module:reporting</code>: Reporting functionality</li>
</ul>
<h3 id="phase"><a class="header" href="#phase">Phase</a></h3>
<ul>
<li><code>phase:0</code>: Core functionality</li>
<li><code>phase:1</code>: Parity features</li>
<li><code>phase:2</code>: Differentiators</li>
<li><code>phase:3</code>: AI &amp; Ecosystem</li>
</ul>
<h3 id="status"><a class="header" href="#status">Status</a></h3>
<ul>
<li><code>status:blocked</code>: Blocked by another issue</li>
<li><code>status:help-wanted</code>: Looking for contributors</li>
<li><code>status:good-first-issue</code>: Good for newcomers</li>
</ul>
<h2 id="release-process"><a class="header" href="#release-process">Release Process</a></h2>
<ol>
<li>Update version in <code>Cargo.toml</code></li>
<li>Update <code>CHANGELOG.md</code> with the new version and changes</li>
<li>Create a new tag with the version number:
<pre><code class="language-bash">git tag -a v0.1.0 -m "Release v0.1.0"
</code></pre>
</li>
<li>Push the tag to trigger the release workflow:
<pre><code class="language-bash">git push origin v0.1.0
</code></pre>
</li>
<li>The CI/CD pipeline will automatically:
<ul>
<li>Build the release binaries</li>
<li>Publish to crates.io</li>
<li>Create a GitHub Release</li>
<li>Push Docker images</li>
</ul>
</li>
</ol>
<h2 id="thank-you"><a class="header" href="#thank-you">Thank You!</a></h2>
<p>Your contributions help make QitOps better for everyone. We appreciate your time and effort!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="license-1"><a class="header" href="#license-1">License</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="github-pages-setup"><a class="header" href="#github-pages-setup">GitHub Pages Setup</a></h1>
<p>This document explains how the QitOps documentation is deployed to GitHub Pages.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>The QitOps documentation is built using <a href="https://rust-lang.github.io/mdBook/">mdBook</a> and automatically deployed to GitHub Pages whenever changes are pushed to the <code>master</code> branch that affect the documentation.</p>
<p>The deployed documentation is available at: <a href="https://qitops.github.io/qitops-cli-tools/">https://qitops.github.io/qitops-cli-tools/</a></p>
<h2 id="deployment-workflow"><a class="header" href="#deployment-workflow">Deployment Workflow</a></h2>
<p>The deployment is handled by a GitHub Actions workflow defined in <code>.github/workflows/docs.yml</code>. This workflow:</p>
<ol>
<li>
<p>Triggers when changes are pushed to the <code>master</code> branch that affect:</p>
<ul>
<li>Files in the <code>docs/</code> directory</li>
<li>The <code>README.md</code> file</li>
<li>The workflow file itself</li>
</ul>
</li>
<li>
<p>Sets up mdBook using the <code>peaceiris/actions-mdbook@v1</code> action</p>
</li>
<li>
<p>Copies key files to the docs directory:</p>
<ul>
<li><code>README.md</code> → <code>docs/index.md</code></li>
<li><code>CHANGELOG.md</code> → <code>docs/changelog.md</code></li>
<li><code>ROADMAP.md</code> → <code>docs/roadmap.md</code></li>
<li><code>CONTRIBUTING.md</code> → <code>docs/contributing.md</code></li>
</ul>
</li>
<li>
<p>Creates a <code>book.toml</code> configuration file if it doesn’t exist</p>
</li>
<li>
<p>Builds the documentation using mdBook</p>
</li>
<li>
<p>Deploys the built documentation to the <code>gh-pages</code> branch using the <code>peaceiris/actions-gh-pages@v3</code> action</p>
</li>
</ol>
<h2 id="enabling-github-pages"><a class="header" href="#enabling-github-pages">Enabling GitHub Pages</a></h2>
<p>To enable GitHub Pages for the QitOps documentation:</p>
<ol>
<li>Go to the repository on GitHub</li>
<li>Navigate to Settings &gt; Pages</li>
<li>Under “Build and deployment”, set the following:
<ul>
<li>Source: “Deploy from a branch”</li>
<li>Branch: “gh-pages”</li>
<li>Folder: “/ (root)”</li>
</ul>
</li>
<li>Click “Save”</li>
</ol>
<h3 id="using-the-github-cli"><a class="header" href="#using-the-github-cli">Using the GitHub CLI</a></h3>
<p>If you have the GitHub CLI installed and authenticated, you can enable GitHub Pages with the following command:</p>
<pre><code class="language-bash">gh api -X PUT repos/qitops/qitops-cli-tools/pages \
  -H "Accept: application/vnd.github+json" \
  -H "X-GitHub-Api-Version: 2022-11-28" \
  -f build_type=workflow \
  -f source.branch=gh-pages \
  -f source.path=/
</code></pre>
<p>This requires a personal access token with the <code>repo</code> scope.</p>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<p>The documentation is configured in the <code>docs/book.toml</code> file, which includes:</p>
<ul>
<li>Book metadata (title, authors, etc.)</li>
<li>HTML output configuration</li>
<li>GitHub repository information</li>
<li>Search settings</li>
<li>Custom CSS and JavaScript</li>
</ul>
<p>Key configuration settings:</p>
<pre><code class="language-toml">[book]
authors = ["Jonathan Opperman"]
language = "en"
multilingual = false
src = "."
title = "QitOps Documentation"

[output.html]
git-repository-url = "https://github.com/qitops/qitops-cli-tools"
git-repository-icon = "fa-github"
edit-url-template = "https://github.com/qitops/qitops-cli-tools/edit/master/docs/{path}"
site-url = "/qitops-cli-tools/"
</code></pre>
<p>The <code>site-url</code> setting is particularly important for GitHub Pages, as it ensures that all relative URLs are correctly resolved.</p>
<h2 id="verifying-the-setup"><a class="header" href="#verifying-the-setup">Verifying the Setup</a></h2>
<p>Once GitHub Pages is enabled, you can verify that the documentation is accessible by visiting:
https://qitops.github.io/qitops-cli-tools/</p>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<p>If the documentation is not accessible after enabling GitHub Pages:</p>
<ol>
<li>Check that the gh-pages branch exists</li>
<li>Check that the GitHub Actions workflow has run successfully</li>
<li>Check that the gh-pages branch contains the built documentation</li>
<li>Wait a few minutes for the changes to propagate</li>
<li>Verify that the <code>site-url</code> in <code>book.toml</code> is set correctly</li>
<li>Check the GitHub Actions logs for any errors</li>
</ol>
<h2 id="local-development"><a class="header" href="#local-development">Local Development</a></h2>
<p>To preview the documentation locally:</p>
<ol>
<li>
<p>Install mdBook:</p>
<pre><code class="language-bash">cargo install mdbook
</code></pre>
</li>
<li>
<p>Run the development server:</p>
<pre><code class="language-bash">cd docs
mdbook serve --open
</code></pre>
</li>
<li>
<p>This will open the documentation in your browser and automatically reload when you make changes</p>
</li>
</ol>
<h2 id="adding-new-pages"><a class="header" href="#adding-new-pages">Adding New Pages</a></h2>
<p>To add a new page to the documentation:</p>
<ol>
<li>Create a new Markdown file in the <code>docs</code> directory</li>
<li>Add the page to the <code>SUMMARY.md</code> file to include it in the navigation</li>
</ol>
<p>Example <code>SUMMARY.md</code> entry:</p>
<pre><code class="language-markdown"># Summary

- [Introduction](index.md)
- [Your New Page](your-new-page.md)
</code></pre>
<h2 id="customization"><a class="header" href="#customization">Customization</a></h2>
<p>The documentation uses custom CSS and JavaScript files for styling and interactivity:</p>
<ul>
<li><code>custom.css</code>: Contains custom styles for the documentation</li>
<li><code>custom.js</code>: Contains custom JavaScript for interactive features</li>
</ul>
<p>These files are referenced in the <code>book.toml</code> file.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="editor.js"></script>
        <script src="mode-rust.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="custom.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
