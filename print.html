<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>QitOps Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="custom.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">QitOps Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/qitops/qitops-cli-tools" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="qitops-cli-tools"><a class="header" href="#qitops-cli-tools">QitOps CLI Tools</a></h1>
<p><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a>
<a href="https://github.com/qitops/qitops-cli-tools/actions/workflows/ci.yml"><img src="https://github.com/qitops/qitops-cli-tools/actions/workflows/ci.yml/badge.svg" alt="CI" /></a>
<a href="https://crates.io/crates/qitops"><img src="https://img.shields.io/crates/v/qitops" alt="Crates.io" /></a>
<a href="https://www.rust-lang.org/"><img src="https://img.shields.io/badge/rust-1.70%2B-blue.svg" alt="Rust Version" /></a>
<a href="https://github.com/qitops/qitops-cli-tools/tree/master/docs"><img src="https://img.shields.io/badge/docs-latest-brightgreen.svg" alt="Documentation" /></a></p>
<p>QitOps is a comprehensive Software Quality Assurance CLI tool for API, Performance, Security, and Web Testing. It provides a unified command-line interface with minimal dependencies and maximum flexibility.</p>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<pre><code class="language-bash"># Install QitOps
cargo install --path .

# Run a basic API test
qitops api -c tests/configs/api_test.json

# Run an API collection (multiple requests with dependencies)
qitops collection -c tests/configs/api_collection.json

# Run a performance test
qitops performance -c tests/configs/performance_test.json -u 10 -d 30

# Run a security scan
qitops security -c tests/configs/security_test.json -d 3

# Run a web test
qitops web -c tests/configs/web_test.json

# Generate a report in HTML format
qitops -r html -o report.html api -c tests/configs/api_test.json

# Run in CI mode (reduced output, exit code based on test results)
qitops --ci-mode -r json -o results.json api -c tests/configs/api_test.json

# Run data-driven tests with CSV data
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv

# Run data-driven tests with JSON data
qitops data-driven -c tests/configs/data_driven_collection.json -d tests/data/products.json -t json
</code></pre>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<h3 id="api-testing"><a class="header" href="#api-testing">API Testing</a></h3>
<ul>
<li>HTTP method support (GET, POST, PUT, DELETE, etc.)</li>
<li>URL configuration with environment-specific settings</li>
<li>Custom headers and request body support</li>
<li>Response validation (status codes, body, headers)</li>
<li>Response time monitoring</li>
<li>Configurable timeouts and retries</li>
<li>Retry mechanism with exponential backoff and jitter
<ul>
<li>Configurable retry attempts</li>
<li>Customizable retry delay</li>
<li>Status code-based retry conditions</li>
<li>Connection error handling</li>
<li>Timeout handling</li>
</ul>
</li>
</ul>
<h3 id="api-collections"><a class="header" href="#api-collections">API Collections</a></h3>
<ul>
<li>Group related API requests in a single configuration</li>
<li>Define dependencies between requests</li>
<li>Capture and use data from previous responses using JSONPath</li>
<li>Variable interpolation with {{variable}} syntax</li>
<li>Environment variables and environment-specific configurations</li>
<li>Sequential request execution with dependency management</li>
<li>Shared authentication across requests (Basic, Bearer, API Key)</li>
<li>Default request configuration (headers, timeout, retries)</li>
<li>Detailed collection reporting with captured variables</li>
<li>Request chaining for complex workflows</li>
</ul>
<h3 id="performance-testing"><a class="header" href="#performance-testing">Performance Testing</a></h3>
<ul>
<li>Load testing with configurable concurrent users</li>
<li>Response time analysis</li>
<li>Success rate monitoring</li>
<li>Ramp-up time configuration</li>
<li>Detailed performance metrics
<ul>
<li>Average response time</li>
<li>Minimum response time</li>
<li>Maximum response time</li>
<li>Total requests</li>
<li>Success/error counts</li>
<li>Success rate percentage</li>
</ul>
</li>
</ul>
<h3 id="enhanced-performance-testing"><a class="header" href="#enhanced-performance-testing">Enhanced Performance Testing</a></h3>
<ul>
<li>Multiple load profiles (constant, ramping, spike)</li>
<li>Multi-stage test execution</li>
<li>Multiple scenarios in a single test</li>
<li>Weighted scenario distribution</li>
<li>Detailed metrics collection and reporting</li>
<li>Percentile calculations (p50, p90, p95, p99)</li>
<li>Custom thresholds with pass/fail criteria</li>
<li>Real-time metrics streaming</li>
<li>Tagged metrics for detailed analysis</li>
<li>Scenario-based reporting</li>
</ul>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<ul>
<li>GitHub Actions workflow templates</li>
<li>CI mode with reduced output</li>
<li>Exit codes based on test results</li>
<li>JSON report generation for CI pipelines</li>
<li>Parallel test execution</li>
<li>Environment-specific configurations</li>
<li>Scheduled test runs</li>
<li>Artifact storage for test results and reports</li>
</ul>
<h3 id="data-driven-testing"><a class="header" href="#data-driven-testing">Data-Driven Testing</a></h3>
<ul>
<li>Parameterize tests with CSV and JSON datasets</li>
<li>Variable interpolation with {{placeholder}} syntax</li>
<li>Support for multiple iterations of the same test</li>
<li>Configurable iteration limits</li>
<li>Stop-on-failure option</li>
<li>Detailed iteration reporting</li>
<li>Support for all test types (API, Performance, Security, Web)</li>
<li>CSV header row support</li>
<li>JSON path extraction</li>
<li>Inline data definition</li>
<li>Customizable success thresholds</li>
</ul>
<h3 id="security-testing"><a class="header" href="#security-testing">Security Testing</a></h3>
<ul>
<li>Comprehensive security scanning</li>
<li>Multiple scan types (headers, SSL, vulnerabilities, sensitive data)</li>
<li>Severity-based reporting</li>
<li>Authentication testing</li>
<li>Common vulnerability checks</li>
<li>Security header validation</li>
<li>CSRF and XSS detection</li>
<li>SQL injection testing</li>
<li>JWT security analysis</li>
<li>Access control verification</li>
</ul>
<h3 id="web-testing"><a class="header" href="#web-testing">Web Testing</a></h3>
<ul>
<li>Headless browser automation</li>
<li>Viewport configuration</li>
<li>Screenshot capture</li>
<li>Element assertions</li>
<li>Text content validation</li>
<li>URL and title validation</li>
<li>Action simulation (click, type, wait, navigate)</li>
<li>Custom user agent configuration</li>
</ul>
<h3 id="ai-powered-features"><a class="header" href="#ai-powered-features">AI-Powered Features</a></h3>
<ul>
<li>
<p><strong>Test Configuration Generation</strong>: Create test configurations from natural language descriptions</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output github_test.json
</code></pre>
</li>
<li>
<p><strong>Test Results Analysis</strong>: Analyze test results to identify patterns and issues</p>
<pre><code class="language-bash">qitops analyze --results test_results.json --output analysis.md
</code></pre>
</li>
<li>
<p><strong>Improvement Suggestions</strong>: Get actionable suggestions to improve your tests</p>
<pre><code class="language-bash">qitops improve --results test_results.json --output improvements.md
</code></pre>
</li>
<li>
<p><strong>Local LLM Support</strong>: Works with various local models (LLaMA, Mistral, GPT-J, Phi)</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --model custom --model-path "ollama:phi"
</code></pre>
</li>
<li>
<p><strong>Model Parameter Customization</strong>: Configure temperature, context size, and other parameters</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --temperature 0.7 --context-size 4096
</code></pre>
</li>
<li>
<p><strong>Offline Operation</strong>: Run completely offline with no data sent to external services</p>
<pre><code class="language-bash">export QITOPS_OFFLINE=true
export QITOPS_MODEL_PATH="/path/to/model.gguf"
qitops analyze --results test_results.json --output analysis.md
</code></pre>
</li>
</ul>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<h3 id="from-cratesio-recommended"><a class="header" href="#from-cratesio-recommended">From crates.io (Recommended)</a></h3>
<pre><code class="language-bash"># Install directly from crates.io
cargo install qitops

# Run QitOps
qitops --help
</code></pre>
<h3 id="from-github-releases"><a class="header" href="#from-github-releases">From GitHub Releases</a></h3>
<ol>
<li>Download the latest binary for your platform from the <a href="https://github.com/qitops/qitops-cli-tools/releases">GitHub Releases page</a></li>
<li>Make the file executable (Linux/macOS): <code>chmod +x qitops-*</code></li>
<li>Move it to a directory in your PATH:
<ul>
<li>Linux/macOS: <code>sudo mv qitops-* /usr/local/bin/qitops</code></li>
<li>Windows: Add the directory containing the executable to your PATH</li>
</ul>
</li>
</ol>
<h3 id="using-docker"><a class="header" href="#using-docker">Using Docker</a></h3>
<pre><code class="language-bash"># Pull the Docker image
docker pull qitops/qitops:latest

# Run QitOps
docker run --rm qitops/qitops:latest --help

# Run with mounted volumes for configs and results
docker run --rm -v $(pwd)/configs:/workspace/configs -v $(pwd)/results:/workspace/results qitops/qitops:latest api -c /workspace/configs/api_test.json
</code></pre>
<h3 id="from-source"><a class="header" href="#from-source">From Source</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/qitops/qitops-cli-tools.git
cd qitops-cli-tools

# Build the project
cargo build --release

# Install the binary (optional)
cargo install --path .
</code></pre>
<h3 id="with-ai-features-optional"><a class="header" href="#with-ai-features-optional">With AI Features (Optional)</a></h3>
<pre><code class="language-bash"># Install with AI features enabled
cargo install qitops --features ai
</code></pre>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="api-test-configuration"><a class="header" href="#api-test-configuration">API Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Example API Test",
    "description": "Test description",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "url": "https://api.example.com",
    "method": "GET",
    "headers": {
        "Accept": "application/json",
        "User-Agent": "QitOps-Test"
    },
    "expected_status": 200,
    "expected_body": {
        "field1": "value1",
        "field2": "value2"
    },
    "max_response_time": 2,
    "expected_headers": {
        "content-type": "application/json",
        "cache-control": "no-cache"
    },
    "retry": {
        "max_retries": 3,
        "initial_delay_ms": 100,
        "max_delay_ms": 1000,
        "retry_status_codes": [408, 429, 500, 502, 503, 504],
        "retry_on_timeout": true,
        "retry_on_connection_error": true
    }
}
</code></pre>
<h3 id="api-collection-configuration"><a class="header" href="#api-collection-configuration">API Collection Configuration</a></h3>
<pre><code class="language-json">{
    "name": "GitHub API Collection",
    "description": "A collection of GitHub API tests",
    "version": "1.0.0",
    "variables": {
        "base_url": "https://api.github.com",
        "username": "octocat",
        "repo": "Hello-World"
    },
    "auth": {
        "type": "bearer",
        "token": "{{GITHUB_TOKEN}}"
    },
    "defaults": {
        "headers": {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "QitOps-Test"
        },
        "timeout": 30,
        "retries": 3
    },
    "requests": [
        {
            "name": "Get User",
            "description": "Get a GitHub user",
            "id": "get-user",
            "url": "{{base_url}}/users/{{username}}",
            "method": "GET",
            "expected_status": 200,
            "expected_body": {
                "login": "{{username}}",
                "type": "User"
            },
            "capture": {
                "user_id": "$.id",
                "user_url": "$.url"
            }
        },
        {
            "name": "Get User Repos",
            "description": "Get repositories for a user",
            "id": "get-user-repos",
            "url": "{{user_url}}/repos",
            "method": "GET",
            "depends_on": ["get-user"],
            "expected_status": 200
        }
    ],
    "environments": {
        "production": {
            "base_url": "https://api.github.com"
        },
        "staging": {
            "base_url": "https://api.staging.github.com"
        }
    },
    "run_options": {
        "sequential": true,
        "stop_on_failure": true,
        "delay_between_requests_ms": 500
    }
}
</code></pre>
<h3 id="performance-test-configuration"><a class="header" href="#performance-test-configuration">Performance Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Sample Performance Test",
    "description": "Load testing a public API endpoint",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com/endpoint",
    "method": "GET",
    "headers": {
        "Accept": "application/json"
    },
    "success_threshold": 95.0,
    "ramp_up_time_secs": 5
}
</code></pre>
<h3 id="enhanced-performance-test-configuration"><a class="header" href="#enhanced-performance-test-configuration">Enhanced Performance Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Enhanced Performance Test",
    "description": "Testing API performance with multiple scenarios and load profiles",
    "timeout": 60,
    "retries": 0,
    "environment": "production",
    "load_profile": {
        "type": "ramping_vus",
        "initial": 1,
        "stages": [
            {
                "duration_secs": 30,
                "target": 10
            },
            {
                "duration_secs": 60,
                "target": 20
            },
            {
                "duration_secs": 30,
                "target": 0
            }
        ]
    },
    "scenarios": [
        {
            "name": "Get Request",
            "target_url": "https://httpbin.org/get",
            "method": "GET",
            "headers": {
                "Accept": "application/json",
                "User-Agent": "QitOps-Test/1.0"
            },
            "weight": 3,
            "tags": {
                "endpoint": "get",
                "category": "read"
            }
        },
        {
            "name": "Post Request",
            "target_url": "https://httpbin.org/post",
            "method": "POST",
            "headers": {
                "Content-Type": "application/json",
                "Accept": "application/json"
            },
            "body": {
                "test": "data",
                "number": 123
            },
            "weight": 1,
            "tags": {
                "endpoint": "post",
                "category": "write"
            }
        }
    ],
    "thresholds": [
        {
            "metric": "response_time.avg",
            "expression": "&lt; 0.5",
            "abort_on_fail": false
        },
        {
            "metric": "response_time.p95",
            "expression": "&lt; 1.0",
            "abort_on_fail": false
        },
        {
            "metric": "success.avg",
            "expression": "&gt; 0.95",
            "abort_on_fail": true
        }
    ],
    "success_threshold": 95.0,
    "stream_metrics": true,
    "metrics_interval_secs": 5
}
</code></pre>
<h3 id="security-test-configuration"><a class="header" href="#security-test-configuration">Security Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Security Scan",
    "description": "Comprehensive security scan of the API",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com",
    "headers": {
        "Accept": "application/json"
    },
    "auth": {
        "type": "bearer",
        "token": "your-token"
    },
    "scan_types": [
        "headers",
        "ssl",
        "vulnerabilities",
        "sensitive-data"
    ],
    "max_high_severity_findings": 0
}
</code></pre>
<h3 id="web-test-configuration"><a class="header" href="#web-test-configuration">Web Test Configuration</a></h3>
<pre><code class="language-json">{
    "name": "Sample Web Test",
    "description": "Testing a public website",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://example.com",
    "viewport": {
        "width": 1280,
        "height": 800,
        "device_scale_factor": 1.0,
        "is_mobile": false
    },
    "wait_for_selector": "body",
    "wait_timeout_secs": 10,
    "screenshots": true,
    "user_agent": "QitOps-WebTester/1.0",
    "assertions": [
        {
            "assertion_type": "title",
            "expected_value": "Example Domain",
            "comparison": "contains"
        },
        {
            "assertion_type": "element",
            "selector": "h1",
            "expected_value": "true"
        }
    ],
    "actions": [
        {
            "action_type": "wait",
            "wait_time_ms": 1000
        },
        {
            "action_type": "click",
            "selector": "a"
        }
    ]
}
</code></pre>
<h3 id="ai-configuration"><a class="header" href="#ai-configuration">AI Configuration</a></h3>
<pre><code class="language-json">{
    "model_type": "llama",
    "model_path": "/usr/local/share/models/llama-2-7b-chat.gguf",
    "context_size": 4096,
    "temperature": 0.7,
    "max_tokens": 2048,
    "system_prompt": "You are an AI assistant specialized in software testing. Your task is to help generate test configurations, analyze test results, and suggest improvements."
}
</code></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<h3 id="api-testing-1"><a class="header" href="#api-testing-1">API Testing</a></h3>
<pre><code class="language-bash"># Run a single API test
qitops api -c tests/configs/api_test.json

# Run tests in a specific environment
qitops api -c tests/configs/api_test.json -e production
</code></pre>
<p>Example output:</p>
<pre><code>Test Results:
Name: Sample API Test
Status: passed
Duration: 0.90s
Details: {
  "headers": {
    "content-type": "application/json",
    "cache-control": "no-cache",
    ...
  },
  "response_time": 0.903123787,
  "status_code": 200
}
Timestamp: 2025-05-09T21:06:33.923402733+00:00
</code></pre>
<h3 id="api-collections-1"><a class="header" href="#api-collections-1">API Collections</a></h3>
<pre><code class="language-bash"># Run an API collection
qitops collection -c tests/configs/api_collection.json

# Run in a specific environment
qitops collection -c tests/configs/api_collection.json -e staging

# Output in JSON format
qitops collection -c tests/configs/api_collection.json -f json
</code></pre>
<p>Example output:</p>
<pre><code>Collection Results:
Name: HTTPBin API Collection
Status: passed
Duration: 2.35s
Timestamp: 2025-05-09T21:07:05.165804274+00:00

Request Results:
  1. Get IP Address - passed
  2. Post with JSON - passed
  3. Get with Headers - passed
  4. Get with Query Parameters - passed

Captured Variables:
  client_ip: 203.0.113.1
  request_id: 97e5b974-e2c3-4073-b45e-5bf5a7f3f0b2
  posted_data: {"test_value":"qitops_test_value","client_ip":"203.0.113.1"}
</code></pre>
<p>The API collections feature supports:</p>
<ul>
<li>Variable interpolation using <code>{{variable}}</code> syntax</li>
<li>Capturing data from responses using JSONPath expressions</li>
<li>Request dependencies to ensure proper execution order</li>
<li>Environment-specific configurations</li>
<li>Shared authentication and default headers</li>
</ul>
<h3 id="performance-testing-1"><a class="header" href="#performance-testing-1">Performance Testing</a></h3>
<pre><code class="language-bash"># Run performance test with default settings
qitops performance -c tests/configs/performance_test.json

# Run with custom concurrent users and duration
qitops performance -c tests/configs/performance_test.json -u 50 -d 120
</code></pre>
<p>Example output:</p>
<pre><code>Performance Test Results:
Name: Sample Performance Test
Status: passed
Duration: 10.04s
Details: {
  "average_response_time": 0.11007347446511631,
  "error_count": 0,
  "max_response_time": 0.521383212,
  "min_response_time": 0.057222978,
  "success_count": 215,
  "success_rate": 100.0,
  "total_requests": 215
}
Timestamp: 2025-05-09T21:06:50.438713024+00:00
</code></pre>
<h3 id="enhanced-performance-testing-1"><a class="header" href="#enhanced-performance-testing-1">Enhanced Performance Testing</a></h3>
<pre><code class="language-bash"># Run enhanced performance test with load profiles and scenarios
qitops performance-enhanced -c tests/configs/enhanced_performance_test.json

# Run in a specific environment
qitops performance-enhanced -c tests/configs/enhanced_performance_test.json -e staging
</code></pre>
<p>Example output:</p>
<pre><code>Enhanced Performance Test Results:
Name: Enhanced Performance Test
Status: passed
Duration: 120.35s

Metrics Summary:
  Total Requests: 1250
  Success Count: 1245
  Error Count: 5
  Success Rate: 99.60%

Response Time:
  Average: 125.32ms
  Min: 57.89ms
  Max: 521.45ms
  p50: 115.67ms
  p90: 198.34ms
  p95: 245.78ms
  p99: 378.91ms

Scenario Results:
  Get Request: 937/940 requests successful (99.68%)
  Post Request: 308/310 requests successful (99.35%)

Thresholds:
  response_time.avg: &lt; 0.5 - PASSED
  response_time.p95: &lt; 1.0 - PASSED
  success.avg: &gt; 0.95 - PASSED

For full details, use the --report option to generate a JSON report.
Timestamp: 2025-05-09T21:08:15.723654912+00:00
</code></pre>
<p>The enhanced performance testing feature supports:</p>
<ul>
<li>Multiple load profiles (constant, ramping, spike)</li>
<li>Multi-stage test execution</li>
<li>Multiple scenarios with weighted distribution</li>
<li>Custom thresholds with pass/fail criteria</li>
<li>Real-time metrics streaming</li>
<li>Detailed metrics with percentiles</li>
</ul>
<h3 id="data-driven-testing-1"><a class="header" href="#data-driven-testing-1">Data-Driven Testing</a></h3>
<pre><code class="language-bash"># Run data-driven API tests with CSV data
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv

# Run with JSON data
qitops data-driven -c tests/configs/data_driven_collection.json -d tests/data/products.json -t json

# Limit the number of iterations
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -m 3

# Stop on first failure
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -s
</code></pre>
<p>Example output:</p>
<pre><code>Iteration 1 Results:
Name: User API Test for johndoe
Status: passed
Duration: 0.52s
Details: {
  "headers": {
    "content-type": "application/json",
    ...
  },
  "response_time": 0.523456,
  "status_code": 200
}
Timestamp: 2025-05-09T21:07:05.165804274+00:00

Data Row:
  username: johndoe
  email: john.doe@example.com
  user_id: 1001
  role: admin

...

Data-Driven Test Summary:
Total Iterations: 5
Successful: 5
Failed: 0
Success Rate: 100.00%
</code></pre>
<p>The data-driven testing feature supports:</p>
<ul>
<li>Parameterizing tests with CSV and JSON datasets</li>
<li>Variable interpolation using <code>{{placeholder}}</code> syntax</li>
<li>Running multiple iterations of the same test with different data</li>
<li>Configurable iteration limits and stop-on-failure options</li>
<li>Detailed reporting for each iteration</li>
</ul>
<h3 id="security-testing-1"><a class="header" href="#security-testing-1">Security Testing</a></h3>
<pre><code class="language-bash"># Run security scan with default settings
qitops security -c tests/configs/security_test.json

# Run with custom scan depth and passive scanning
qitops security -c tests/configs/security_test.json -d 4 -p
</code></pre>
<p>Example output:</p>
<pre><code>Security Test Results:
Name: API Security Test
Status: passed
Duration: 0.00s
Details: {
  "findings": [],
  "summary": {
    "critical_findings": 0,
    "high_findings": 0,
    "low_findings": 0,
    "medium_findings": 0,
    "total_findings": 0
  }
}
Timestamp: 2025-05-09T21:07:05.165804274+00:00
</code></pre>
<h3 id="web-testing-1"><a class="header" href="#web-testing-1">Web Testing</a></h3>
<pre><code class="language-bash"># Run web test with default settings
qitops web -c tests/configs/web_test.json

# Run with headless mode disabled and custom screenshot directory
qitops web -c tests/configs/web_test.json -h false -s ./screenshots
</code></pre>
<p>Example output:</p>
<pre><code>Web Test Results:
Name: Sample Web Test
Status: passed
Duration: 1.25s
Details: {
  "action_results": [
    {
      "duration_ms": 1000,
      "success": true,
      "type": "wait"
    },
    {
      "selector": "a",
      "success": true,
      "type": "click"
    }
  ],
  "assertion_results": [
    {
      "details": "Title: Simulated Page Title",
      "passed": true,
      "type": "title"
    },
    {
      "details": "Element with selector 'h1' exists: true",
      "passed": true,
      "type": "element"
    }
  ],
  "content_length": 1256,
  "page_title": "Simulated Page Title",
  "screenshot": "./screenshots/screenshot_1715284025.png",
  "status_code": 200
}
Timestamp: 2025-05-09T21:07:05.165804274+00:00
</code></pre>
<h3 id="output-formats"><a class="header" href="#output-formats">Output Formats</a></h3>
<p>QitOps provides both human-readable and machine-readable output formats to support both interactive use and CI integration:</p>
<pre><code class="language-bash"># Default human-readable output to stdout
qitops api -c tests/configs/api_test.json

# Generate machine-readable JSON report for CI integration
qitops -r json -o report.json api -c tests/configs/api_test.json

# Generate XML report (JUnit format for CI integration)
qitops -r xml -o report.xml security -c tests/configs/security_test.json

# Generate HTML report for visual inspection
qitops -r html -o report.html performance -c tests/configs/performance_test.json

# Generate CSV report for data analysis
qitops -r csv -o report.csv web -c tests/configs/web_test.json
</code></pre>
<p>All outputs include consistent timestamping for audit trails and traceability.</p>
<h3 id="ai-powered-features-1"><a class="header" href="#ai-powered-features-1">AI-Powered Features</a></h3>
<pre><code class="language-bash"># Generate an API test configuration from a description
qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output tests/configs/github_api_test.json

# Generate a web test configuration from a description
qitops generate --test-type web --description "Test the login form on example.com with valid credentials" --output tests/configs/login_test.json

# Analyze test results
qitops analyze --results results/api_test_result.json --output analysis.md

# Get improvement suggestions based on test results
qitops improve --results results/performance_test_result.json --output improvements.md

# Use a specific AI model
qitops generate --test-type security --description "Test for SQL injection vulnerabilities" --output tests/configs/sql_injection_test.json --model mistral

# Use a custom model
qitops analyze --results results/security_test_result.json --output analysis.md --model custom --model-path /path/to/custom/model.gguf

# Use Ollama for local LLM inference
qitops generate --test-type api --description "Test the Twitter API" --output twitter_test.json --model custom --model-path "ollama:phi"
</code></pre>
<h3 id="testing-ai-features"><a class="header" href="#testing-ai-features">Testing AI Features</a></h3>
<pre><code class="language-bash"># Run the test script to verify AI features
./test_ai_features.sh

# Test with a real local LLM using Ollama
# 1. Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Pull a model
ollama pull phi

# 3. Test with Ollama
cargo run --features ai -- generate --test-type api --description "Test description" --model custom --model-path "ollama:phi"

# For more detailed instructions, see docs/testing-ai-features.md
</code></pre>
<h2 id="command-line-options"><a class="header" href="#command-line-options">Command Line Options</a></h2>
<h3 id="global-options"><a class="header" href="#global-options">Global Options</a></h3>
<ul>
<li><code>-r, --report</code>: Generate report in specified format (json, xml, html, csv)</li>
<li><code>-o, --output</code>: Output path for the report</li>
<li><code>--ci-mode</code>: Run in CI mode (reduced output, exit code based on test results)</li>
</ul>
<h3 id="api-testing-2"><a class="header" href="#api-testing-2">API Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
</ul>
<h3 id="api-collections-2"><a class="header" href="#api-collections-2">API Collections</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the collection configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-f, --format</code>: Output format (human, json) (default: “human”)</li>
</ul>
<h3 id="performance-testing-2"><a class="header" href="#performance-testing-2">Performance Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-u, --users</code>: Number of concurrent users (default: 10)</li>
<li><code>-d, --duration</code>: Test duration in seconds (default: 60)</li>
</ul>
<h3 id="enhanced-performance-testing-2"><a class="header" href="#enhanced-performance-testing-2">Enhanced Performance Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
</ul>
<h3 id="data-driven-testing-2"><a class="header" href="#data-driven-testing-2">Data-Driven Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-d, --data</code>: Path to the data source file (CSV or JSON)</li>
<li><code>-t, --data-type</code>: Data source type (csv, json) (default: “csv”)</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-m, --max-iterations</code>: Maximum number of iterations to run</li>
<li><code>-s, --stop-on-failure</code>: Stop on first failure</li>
</ul>
<h3 id="security-testing-2"><a class="header" href="#security-testing-2">Security Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-d, --depth</code>: Scan depth (1-5, default: 3)
<ul>
<li>Level 1: Basic security checks (headers, SSL)</li>
<li>Level 2: Common vulnerabilities</li>
<li>Level 3: Authentication and authorization</li>
<li>Level 4: Advanced vulnerability scanning</li>
<li>Level 5: Comprehensive security audit</li>
</ul>
</li>
<li><code>-p, --passive</code>: Include passive scanning</li>
</ul>
<h3 id="web-testing-2"><a class="header" href="#web-testing-2">Web Testing</a></h3>
<ul>
<li><code>-c, --config</code>: Path to the test configuration file</li>
<li><code>-e, --environment</code>: Environment to run tests in (default: “production”)</li>
<li><code>-h, --headless</code>: Run in headless mode (default: true)</li>
<li><code>-s, --screenshot_dir</code>: Directory to save screenshots</li>
</ul>
<h3 id="ai-test-generation"><a class="header" href="#ai-test-generation">AI Test Generation</a></h3>
<ul>
<li><code>-t, --test_type</code>: Type of test to generate (api, performance, security, web)</li>
<li><code>-d, --description</code>: Description of the test to generate</li>
<li><code>-o, --output</code>: Output file path for the generated configuration</li>
<li><code>-m, --model</code>: AI model to use (llama, mistral, gptj, phi, custom)</li>
<li><code>-p, --model_path</code>: Path to model weights (required for custom models)</li>
</ul>
<h3 id="ai-test-analysis"><a class="header" href="#ai-test-analysis">AI Test Analysis</a></h3>
<ul>
<li><code>-r, --results</code>: Path to test results file(s)</li>
<li><code>-o, --output</code>: Output file path for the analysis</li>
<li><code>-m, --model</code>: AI model to use (llama, mistral, gptj, phi, custom)</li>
<li><code>-p, --model_path</code>: Path to model weights (required for custom models)</li>
</ul>
<h3 id="ai-improvement-suggestions"><a class="header" href="#ai-improvement-suggestions">AI Improvement Suggestions</a></h3>
<ul>
<li><code>-r, --results</code>: Path to test results file(s)</li>
<li><code>-o, --output</code>: Output file path for the suggestions</li>
<li><code>-m, --model</code>: AI model to use (llama, mistral, gptj, phi, custom)</li>
<li><code>-p, --model_path</code>: Path to model weights (required for custom models)</li>
</ul>
<h2 id="test-results"><a class="header" href="#test-results">Test Results</a></h2>
<h3 id="api-test-results"><a class="header" href="#api-test-results">API Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Response details:
<ul>
<li>Status code</li>
<li>Response time</li>
<li>Headers</li>
<li>Retry attempts (if any)</li>
</ul>
</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="api-collection-results"><a class="header" href="#api-collection-results">API Collection Results</a></h3>
<ul>
<li>Collection name and status</li>
<li>Overall duration</li>
<li>Individual request results:
<ul>
<li>Request name</li>
<li>Status</li>
<li>Duration</li>
<li>Response details</li>
</ul>
</li>
<li>Captured variables</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="performance-test-results"><a class="header" href="#performance-test-results">Performance Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Performance metrics:
<ul>
<li>Total requests</li>
<li>Success/error counts</li>
<li>Success rate</li>
<li>Average response time</li>
<li>Minimum response time</li>
<li>Maximum response time</li>
</ul>
</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="enhanced-performance-test-results"><a class="header" href="#enhanced-performance-test-results">Enhanced Performance Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Detailed metrics:
<ul>
<li>Total requests</li>
<li>Success/error counts</li>
<li>Success rate</li>
<li>Response time statistics (avg, min, max)</li>
<li>Percentile measurements (p50, p90, p95, p99)</li>
</ul>
</li>
<li>Scenario-specific metrics:
<ul>
<li>Per-scenario success rates</li>
<li>Per-scenario request counts</li>
</ul>
</li>
<li>Threshold evaluations:
<ul>
<li>Metric name</li>
<li>Expression</li>
<li>Pass/fail status</li>
</ul>
</li>
<li>Tagged metrics for detailed analysis</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="security-test-results"><a class="header" href="#security-test-results">Security Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Security findings:
<ul>
<li>Critical findings</li>
<li>High severity findings</li>
<li>Medium severity findings</li>
<li>Low severity findings</li>
<li>Total findings</li>
</ul>
</li>
<li>Detailed findings with:
<ul>
<li>Severity level</li>
<li>Category</li>
<li>Description</li>
<li>Recommendation</li>
</ul>
</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h3 id="web-test-results"><a class="header" href="#web-test-results">Web Test Results</a></h3>
<ul>
<li>Test name and status</li>
<li>Duration</li>
<li>Page information:
<ul>
<li>Page title</li>
<li>Status code</li>
<li>Content length</li>
</ul>
</li>
<li>Assertion results:
<ul>
<li>Type (title, url, element, text)</li>
<li>Pass/fail status</li>
<li>Details</li>
</ul>
</li>
<li>Action results:
<ul>
<li>Type (click, type, wait, navigate)</li>
<li>Success status</li>
<li>Details</li>
</ul>
</li>
<li>Screenshot path (if enabled)</li>
<li>Timestamp</li>
<li>Environment information</li>
</ul>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="api-testing-3"><a class="header" href="#api-testing-3">API Testing</a></h3>
<ul>
<li>Use environment-specific configurations for different deployment stages</li>
<li>Set appropriate timeouts based on your API’s expected response times</li>
<li>Configure retry mechanisms for transient failures</li>
<li>Validate both success and error responses</li>
<li>Use JSON Schema validation for complex response structures</li>
<li>Monitor response times to catch performance degradation</li>
</ul>
<h3 id="api-collections-3"><a class="header" href="#api-collections-3">API Collections</a></h3>
<ul>
<li>Organize related requests into logical collections</li>
<li>Use meaningful request IDs for better readability and dependencies</li>
<li>Leverage JSONPath for precise data extraction from responses</li>
<li>Use variable capture and reuse for efficient testing</li>
<li>Define environment-specific variables for different deployment stages</li>
<li>Use sequential execution for dependent requests</li>
<li>Set appropriate delays between requests to avoid rate limiting</li>
<li>Define shared authentication at the collection level</li>
<li>Use defaults for common configuration across requests</li>
<li>Structure collections to follow user journeys or business processes</li>
<li>Use request dependencies to ensure proper execution order</li>
<li>Keep collections focused on a specific testing goal</li>
</ul>
<h3 id="performance-testing-3"><a class="header" href="#performance-testing-3">Performance Testing</a></h3>
<ul>
<li>Start with a small number of concurrent users and gradually increase</li>
<li>Use appropriate ramp-up times to avoid overwhelming the system</li>
<li>Set realistic success thresholds based on your requirements</li>
<li>Monitor system resources during tests</li>
<li>Run tests in a controlled environment</li>
<li>Consider network latency in your test environment</li>
</ul>
<h3 id="enhanced-performance-testing-3"><a class="header" href="#enhanced-performance-testing-3">Enhanced Performance Testing</a></h3>
<ul>
<li>Design multi-stage tests to simulate realistic user behavior</li>
<li>Use different load profiles for different testing scenarios</li>
<li>Define multiple scenarios to test different API endpoints</li>
<li>Use weighted scenarios to simulate real-world usage patterns</li>
<li>Set appropriate thresholds based on SLAs and performance requirements</li>
<li>Use tags to categorize and analyze metrics</li>
<li>Monitor real-time metrics during test execution</li>
<li>Analyze percentile measurements for a better understanding of performance</li>
<li>Use custom thresholds to catch performance regressions early</li>
<li>Run tests in different environments to compare performance</li>
</ul>
<h3 id="data-driven-testing-3"><a class="header" href="#data-driven-testing-3">Data-Driven Testing</a></h3>
<ul>
<li>Organize test data in CSV or JSON format based on complexity</li>
<li>Use CSV for simple tabular data with a consistent structure</li>
<li>Use JSON for complex nested data structures</li>
<li>Include a header row in CSV files for better readability</li>
<li>Use meaningful placeholder names that match data column names</li>
<li>Keep test configurations generic with placeholders</li>
<li>Use stop-on-failure for dependent test iterations</li>
<li>Set appropriate max iterations for large datasets</li>
<li>Validate data files before running tests</li>
<li>Use environment-specific configurations with data-driven tests</li>
<li>Combine data-driven testing with API collections for complex workflows</li>
</ul>
<h3 id="security-testing-3"><a class="header" href="#security-testing-3">Security Testing</a></h3>
<ul>
<li>Start with passive scanning before active scanning</li>
<li>Use appropriate scan depth based on your security requirements</li>
<li>Review and address high-severity findings immediately</li>
<li>Keep authentication tokens secure</li>
<li>Run security tests in a controlled environment</li>
<li>Regularly update security test configurations</li>
</ul>
<h3 id="web-testing-3"><a class="header" href="#web-testing-3">Web Testing</a></h3>
<ul>
<li>Use headless mode for CI/CD pipelines</li>
<li>Configure appropriate viewport sizes for different devices</li>
<li>Keep assertions focused and specific</li>
<li>Use explicit waits for dynamic content</li>
<li>Capture screenshots for visual verification</li>
<li>Test across different browsers in production</li>
<li>Organize tests by user journey or feature</li>
<li>Use custom user agents when needed</li>
</ul>
<h3 id="ai-powered-testing"><a class="header" href="#ai-powered-testing">AI-Powered Testing</a></h3>
<ul>
<li>Use specific, detailed descriptions when generating tests</li>
<li>Review and refine AI-generated test configurations before use</li>
<li>Provide context in your descriptions (e.g., authentication requirements)</li>
<li>Use lower temperature values (0.1-0.3) for more deterministic outputs</li>
<li>Use higher temperature values (0.7-0.9) for more creative test scenarios</li>
<li>Analyze test results regularly to identify patterns and issues</li>
<li>Combine AI suggestions with human expertise for best results</li>
<li>Keep model weights updated for best performance</li>
</ul>
<h3 id="cicd-integration-1"><a class="header" href="#cicd-integration-1">CI/CD Integration</a></h3>
<ul>
<li>Use <code>--ci-mode</code> for reduced output and exit codes in CI pipelines</li>
<li>Generate JSON reports for machine-readable results</li>
<li>Use GitHub Actions templates for quick setup</li>
<li>Run different test types in parallel for faster feedback</li>
<li>Set up scheduled runs for regular testing</li>
<li>Use environment-specific configurations for different stages</li>
<li>Store test results as artifacts for historical analysis</li>
<li>Set appropriate timeouts for CI environments</li>
<li>Use exit codes to gate deployments</li>
<li>Integrate with notification systems for test failures</li>
</ul>
<h2 id="configuration-reference"><a class="header" href="#configuration-reference">Configuration Reference</a></h2>
<h3 id="api-test-configuration-1"><a class="header" href="#api-test-configuration-1">API Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>method</td><td>string</td><td>HTTP method</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>expected_status</td><td>number</td><td>Expected HTTP status code</td><td>Optional</td></tr>
<tr><td>expected_body</td><td>object</td><td>Expected response body</td><td>Optional</td></tr>
<tr><td>max_response_time</td><td>number</td><td>Maximum allowed response time in seconds</td><td>Optional</td></tr>
<tr><td>expected_headers</td><td>object</td><td>Expected response headers</td><td>Optional</td></tr>
<tr><td>retry</td><td>object</td><td>Retry configuration</td><td>See below</td></tr>
</tbody></table>
</div>
<h4 id="retry-configuration"><a class="header" href="#retry-configuration">Retry Configuration</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>max_retries</td><td>number</td><td>Maximum number of retry attempts</td><td>3</td></tr>
<tr><td>initial_delay_ms</td><td>number</td><td>Initial delay between retries in milliseconds</td><td>100</td></tr>
<tr><td>max_delay_ms</td><td>number</td><td>Maximum delay between retries in milliseconds</td><td>1000</td></tr>
<tr><td>retry_status_codes</td><td>array</td><td>HTTP status codes that trigger retries</td><td>[408, 429, 500, 502, 503, 504]</td></tr>
<tr><td>retry_on_timeout</td><td>boolean</td><td>Whether to retry on timeout</td><td>true</td></tr>
<tr><td>retry_on_connection_error</td><td>boolean</td><td>Whether to retry on connection errors</td><td>true</td></tr>
</tbody></table>
</div>
<h3 id="api-collection-configuration-1"><a class="header" href="#api-collection-configuration-1">API Collection Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Collection name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Collection description</td><td>Optional</td></tr>
<tr><td>version</td><td>string</td><td>Collection version</td><td>Optional</td></tr>
<tr><td>variables</td><td>object</td><td>Collection variables</td><td>Optional</td></tr>
<tr><td>auth</td><td>object</td><td>Collection authentication</td><td>Optional</td></tr>
<tr><td>defaults</td><td>object</td><td>Default request configuration</td><td>Optional</td></tr>
<tr><td>requests</td><td>array</td><td>Collection requests</td><td>Required</td></tr>
<tr><td>environments</td><td>object</td><td>Environment-specific variables</td><td>Optional</td></tr>
<tr><td>run_options</td><td>object</td><td>Run options</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="collection-auth"><a class="header" href="#collection-auth">Collection Auth</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>type</td><td>string</td><td>Authentication type (basic, bearer, api_key)</td><td>Required</td></tr>
<tr><td>username</td><td>string</td><td>Username for basic auth</td><td>Optional</td></tr>
<tr><td>password</td><td>string</td><td>Password for basic auth</td><td>Optional</td></tr>
<tr><td>token</td><td>string</td><td>Token for bearer auth</td><td>Optional</td></tr>
<tr><td>key_name</td><td>string</td><td>Key name for API key auth</td><td>Optional</td></tr>
<tr><td>key_value</td><td>string</td><td>Key value for API key auth</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="collection-defaults"><a class="header" href="#collection-defaults">Collection Defaults</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>headers</td><td>object</td><td>Default headers for all requests</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Default timeout in seconds</td><td>Optional</td></tr>
<tr><td>retries</td><td>number</td><td>Default number of retries</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="collection-request"><a class="header" href="#collection-request">Collection Request</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Request name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Request description</td><td>Optional</td></tr>
<tr><td>id</td><td>string</td><td>Request ID (used for dependencies)</td><td>Optional</td></tr>
<tr><td>url</td><td>string</td><td>Request URL</td><td>Required</td></tr>
<tr><td>method</td><td>string</td><td>HTTP method</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>body</td><td>object</td><td>Request body</td><td>Optional</td></tr>
<tr><td>expected_status</td><td>number</td><td>Expected HTTP status code</td><td>Optional</td></tr>
<tr><td>expected_body</td><td>object</td><td>Expected response body</td><td>Optional</td></tr>
<tr><td>expected_body_type</td><td>string</td><td>Expected response body type</td><td>Optional</td></tr>
<tr><td>depends_on</td><td>array</td><td>Request dependencies</td><td>Optional</td></tr>
<tr><td>capture</td><td>object</td><td>Variables to capture from response</td><td>Optional</td></tr>
</tbody></table>
</div>
<h3 id="data-driven-testing-configuration"><a class="header" href="#data-driven-testing-configuration">Data-Driven Testing Configuration</a></h3>
<h4 id="csv-data-file"><a class="header" href="#csv-data-file">CSV Data File</a></h4>
<pre><code class="language-csv">username,email,user_id,role
johndoe,john.doe@example.com,1001,admin
janedoe,jane.doe@example.com,1002,user
bobsmith,bob.smith@example.com,1003,user
</code></pre>
<h4 id="json-data-file"><a class="header" href="#json-data-file">JSON Data File</a></h4>
<pre><code class="language-json">[
  {
    "product_id": "P001",
    "name": "Smartphone",
    "price": 599.99,
    "category": "Electronics",
    "in_stock": true
  },
  {
    "product_id": "P002",
    "name": "Laptop",
    "price": 1299.99,
    "category": "Electronics",
    "in_stock": true
  }
]
</code></pre>
<h4 id="test-configuration-with-placeholders"><a class="header" href="#test-configuration-with-placeholders">Test Configuration with Placeholders</a></h4>
<pre><code class="language-json">{
  "name": "User API Test for {{username}}",
  "description": "Test the user API for {{username}}",
  "url": "https://api.example.com/users/{{user_id}}",
  "method": "GET",
  "headers": {
    "Accept": "application/json",
    "X-User-Email": "{{email}}"
  },
  "expected_status": 200,
  "expected_body": {
    "id": "{{user_id}}",
    "role": "{{role}}"
  }
}
</code></pre>
<h4 id="run-options"><a class="header" href="#run-options">Run Options</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>sequential</td><td>boolean</td><td>Run requests sequentially</td><td>true</td></tr>
<tr><td>stop_on_failure</td><td>boolean</td><td>Stop on first failure</td><td>true</td></tr>
<tr><td>delay_between_requests_ms</td><td>number</td><td>Delay between requests in milliseconds</td><td>0</td></tr>
</tbody></table>
</div>
<h3 id="performance-test-configuration-1"><a class="header" href="#performance-test-configuration-1">Performance Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>target_url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>method</td><td>string</td><td>HTTP method</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>success_threshold</td><td>number</td><td>Minimum success rate percentage</td><td>95.0</td></tr>
<tr><td>ramp_up_time_secs</td><td>number</td><td>Time to ramp up to full load in seconds</td><td>5</td></tr>
</tbody></table>
</div>
<h3 id="security-test-configuration-1"><a class="header" href="#security-test-configuration-1">Security Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>target_url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>headers</td><td>object</td><td>Request headers</td><td>Optional</td></tr>
<tr><td>auth</td><td>object</td><td>Authentication configuration</td><td>Optional</td></tr>
<tr><td>scan_types</td><td>array</td><td>Types of security scans to perform</td><td>[“headers”, “ssl”, “vulnerabilities”, “sensitive-data”]</td></tr>
<tr><td>max_high_severity_findings</td><td>number</td><td>Maximum allowed high severity findings</td><td>0</td></tr>
</tbody></table>
</div>
<h3 id="web-test-configuration-1"><a class="header" href="#web-test-configuration-1">Web Test Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Test name</td><td>Required</td></tr>
<tr><td>description</td><td>string</td><td>Test description</td><td>Optional</td></tr>
<tr><td>timeout</td><td>number</td><td>Request timeout in seconds</td><td>30</td></tr>
<tr><td>retries</td><td>number</td><td>Number of retry attempts</td><td>3</td></tr>
<tr><td>environment</td><td>string</td><td>Environment name</td><td>“production”</td></tr>
<tr><td>target_url</td><td>string</td><td>Target URL</td><td>Required</td></tr>
<tr><td>viewport</td><td>object</td><td>Browser viewport configuration</td><td>Optional</td></tr>
<tr><td>wait_for_selector</td><td>string</td><td>Selector to wait for before starting test</td><td>Optional</td></tr>
<tr><td>wait_timeout_secs</td><td>number</td><td>Timeout for waiting for selector</td><td>30</td></tr>
<tr><td>screenshots</td><td>boolean</td><td>Whether to capture screenshots</td><td>false</td></tr>
<tr><td>user_agent</td><td>string</td><td>Custom user agent string</td><td>“QitOps-WebTester/1.0”</td></tr>
<tr><td>assertions</td><td>array</td><td>List of assertions to perform</td><td>Optional</td></tr>
<tr><td>actions</td><td>array</td><td>List of actions to perform</td><td>Optional</td></tr>
</tbody></table>
</div>
<h4 id="viewport-configuration"><a class="header" href="#viewport-configuration">Viewport Configuration</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>width</td><td>number</td><td>Viewport width in pixels</td><td>Required</td></tr>
<tr><td>height</td><td>number</td><td>Viewport height in pixels</td><td>Required</td></tr>
<tr><td>device_scale_factor</td><td>number</td><td>Device scale factor</td><td>1.0</td></tr>
<tr><td>is_mobile</td><td>boolean</td><td>Whether to emulate a mobile device</td><td>false</td></tr>
</tbody></table>
</div>
<h4 id="web-assertion"><a class="header" href="#web-assertion">Web Assertion</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>assertion_type</td><td>string</td><td>Type of assertion (title, url, element, text, attribute)</td><td>Required</td></tr>
<tr><td>selector</td><td>string</td><td>CSS selector for element assertions</td><td>Optional</td></tr>
<tr><td>attribute</td><td>string</td><td>Attribute name for attribute assertions</td><td>Optional</td></tr>
<tr><td>expected_value</td><td>string</td><td>Expected value to compare against</td><td>Required</td></tr>
<tr><td>comparison</td><td>string</td><td>Comparison type (equals, contains, startsWith, endsWith, matches)</td><td>“equals”</td></tr>
</tbody></table>
</div>
<h4 id="web-action"><a class="header" href="#web-action">Web Action</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>action_type</td><td>string</td><td>Type of action (click, type, wait, navigate)</td><td>Required</td></tr>
<tr><td>selector</td><td>string</td><td>CSS selector for element actions</td><td>Optional</td></tr>
<tr><td>value</td><td>string</td><td>Value for type actions or URL for navigate actions</td><td>Optional</td></tr>
<tr><td>wait_time_ms</td><td>number</td><td>Wait time in milliseconds for wait actions</td><td>1000</td></tr>
</tbody></table>
</div>
<h3 id="ai-configuration-1"><a class="header" href="#ai-configuration-1">AI Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td>model_type</td><td>string</td><td>Type of AI model (llama, mistral, gptj, phi, custom)</td><td>Required</td></tr>
<tr><td>model_path</td><td>string</td><td>Path to the model weights</td><td>Optional</td></tr>
<tr><td>context_size</td><td>number</td><td>Context window size</td><td>2048</td></tr>
<tr><td>temperature</td><td>number</td><td>Temperature for generation (0.0-1.0)</td><td>0.7</td></tr>
<tr><td>max_tokens</td><td>number</td><td>Maximum tokens to generate</td><td>1024</td></tr>
<tr><td>system_prompt</td><td>string</td><td>System prompt to use</td><td>Optional</td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h3>
<h4 id="api-testing-4"><a class="header" href="#api-testing-4">API Testing</a></h4>
<ul>
<li><strong>Timeout Errors</strong>: Increase the timeout value in your configuration</li>
<li><strong>Connection Errors</strong>: Check network connectivity and retry settings</li>
<li><strong>Validation Failures</strong>: Verify expected response format and values</li>
<li><strong>Retry Loop</strong>: Check retry configuration and target system status</li>
</ul>
<h4 id="api-collections-4"><a class="header" href="#api-collections-4">API Collections</a></h4>
<ul>
<li><strong>Dependency Errors</strong>: Ensure dependent requests are correctly defined and executed</li>
<li><strong>Variable Capture Failures</strong>: Check JSONPath expressions and response structure</li>
<li><strong>Variable Interpolation Issues</strong>: Verify variable names and syntax ({{variable}})</li>
<li><strong>Authentication Failures</strong>: Check auth configuration and token validity</li>
<li><strong>Sequential Execution Problems</strong>: Verify run_options and dependencies</li>
<li><strong>JSONPath Errors</strong>: Validate JSONPath expressions against actual response structure</li>
<li><strong>Missing Variables</strong>: Ensure all referenced variables are defined or captured</li>
<li><strong>Request Chaining Issues</strong>: Check that dependent requests are capturing the expected data</li>
<li><strong>Environment Configuration</strong>: Verify environment-specific variables are correctly set</li>
</ul>
<h4 id="performance-testing-4"><a class="header" href="#performance-testing-4">Performance Testing</a></h4>
<ul>
<li><strong>High Error Rate</strong>: Reduce concurrent users or increase ramp-up time</li>
<li><strong>Slow Response Times</strong>: Check network latency and target system load</li>
<li><strong>Resource Exhaustion</strong>: Monitor system resources and adjust test parameters</li>
<li><strong>Inconsistent Results</strong>: Ensure test environment stability</li>
</ul>
<h4 id="enhanced-performance-testing-4"><a class="header" href="#enhanced-performance-testing-4">Enhanced Performance Testing</a></h4>
<ul>
<li><strong>Stage Transition Issues</strong>: Check stage durations and target values</li>
<li><strong>Threshold Failures</strong>: Verify threshold expressions and metric names</li>
<li><strong>Scenario Distribution Problems</strong>: Check scenario weights and total count</li>
<li><strong>Metric Collection Issues</strong>: Ensure metrics are being properly captured</li>
<li><strong>High Resource Usage</strong>: Reduce the number of concurrent VUs or increase stage duration</li>
<li><strong>Percentile Calculation Errors</strong>: Ensure enough samples for accurate percentiles</li>
<li><strong>Tagged Metrics Missing</strong>: Verify tag names and values in scenario configuration</li>
</ul>
<h4 id="cicd-integration-2"><a class="header" href="#cicd-integration-2">CI/CD Integration</a></h4>
<ul>
<li><strong>Exit Code Issues</strong>: Ensure test status is correctly reported</li>
<li><strong>GitHub Actions Failures</strong>: Check workflow YAML syntax and permissions</li>
<li><strong>Report Generation Failures</strong>: Verify output directory exists and is writable</li>
<li><strong>Parallel Test Conflicts</strong>: Ensure tests don’t interfere with each other</li>
<li><strong>Timeout Errors</strong>: Increase CI job timeout or reduce test duration</li>
<li><strong>Environment Variable Issues</strong>: Check environment variable configuration</li>
<li><strong>Artifact Storage Problems</strong>: Verify artifact paths and retention settings</li>
</ul>
<h4 id="data-driven-testing-4"><a class="header" href="#data-driven-testing-4">Data-Driven Testing</a></h4>
<ul>
<li><strong>CSV Parsing Errors</strong>: Check CSV format and delimiter settings</li>
<li><strong>JSON Parsing Errors</strong>: Validate JSON syntax and structure</li>
<li><strong>Placeholder Not Found</strong>: Ensure placeholder names match data column names</li>
<li><strong>Missing Data Columns</strong>: Verify data file contains all required columns</li>
<li><strong>Iteration Failures</strong>: Check if stop-on-failure is appropriate for your test</li>
<li><strong>Performance Issues</strong>: Reduce max iterations for large datasets</li>
<li><strong>File Not Found Errors</strong>: Verify data file paths</li>
<li><strong>JSON Path Errors</strong>: Check JSON path syntax for complex data structures</li>
<li><strong>Type Conversion Issues</strong>: Ensure data types match expected values</li>
<li><strong>Empty Data Sets</strong>: Verify data files contain valid test data</li>
</ul>
<h4 id="security-testing-4"><a class="header" href="#security-testing-4">Security Testing</a></h4>
<ul>
<li><strong>False Positives</strong>: Review and adjust scan depth and types</li>
<li><strong>Authentication Failures</strong>: Verify auth configuration</li>
<li><strong>Scan Timeouts</strong>: Adjust timeout settings for complex scans</li>
<li><strong>Missing Findings</strong>: Check scan depth and types configuration</li>
</ul>
<h4 id="web-testing-4"><a class="header" href="#web-testing-4">Web Testing</a></h4>
<ul>
<li><strong>Element Not Found</strong>: Check selectors and wait conditions</li>
<li><strong>Timeout Errors</strong>: Increase wait timeout for dynamic content</li>
<li><strong>Screenshot Issues</strong>: Verify screenshot directory permissions</li>
<li><strong>Assertion Failures</strong>: Check expected values and comparison types</li>
<li><strong>Action Failures</strong>: Verify element visibility and interactability</li>
</ul>
<h4 id="ai-features"><a class="header" href="#ai-features">AI Features</a></h4>
<ul>
<li><strong>Model Loading Errors</strong>: Verify model path and format compatibility</li>
<li><strong>Out of Memory</strong>: Reduce context size or use a smaller model</li>
<li><strong>Poor Quality Output</strong>: Adjust temperature or provide more detailed prompts</li>
<li><strong>Slow Generation</strong>: Use a smaller model or reduce max tokens</li>
<li><strong>Missing Dependencies</strong>: Install AI dependencies with <code>cargo build --features ai</code></li>
</ul>
<h2 id="development"><a class="header" href="#development">Development</a></h2>
<h3 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h3>
<ul>
<li>Rust 1.70 or higher</li>
<li>Cargo</li>
<li>Git</li>
</ul>
<h3 id="constraints"><a class="header" href="#constraints">Constraints</a></h3>
<p>QitOps is designed with the following constraints in mind:</p>
<ul>
<li><strong>Minimal dependencies</strong>: Uses only the Rust standard library and well-known crates</li>
<li><strong>Static binary compilation</strong>: Can be compiled to a static binary for Linux</li>
<li><strong>CLI-only interface</strong>: All functionality is accessible via CLI flags with no UI dependencies</li>
<li><strong>Terminal-friendly output</strong>: Human-readable output for direct terminal use</li>
<li><strong>Machine-readable formats</strong>: Structured output for CI/CD integration</li>
</ul>
<h3 id="building-from-source"><a class="header" href="#building-from-source">Building from Source</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/yourusername/qitops.git
cd qitops

# Build the project
cargo build

# Run tests
cargo test

# Build documentation
cargo doc --no-deps

# Build static binary for Linux
cargo build --release --target x86_64-unknown-linux-musl
</code></pre>
<h3 id="architecture--project-structure"><a class="header" href="#architecture--project-structure">Architecture &amp; Project Structure</a></h3>
<p>QitOps follows a modular architecture with clear boundaries between components:</p>
<pre><code>qitops/
├── src/
│   ├── main.rs        # CLI parsing using clap
│   ├── api.rs         # API testing implementation
│   ├── performance.rs # Performance testing implementation
│   ├── security.rs    # Security testing implementation
│   ├── web.rs         # Web testing implementation (extension)
│   ├── ai.rs          # AI-powered test generation (extension)
│   ├── reporting.rs   # Report generation (extension)
│   ├── common.rs      # Shared functionality and interfaces
│   └── error.rs       # Error handling
├── tests/
│   └── configs/       # JSON test configuration files
│       ├── api_test.json
│       ├── performance_test.json
│       ├── security_test.json
│       ├── web_test.json
│       └── ai_config.json
├── .github/
│   └── workflows/     # CI configuration
├── Dockerfile         # Container definition
├── docker-compose.yml # Container orchestration
└── Cargo.toml         # Dependencies (minimal and native)
</code></pre>
<p>The architecture is designed with the following principles:</p>
<ul>
<li><strong>Clear module boundaries</strong>: Each testing type has its own module</li>
<li><strong>Common interfaces</strong>: All test runners implement the <code>TestRunner</code> trait</li>
<li><strong>JSON-based configuration</strong>: Tests are defined using structured JSON files</li>
<li><strong>Minimal dependencies</strong>: Uses Rust standard library and well-known crates</li>
<li><strong>CLI-first approach</strong>: All functionality accessible via command-line flags</li>
<li><strong>Extensibility</strong>: Designed for future expansion (TUI, AI integration)</li>
</ul>
<h3 id="cicd-integration-3"><a class="header" href="#cicd-integration-3">CI/CD Integration</a></h3>
<p>QitOps is designed to be CI/CD ready and can be easily integrated into your CI/CD pipeline:</p>
<h4 id="github-actions"><a class="header" href="#github-actions">GitHub Actions</a></h4>
<p>The included GitHub Actions workflow (<code>ci.yml</code>) automatically:</p>
<ul>
<li>Builds and tests the project</li>
<li>Runs linting and formatting checks</li>
<li>Executes sample tests for each test type</li>
<li>Creates release artifacts</li>
</ul>
<h4 id="docker-integration"><a class="header" href="#docker-integration">Docker Integration</a></h4>
<p>The included Dockerfile and docker-compose.yml allow you to:</p>
<ul>
<li>Build a containerized version of QitOps</li>
<li>Run tests in isolated containers</li>
<li>Mount configuration and result volumes</li>
<li>Set environment variables for different environments</li>
</ul>
<h4 id="junit-xml-reports"><a class="header" href="#junit-xml-reports">JUnit XML Reports</a></h4>
<p>Generate JUnit XML reports for integration with CI/CD tools:</p>
<pre><code class="language-bash">qitops -r xml -o test-results.xml api -c tests/configs/api_test.json
</code></pre>
<p>Most CI/CD platforms (Jenkins, GitHub Actions, GitLab CI, etc.) can automatically parse these reports to display test results.</p>
<h3 id="adding-new-features"><a class="header" href="#adding-new-features">Adding New Features</a></h3>
<ol>
<li>Create a new module in <code>src/</code></li>
<li>Implement the <code>TestRunner</code> trait</li>
<li>Add CLI commands in <code>main.rs</code></li>
<li>Add configuration structures</li>
<li>Write tests</li>
<li>Update documentation</li>
</ol>
<h2 id="qitops-os-integration"><a class="header" href="#qitops-os-integration">QitOps OS Integration</a></h2>
<p>QitOps CLI is designed to be bundled into QitOps OS, a custom bootable Linux distribution for QA professionals. When integrated into QitOps OS, the tool will be:</p>
<ul>
<li>Pre-installed in <code>/usr/local/bin</code> as a static binary</li>
<li>Configured with default test configurations in <code>/etc/qitops/configs</code></li>
<li>Available directly from the terminal without additional setup</li>
<li>Optimized for the QitOps OS environment</li>
</ul>
<p>QA professionals can boot directly into QitOps OS and run tests from the terminal without any additional installation or configuration steps.</p>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.</p>
<p>When contributing, please keep in mind the core principles of the project:</p>
<ul>
<li>Maintain CLI-first approach with no UI dependencies</li>
<li>Keep dependencies minimal and native</li>
<li>Ensure compatibility with static binary compilation</li>
<li>Preserve clear module boundaries</li>
<li>Design for extensibility</li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="why-qitops"><a class="header" href="#why-qitops">Why QitOps?</a></h1>
<p>QitOps is a comprehensive CLI testing tool designed to address the limitations of existing testing solutions while providing a modern, efficient, and developer-friendly approach to quality assurance.</p>
<h2 id="key-benefits"><a class="header" href="#key-benefits">Key Benefits</a></h2>
<h3 id="1-unified-testing-platform"><a class="header" href="#1-unified-testing-platform">1. Unified Testing Platform</a></h3>
<p>QitOps provides a single tool for multiple testing needs:</p>
<ul>
<li><strong>API Testing</strong>: Test individual endpoints and complex API workflows</li>
<li><strong>Performance Testing</strong>: Measure and validate system performance under load</li>
<li><strong>Security Testing</strong>: Identify vulnerabilities and ensure compliance</li>
<li><strong>Web Testing</strong>: Automate browser interactions and validate web applications</li>
<li><strong>Data-Driven Testing</strong>: Run tests with multiple data sets</li>
</ul>
<p>This unified approach eliminates the need for multiple tools and simplifies your testing workflow.</p>
<h3 id="2-cli-first-design"><a class="header" href="#2-cli-first-design">2. CLI-First Design</a></h3>
<p>QitOps is built with a CLI-first philosophy:</p>
<ul>
<li><strong>Developer-Friendly</strong>: Integrates seamlessly with developer workflows</li>
<li><strong>Scriptable</strong>: Easy to automate and integrate with CI/CD pipelines</li>
<li><strong>Lightweight</strong>: No heavy GUI or browser dependencies</li>
<li><strong>Resource-Efficient</strong>: Minimal system requirements</li>
<li><strong>Cross-Platform</strong>: Works on Linux, macOS, and Windows</li>
</ul>
<p>The CLI-first approach makes QitOps ideal for modern development practices like GitOps and DevOps.</p>
<h3 id="3-ai-powered-testing"><a class="header" href="#3-ai-powered-testing">3. AI-Powered Testing</a></h3>
<p>QitOps leverages AI to enhance testing capabilities:</p>
<ul>
<li><strong>Test Generation</strong>: Create test configurations from natural language descriptions</li>
<li><strong>Results Analysis</strong>: Get intelligent insights from test results</li>
<li><strong>Improvement Suggestions</strong>: Receive actionable recommendations to enhance tests</li>
<li><strong>Local LLM Support</strong>: Run AI features completely offline with local models</li>
</ul>
<p>These AI capabilities help you create better tests, understand results more deeply, and continuously improve your testing strategy.</p>
<h3 id="4-git-integration"><a class="header" href="#4-git-integration">4. Git Integration</a></h3>
<p>QitOps is designed to work seamlessly with Git:</p>
<ul>
<li><strong>Version Control</strong>: Store test configurations in Git alongside code</li>
<li><strong>Diff Support</strong>: See changes to test configurations in Git diffs</li>
<li><strong>Branch-Based Testing</strong>: Run different tests on different branches</li>
<li><strong>PR Validation</strong>: Validate changes before merging</li>
</ul>
<p>This Git-centric approach ensures your tests evolve alongside your codebase.</p>
<h3 id="5-comprehensive-reporting"><a class="header" href="#5-comprehensive-reporting">5. Comprehensive Reporting</a></h3>
<p>QitOps provides detailed, actionable reports:</p>
<ul>
<li><strong>Multiple Formats</strong>: Generate reports in JSON, HTML, XML, and CSV</li>
<li><strong>Visual Dashboards</strong>: View test results in interactive dashboards</li>
<li><strong>Trend Analysis</strong>: Track performance and reliability over time</li>
<li><strong>CI/CD Integration</strong>: Seamlessly integrate with CI/CD reporting systems</li>
</ul>
<p>These reporting capabilities help you understand test results and make informed decisions.</p>
<h2 id="comparison-with-other-tools"><a class="header" href="#comparison-with-other-tools">Comparison with Other Tools</a></h2>
<h3 id="qitops-vs-postman"><a class="header" href="#qitops-vs-postman">QitOps vs. Postman</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>QitOps</th><th>Postman</th></tr></thead><tbody>
<tr><td>CLI-First</td><td>✅</td><td>❌ (CLI is secondary)</td></tr>
<tr><td>Resource Usage</td><td>✅ Lightweight</td><td>❌ Heavy Electron app</td></tr>
<tr><td>Git Integration</td><td>✅ Native</td><td>⚠️ Limited</td></tr>
<tr><td>AI Features</td><td>✅ Local &amp; private</td><td>⚠️ Cloud-based only</td></tr>
<tr><td>Performance Testing</td><td>✅ Built-in</td><td>⚠️ Limited</td></tr>
<tr><td>Security Testing</td><td>✅ Built-in</td><td>❌ Requires add-ons</td></tr>
<tr><td>Web Testing</td><td>✅ Built-in</td><td>❌ Not available</td></tr>
<tr><td>Open Source</td><td>✅ MIT License</td><td>❌ Proprietary</td></tr>
</tbody></table>
</div>
<h3 id="qitops-vs-k6"><a class="header" href="#qitops-vs-k6">QitOps vs. k6</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>QitOps</th><th>k6</th></tr></thead><tbody>
<tr><td>API Testing</td><td>✅ Comprehensive</td><td>⚠️ Basic</td></tr>
<tr><td>Performance Testing</td><td>✅ Built-in</td><td>✅ Specialized</td></tr>
<tr><td>Security Testing</td><td>✅ Built-in</td><td>❌ Not available</td></tr>
<tr><td>Web Testing</td><td>✅ Built-in</td><td>⚠️ Limited</td></tr>
<tr><td>AI Features</td><td>✅ Local &amp; private</td><td>❌ Not available</td></tr>
<tr><td>Configuration Format</td><td>✅ JSON (no coding)</td><td>⚠️ JavaScript</td></tr>
<tr><td>Learning Curve</td><td>✅ Low</td><td>⚠️ Moderate</td></tr>
<tr><td>Open Source</td><td>✅ MIT License</td><td>✅ AGPL License</td></tr>
</tbody></table>
</div>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<h3 id="devops-and-cicd-integration"><a class="header" href="#devops-and-cicd-integration">DevOps and CI/CD Integration</a></h3>
<p>QitOps is ideal for DevOps workflows:</p>
<ul>
<li>Run automated tests as part of CI/CD pipelines</li>
<li>Validate API changes before deployment</li>
<li>Ensure performance meets requirements</li>
<li>Identify security vulnerabilities early</li>
<li>Generate test reports for review</li>
</ul>
<h3 id="api-development-and-testing"><a class="header" href="#api-development-and-testing">API Development and Testing</a></h3>
<p>QitOps provides comprehensive API testing capabilities:</p>
<ul>
<li>Test individual endpoints and complex workflows</li>
<li>Validate response status, headers, and body</li>
<li>Measure and validate performance</li>
<li>Identify security vulnerabilities</li>
<li>Generate documentation from tests</li>
</ul>
<h3 id="quality-assurance"><a class="header" href="#quality-assurance">Quality Assurance</a></h3>
<p>QitOps helps QA teams ensure software quality:</p>
<ul>
<li>Create and run comprehensive test suites</li>
<li>Automate repetitive testing tasks</li>
<li>Generate detailed test reports</li>
<li>Track quality metrics over time</li>
<li>Identify and address issues early</li>
</ul>
<h3 id="security-validation"><a class="header" href="#security-validation">Security Validation</a></h3>
<p>QitOps includes security testing features:</p>
<ul>
<li>Scan for common vulnerabilities (OWASP Top 10)</li>
<li>Check for secure headers and SSL/TLS configuration</li>
<li>Detect sensitive data exposure</li>
<li>Validate authentication and authorization mechanisms</li>
<li>Generate security compliance reports</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>Ready to try QitOps? Check out the <a href="installation.html">Installation</a> guide and <a href="quick-start.html">Quick Start</a> tutorial to begin your journey with QitOps.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation-1"><a class="header" href="#installation-1">Installation</a></h1>
<p>QitOps is available for Linux, macOS, and Windows. This guide covers various installation methods to help you get started quickly.</p>
<h2 id="system-requirements"><a class="header" href="#system-requirements">System Requirements</a></h2>
<ul>
<li><strong>Operating System</strong>: Linux, macOS, or Windows</li>
<li><strong>Disk Space</strong>: 50MB minimum</li>
<li><strong>Memory</strong>: 256MB minimum (2GB+ recommended for AI features)</li>
<li><strong>Dependencies</strong>: None (self-contained binary)</li>
</ul>
<h2 id="quick-installation"><a class="header" href="#quick-installation">Quick Installation</a></h2>
<h3 id="using-the-install-script-linuxmacos"><a class="header" href="#using-the-install-script-linuxmacos">Using the Install Script (Linux/macOS)</a></h3>
<p>The easiest way to install QitOps is using our install script:</p>
<pre><code class="language-bash">curl -sSL https://get.qitops.dev | bash
</code></pre>
<p>This script will download the latest version of QitOps and install it to <code>/usr/local/bin/qitops</code>.</p>
<h3 id="manual-installation"><a class="header" href="#manual-installation">Manual Installation</a></h3>
<h4 id="linux"><a class="header" href="#linux">Linux</a></h4>
<pre><code class="language-bash"># Download the latest release
curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o qitops

# Make it executable
chmod +x qitops

# Move to a directory in your PATH
sudo mv qitops /usr/local/bin/
</code></pre>
<h4 id="macos"><a class="header" href="#macos">macOS</a></h4>
<pre><code class="language-bash"># Download the latest release
curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-macos-x86_64 -o qitops

# Make it executable
chmod +x qitops

# Move to a directory in your PATH
sudo mv qitops /usr/local/bin/
</code></pre>
<h4 id="windows"><a class="header" href="#windows">Windows</a></h4>
<pre><code class="language-powershell"># Download the latest release
Invoke-WebRequest -Uri https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-windows-x86_64.exe -OutFile qitops.exe

# Move to a directory in your PATH
Move-Item -Path qitops.exe -Destination "$env:USERPROFILE\AppData\Local\Microsoft\WindowsApps\"
</code></pre>
<h2 id="package-managers"><a class="header" href="#package-managers">Package Managers</a></h2>
<h3 id="homebrew-macoslinux"><a class="header" href="#homebrew-macoslinux">Homebrew (macOS/Linux)</a></h3>
<pre><code class="language-bash">brew tap qitops/qitops
brew install qitops
</code></pre>
<h3 id="scoop-windows"><a class="header" href="#scoop-windows">Scoop (Windows)</a></h3>
<pre><code class="language-powershell">scoop bucket add qitops https://github.com/qitops/scoop-bucket.git
scoop install qitops
</code></pre>
<h3 id="apt-debianubuntu"><a class="header" href="#apt-debianubuntu">APT (Debian/Ubuntu)</a></h3>
<pre><code class="language-bash"># Add the QitOps repository
echo "deb [trusted=yes] https://apt.qitops.dev/ stable main" | sudo tee /etc/apt/sources.list.d/qitops.list

# Update package list
sudo apt update

# Install QitOps
sudo apt install qitops
</code></pre>
<h3 id="yumdnf-rhelfedoracentos"><a class="header" href="#yumdnf-rhelfedoracentos">YUM/DNF (RHEL/Fedora/CentOS)</a></h3>
<pre><code class="language-bash"># Add the QitOps repository
sudo tee /etc/yum.repos.d/qitops.repo &lt;&lt; EOF
[qitops]
name=QitOps Repository
baseurl=https://yum.qitops.dev/
enabled=1
gpgcheck=0
EOF

# Install QitOps
sudo yum install qitops
</code></pre>
<h3 id="npm-cross-platform"><a class="header" href="#npm-cross-platform">NPM (Cross-platform)</a></h3>
<pre><code class="language-bash">npm install -g qitops
</code></pre>
<h2 id="docker"><a class="header" href="#docker">Docker</a></h2>
<p>QitOps is also available as a Docker image:</p>
<pre><code class="language-bash"># Pull the latest image
docker pull qitops/qitops:latest

# Run QitOps
docker run --rm qitops/qitops:latest --version

# Run QitOps with mounted configuration
docker run --rm -v $(pwd)/tests:/tests qitops/qitops:latest api -c /tests/configs/api_test.json
</code></pre>
<h2 id="building-from-source-1"><a class="header" href="#building-from-source-1">Building from Source</a></h2>
<p>If you prefer to build QitOps from source:</p>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/qitops/qitops-cli-tools.git
cd qitops-cli-tools

# Build the binary
make build

# Install the binary
make install
</code></pre>
<h2 id="verifying-the-installation"><a class="header" href="#verifying-the-installation">Verifying the Installation</a></h2>
<p>After installation, verify that QitOps is installed correctly:</p>
<pre><code class="language-bash">qitops --version
</code></pre>
<p>You should see output similar to:</p>
<pre><code>QitOps CLI v1.0.0
</code></pre>
<h2 id="updating-qitops"><a class="header" href="#updating-qitops">Updating QitOps</a></h2>
<h3 id="using-the-update-command"><a class="header" href="#using-the-update-command">Using the Update Command</a></h3>
<p>QitOps includes a self-update feature:</p>
<pre><code class="language-bash">qitops update
</code></pre>
<h3 id="manual-update"><a class="header" href="#manual-update">Manual Update</a></h3>
<p>To update manually, simply download and install the latest version using the same method you used for the initial installation.</p>
<h2 id="uninstalling-qitops"><a class="header" href="#uninstalling-qitops">Uninstalling QitOps</a></h2>
<h3 id="linuxmacos"><a class="header" href="#linuxmacos">Linux/macOS</a></h3>
<pre><code class="language-bash">sudo rm /usr/local/bin/qitops
</code></pre>
<h3 id="windows-1"><a class="header" href="#windows-1">Windows</a></h3>
<pre><code class="language-powershell">Remove-Item "$env:USERPROFILE\AppData\Local\Microsoft\WindowsApps\qitops.exe"
</code></pre>
<h3 id="package-managers-1"><a class="header" href="#package-managers-1">Package Managers</a></h3>
<h4 id="homebrew"><a class="header" href="#homebrew">Homebrew</a></h4>
<pre><code class="language-bash">brew uninstall qitops
</code></pre>
<h4 id="scoop"><a class="header" href="#scoop">Scoop</a></h4>
<pre><code class="language-powershell">scoop uninstall qitops
</code></pre>
<h4 id="apt"><a class="header" href="#apt">APT</a></h4>
<pre><code class="language-bash">sudo apt remove qitops
</code></pre>
<h4 id="yumdnf"><a class="header" href="#yumdnf">YUM/DNF</a></h4>
<pre><code class="language-bash">sudo yum remove qitops
</code></pre>
<h4 id="npm"><a class="header" href="#npm">NPM</a></h4>
<pre><code class="language-bash">npm uninstall -g qitops
</code></pre>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="common-issues-1"><a class="header" href="#common-issues-1">Common Issues</a></h3>
<h4 id="permission-denied"><a class="header" href="#permission-denied">Permission Denied</a></h4>
<p>If you see a “permission denied” error when running QitOps:</p>
<pre><code class="language-bash">chmod +x /path/to/qitops
</code></pre>
<h4 id="command-not-found"><a class="header" href="#command-not-found">Command Not Found</a></h4>
<p>If you see a “command not found” error:</p>
<ol>
<li>Make sure QitOps is installed in a directory in your PATH</li>
<li>Try using the full path to the binary: <code>/usr/local/bin/qitops</code></li>
</ol>
<h4 id="ssl-certificate-errors"><a class="header" href="#ssl-certificate-errors">SSL Certificate Errors</a></h4>
<p>If you see SSL certificate errors when downloading:</p>
<pre><code class="language-bash">curl -sSL --insecure https://get.qitops.dev | bash
</code></pre>
<h4 id="proxy-issues"><a class="header" href="#proxy-issues">Proxy Issues</a></h4>
<p>If you’re behind a proxy:</p>
<pre><code class="language-bash">export HTTP_PROXY=http://proxy.example.com:8080
export HTTPS_PROXY=http://proxy.example.com:8080
curl -sSL https://get.qitops.dev | bash
</code></pre>
<h3 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h3>
<p>If you encounter any issues during installation:</p>
<ul>
<li>Check the <a href="https://docs.qitops.dev/troubleshooting">Troubleshooting Guide</a></li>
<li>Join our <a href="https://discord.gg/qitops">Discord Community</a></li>
<li>Open an issue on <a href="https://github.com/qitops/qitops-cli-tools/issues">GitHub</a></li>
</ul>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Now that you have QitOps installed, check out the <a href="quick-start.html">Quick Start</a> guide to learn how to use it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h1>
<p>This guide will help you get started with QitOps quickly. You’ll learn how to run your first tests and understand the basic workflow.</p>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<p>Before you begin, make sure you have:</p>
<ul>
<li>QitOps installed (see <a href="installation.html">Installation</a>)</li>
<li>A target API or web application to test</li>
<li>Basic understanding of HTTP requests and responses</li>
</ul>
<h2 id="your-first-api-test"><a class="header" href="#your-first-api-test">Your First API Test</a></h2>
<p>Let’s start with a simple API test to verify that a public API is working correctly.</p>
<h3 id="1-create-a-test-configuration"><a class="header" href="#1-create-a-test-configuration">1. Create a Test Configuration</a></h3>
<p>Create a file named <code>github_api_test.json</code> with the following content:</p>
<pre><code class="language-json">{
  "name": "GitHub API Test",
  "description": "Test the GitHub API to fetch user information",
  "url": "https://api.github.com/users/octocat",
  "method": "GET",
  "headers": {
    "Accept": "application/vnd.github.v3+json",
    "User-Agent": "QitOps-Test"
  },
  "expected_status": 200,
  "expected_body": {
    "login": "octocat",
    "type": "User"
  }
}
</code></pre>
<p>This configuration defines a test that:</p>
<ul>
<li>Makes a GET request to the GitHub API</li>
<li>Expects a 200 status code</li>
<li>Validates that the response contains specific fields</li>
</ul>
<h3 id="2-run-the-test"><a class="header" href="#2-run-the-test">2. Run the Test</a></h3>
<p>Run the test using the QitOps CLI:</p>
<pre><code class="language-bash">qitops api -c github_api_test.json
</code></pre>
<p>You should see output similar to:</p>
<pre><code>Running API test: GitHub API Test
✓ Status code is 200
✓ Response body contains expected fields
✓ Test completed successfully in 0.324s
</code></pre>
<h3 id="3-generate-a-report"><a class="header" href="#3-generate-a-report">3. Generate a Report</a></h3>
<p>Generate a detailed report of the test results:</p>
<pre><code class="language-bash">qitops api -c github_api_test.json -r html -o github_test_report.html
</code></pre>
<p>This command runs the test and generates an HTML report with detailed information about the request, response, and validation results.</p>
<h2 id="testing-an-api-collection"><a class="header" href="#testing-an-api-collection">Testing an API Collection</a></h2>
<p>Now let’s create a collection of related API tests.</p>
<h3 id="1-create-a-collection-configuration"><a class="header" href="#1-create-a-collection-configuration">1. Create a Collection Configuration</a></h3>
<p>Create a file named <code>github_api_collection.json</code> with the following content:</p>
<pre><code class="language-json">{
  "name": "GitHub API Collection",
  "description": "A collection of GitHub API tests",
  "variables": {
    "base_url": "https://api.github.com",
    "username": "octocat"
  },
  "defaults": {
    "headers": {
      "Accept": "application/vnd.github.v3+json",
      "User-Agent": "QitOps-Test"
    }
  },
  "requests": [
    {
      "name": "Get User",
      "id": "get-user",
      "url": "{{base_url}}/users/{{username}}",
      "method": "GET",
      "expected_status": 200,
      "capture": {
        "repos_url": "$.repos_url"
      }
    },
    {
      "name": "Get User Repos",
      "id": "get-repos",
      "url": "{{repos_url}}",
      "method": "GET",
      "depends_on": ["get-user"],
      "expected_status": 200
    }
  ]
}
</code></pre>
<p>This collection defines:</p>
<ul>
<li>Variables that can be reused across requests</li>
<li>Default headers for all requests</li>
<li>Two related requests, where the second depends on the first</li>
<li>Data capture from the first request to use in the second</li>
</ul>
<h3 id="2-run-the-collection"><a class="header" href="#2-run-the-collection">2. Run the Collection</a></h3>
<p>Run the collection using the QitOps CLI:</p>
<pre><code class="language-bash">qitops collection -c github_api_collection.json
</code></pre>
<p>You should see output showing the execution of each request in the collection.</p>
<h2 id="running-a-performance-test"><a class="header" href="#running-a-performance-test">Running a Performance Test</a></h2>
<p>Let’s run a simple performance test to measure the response time of an API.</p>
<h3 id="1-create-a-performance-test-configuration"><a class="header" href="#1-create-a-performance-test-configuration">1. Create a Performance Test Configuration</a></h3>
<p>Create a file named <code>performance_test.json</code> with the following content:</p>
<pre><code class="language-json">{
  "name": "GitHub API Performance Test",
  "description": "Test the performance of the GitHub API",
  "target_url": "https://api.github.com/users/octocat",
  "method": "GET",
  "headers": {
    "Accept": "application/vnd.github.v3+json",
    "User-Agent": "QitOps-Test"
  },
  "concurrent_users": 10,
  "duration_secs": 30,
  "ramp_up_time_secs": 5,
  "success_threshold": 95.0,
  "max_response_time_ms": 500
}
</code></pre>
<p>This configuration defines a performance test that:</p>
<ul>
<li>Simulates 10 concurrent users</li>
<li>Runs for 30 seconds</li>
<li>Gradually ramps up to full load over 5 seconds</li>
<li>Expects a 95% success rate</li>
<li>Expects a maximum response time of 500ms</li>
</ul>
<h3 id="2-run-the-performance-test"><a class="header" href="#2-run-the-performance-test">2. Run the Performance Test</a></h3>
<p>Run the performance test using the QitOps CLI:</p>
<pre><code class="language-bash">qitops performance -c performance_test.json
</code></pre>
<p>You should see output showing real-time metrics during the test and a summary at the end.</p>
<h2 id="using-ai-features"><a class="header" href="#using-ai-features">Using AI Features</a></h2>
<p>QitOps includes AI features that can help you create and improve tests.</p>
<h3 id="1-generate-a-test-configuration"><a class="header" href="#1-generate-a-test-configuration">1. Generate a Test Configuration</a></h3>
<p>Generate a test configuration from a natural language description:</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test the GitHub API to fetch user information for 'octocat' and verify the response contains the correct login name and user type" --output generated_test.json
</code></pre>
<p>This command uses AI to generate a test configuration based on your description.</p>
<h3 id="2-analyze-test-results"><a class="header" href="#2-analyze-test-results">2. Analyze Test Results</a></h3>
<p>Run a test and analyze the results:</p>
<pre><code class="language-bash"># Run a test and save the results
qitops api -c github_api_test.json -r json -o test_results.json

# Analyze the results
qitops analyze --results test_results.json --output analysis.md
</code></pre>
<p>The analysis will provide insights into the test results and identify any patterns or issues.</p>
<h3 id="3-get-improvement-suggestions"><a class="header" href="#3-get-improvement-suggestions">3. Get Improvement Suggestions</a></h3>
<p>Get suggestions for improving your tests:</p>
<pre><code class="language-bash">qitops improve --results test_results.json --output improvements.md
</code></pre>
<p>The suggestions will help you enhance your tests for better coverage and reliability.</p>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Now that you’ve run your first tests with QitOps, you can explore more advanced features:</p>
<ul>
<li><a href="api-testing.html">API Testing</a>: Learn more about API testing capabilities</li>
<li><a href="api-collections.html">API Collections</a>: Create complex API test workflows</li>
<li><a href="performance-testing.html">Performance Testing</a>: Measure and validate system performance</li>
<li><a href="security-testing.html">Security Testing</a>: Identify vulnerabilities and ensure compliance</li>
<li><a href="web-testing.html">Web Testing</a>: Automate browser interactions and validate web applications</li>
<li><a href="data-driven-testing.html">Data-Driven Testing</a>: Run tests with multiple data sets</li>
<li><a href="ai-features.html">AI Features</a>: Leverage AI to enhance your testing workflow</li>
</ul>
<p>For a complete reference of all QitOps commands and options, see the <a href="usage.html">Usage Guide</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-testing-5"><a class="header" href="#api-testing-5">API Testing</a></h1>
<p>QitOps provides comprehensive API testing capabilities that allow you to validate REST APIs, ensure correct functionality, and verify performance and reliability.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>API testing in QitOps allows you to:</p>
<ul>
<li>Test individual API endpoints with various HTTP methods</li>
<li>Validate response status codes, headers, and body content</li>
<li>Set up authentication and authorization</li>
<li>Measure and validate response times</li>
<li>Configure timeouts and retries for reliability</li>
<li>Chain requests with data from previous responses</li>
</ul>
<h2 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h2>
<h3 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h3>
<pre><code class="language-bash"># Run a single API test
qitops api -c tests/configs/api_test.json

# Run tests in a specific environment
qitops api -c tests/configs/api_test.json -e production

# Run with custom variables
qitops api -c tests/configs/api_test.json -v base_url=https://api.example.com -v api_key=12345
</code></pre>
<h3 id="command-line-options-1"><a class="header" href="#command-line-options-1">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>-c, --config &lt;FILE&gt;</code></td><td>API test configuration file</td></tr>
<tr><td><code>-e, --environment &lt;ENV&gt;</code></td><td>Environment to use (default: production)</td></tr>
<tr><td><code>-v, --variable &lt;KEY=VALUE&gt;</code></td><td>Set a variable for the test</td></tr>
<tr><td><code>--timeout &lt;SECONDS&gt;</code></td><td>Override timeout in seconds</td></tr>
<tr><td><code>--retries &lt;NUMBER&gt;</code></td><td>Override number of retries</td></tr>
<tr><td><code>-r, --report &lt;FORMAT&gt;</code></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td><code>-o, --output &lt;FILE&gt;</code></td><td>Output file for the report</td></tr>
<tr><td><code>--verbose</code></td><td>Enable verbose output</td></tr>
</tbody></table>
</div>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<p>API tests are defined in JSON configuration files that specify the endpoint, method, headers, and expected responses.</p>
<h3 id="basic-configuration-structure"><a class="header" href="#basic-configuration-structure">Basic Configuration Structure</a></h3>
<pre><code class="language-json">{
  "name": "Example API Test",
  "description": "Test description",
  "timeout": 30,
  "retries": 3,
  "environment": "production",
  "url": "https://api.example.com/users/123",
  "method": "GET",
  "headers": {
    "Accept": "application/json",
    "User-Agent": "QitOps-Test"
  },
  "expected_status": 200,
  "expected_body": {
    "id": 123,
    "name": "John Doe"
  },
  "max_response_time": 2,
  "expected_headers": {
    "content-type": "application/json",
    "cache-control": "no-cache"
  }
}
</code></pre>
<h3 id="configuration-fields"><a class="header" href="#configuration-fields">Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Yes</td><td>Name of the test</td></tr>
<tr><td>description</td><td>string</td><td>No</td><td>Description of the test</td></tr>
<tr><td>timeout</td><td>number</td><td>No</td><td>Request timeout in seconds (default: 30)</td></tr>
<tr><td>retries</td><td>number</td><td>No</td><td>Number of retries (default: 3)</td></tr>
<tr><td>environment</td><td>string</td><td>No</td><td>Environment to use (default: production)</td></tr>
<tr><td>url</td><td>string</td><td>Yes</td><td>URL to test</td></tr>
<tr><td>method</td><td>string</td><td>Yes</td><td>HTTP method (GET, POST, PUT, DELETE, etc.)</td></tr>
<tr><td>headers</td><td>object</td><td>No</td><td>HTTP headers to send</td></tr>
<tr><td>body</td><td>object/string</td><td>No</td><td>Request body (JSON object or string)</td></tr>
<tr><td>expected_status</td><td>number</td><td>No</td><td>Expected HTTP status code (default: 200)</td></tr>
<tr><td>expected_body</td><td>object/string</td><td>No</td><td>Expected response body (JSON object or string)</td></tr>
<tr><td>max_response_time</td><td>number</td><td>No</td><td>Maximum acceptable response time in seconds</td></tr>
<tr><td>expected_headers</td><td>object</td><td>No</td><td>Expected response headers</td></tr>
<tr><td>retry</td><td>object</td><td>No</td><td>Retry configuration</td></tr>
</tbody></table>
</div>
<h3 id="authentication"><a class="header" href="#authentication">Authentication</a></h3>
<p>QitOps supports various authentication methods:</p>
<h4 id="basic-authentication"><a class="header" href="#basic-authentication">Basic Authentication</a></h4>
<pre><code class="language-json">"auth": {
  "type": "basic",
  "username": "user",
  "password": "pass"
}
</code></pre>
<h4 id="bearer-token"><a class="header" href="#bearer-token">Bearer Token</a></h4>
<pre><code class="language-json">"auth": {
  "type": "bearer",
  "token": "your-token"
}
</code></pre>
<h4 id="api-key"><a class="header" href="#api-key">API Key</a></h4>
<pre><code class="language-json">"auth": {
  "type": "apikey",
  "key": "X-API-Key",
  "value": "your-api-key",
  "in": "header"  // or "query"
}
</code></pre>
<h4 id="oauth2"><a class="header" href="#oauth2">OAuth2</a></h4>
<pre><code class="language-json">"auth": {
  "type": "oauth2",
  "token_url": "https://auth.example.com/token",
  "client_id": "your-client-id",
  "client_secret": "your-client-secret",
  "scope": "read write"
}
</code></pre>
<h3 id="request-body"><a class="header" href="#request-body">Request Body</a></h3>
<p>You can specify the request body in different formats:</p>
<h4 id="json-body"><a class="header" href="#json-body">JSON Body</a></h4>
<pre><code class="language-json">"body": {
  "name": "John Doe",
  "email": "john@example.com",
  "age": 30
}
</code></pre>
<h4 id="string-body"><a class="header" href="#string-body">String Body</a></h4>
<pre><code class="language-json">"body": "name=John%20Doe&amp;email=john%40example.com",
"headers": {
  "Content-Type": "application/x-www-form-urlencoded"
}
</code></pre>
<h4 id="binary-body"><a class="header" href="#binary-body">Binary Body</a></h4>
<pre><code class="language-json">"body": {
  "_file": "path/to/file.pdf"
},
"headers": {
  "Content-Type": "application/pdf"
}
</code></pre>
<h3 id="response-validation"><a class="header" href="#response-validation">Response Validation</a></h3>
<p>QitOps provides several ways to validate API responses:</p>
<h4 id="status-code"><a class="header" href="#status-code">Status Code</a></h4>
<pre><code class="language-json">"expected_status": 200
</code></pre>
<h4 id="headers"><a class="header" href="#headers">Headers</a></h4>
<pre><code class="language-json">"expected_headers": {
  "content-type": "application/json",
  "cache-control": "no-cache"
}
</code></pre>
<h4 id="body-exact-match"><a class="header" href="#body-exact-match">Body (Exact Match)</a></h4>
<pre><code class="language-json">"expected_body": {
  "id": 123,
  "name": "John Doe"
}
</code></pre>
<h4 id="body-partial-match"><a class="header" href="#body-partial-match">Body (Partial Match)</a></h4>
<pre><code class="language-json">"expected_body_contains": {
  "name": "John Doe"
}
</code></pre>
<h4 id="json-schema-validation"><a class="header" href="#json-schema-validation">JSON Schema Validation</a></h4>
<pre><code class="language-json">"validate_json_schema": {
  "type": "object",
  "required": ["id", "name"],
  "properties": {
    "id": { "type": "integer" },
    "name": { "type": "string" }
  }
}
</code></pre>
<h4 id="jsonpath-assertions"><a class="header" href="#jsonpath-assertions">JSONPath Assertions</a></h4>
<pre><code class="language-json">"assertions": [
  {
    "jsonpath": "$.name",
    "expected": "John Doe",
    "comparison": "equals"
  },
  {
    "jsonpath": "$.age",
    "expected": 18,
    "comparison": "greater_than"
  }
]
</code></pre>
<h3 id="retry-configuration-1"><a class="header" href="#retry-configuration-1">Retry Configuration</a></h3>
<p>Configure retry behavior for transient failures:</p>
<pre><code class="language-json">"retry": {
  "max_retries": 3,
  "initial_delay_ms": 100,
  "max_delay_ms": 1000,
  "retry_status_codes": [408, 429, 500, 502, 503, 504],
  "retry_on_timeout": true,
  "retry_on_connection_error": true
}
</code></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="get-request"><a class="header" href="#get-request">GET Request</a></h3>
<pre><code class="language-json">{
  "name": "Get User",
  "description": "Get a user by ID",
  "url": "https://api.example.com/users/123",
  "method": "GET",
  "headers": {
    "Accept": "application/json"
  },
  "expected_status": 200,
  "expected_body": {
    "id": 123,
    "name": "John Doe",
    "email": "john@example.com"
  }
}
</code></pre>
<h3 id="post-request"><a class="header" href="#post-request">POST Request</a></h3>
<pre><code class="language-json">{
  "name": "Create User",
  "description": "Create a new user",
  "url": "https://api.example.com/users",
  "method": "POST",
  "headers": {
    "Content-Type": "application/json",
    "Accept": "application/json"
  },
  "body": {
    "name": "Jane Doe",
    "email": "jane@example.com",
    "age": 28
  },
  "expected_status": 201,
  "expected_body_contains": {
    "id": true,
    "name": "Jane Doe"
  }
}
</code></pre>
<h3 id="put-request"><a class="header" href="#put-request">PUT Request</a></h3>
<pre><code class="language-json">{
  "name": "Update User",
  "description": "Update an existing user",
  "url": "https://api.example.com/users/123",
  "method": "PUT",
  "headers": {
    "Content-Type": "application/json",
    "Accept": "application/json"
  },
  "body": {
    "name": "John Smith",
    "email": "john.smith@example.com"
  },
  "expected_status": 200,
  "expected_body": {
    "id": 123,
    "name": "John Smith",
    "email": "john.smith@example.com"
  }
}
</code></pre>
<h3 id="delete-request"><a class="header" href="#delete-request">DELETE Request</a></h3>
<pre><code class="language-json">{
  "name": "Delete User",
  "description": "Delete a user",
  "url": "https://api.example.com/users/123",
  "method": "DELETE",
  "expected_status": 204
}
</code></pre>
<h3 id="authentication-example"><a class="header" href="#authentication-example">Authentication Example</a></h3>
<pre><code class="language-json">{
  "name": "Authenticated Request",
  "description": "Make an authenticated API request",
  "url": "https://api.example.com/protected-resource",
  "method": "GET",
  "auth": {
    "type": "bearer",
    "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
  },
  "expected_status": 200
}
</code></pre>
<h3 id="file-upload"><a class="header" href="#file-upload">File Upload</a></h3>
<pre><code class="language-json">{
  "name": "Upload File",
  "description": "Upload a file to the API",
  "url": "https://api.example.com/upload",
  "method": "POST",
  "headers": {
    "Content-Type": "multipart/form-data"
  },
  "form_data": {
    "file": {
      "_file": "path/to/file.jpg"
    },
    "description": "Profile picture"
  },
  "expected_status": 200,
  "expected_body_contains": {
    "success": true
  }
}
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="test-organization"><a class="header" href="#test-organization">Test Organization</a></h3>
<ul>
<li>Group related tests in separate configuration files</li>
<li>Use descriptive names for tests</li>
<li>Include detailed descriptions</li>
<li>Organize tests by functionality or endpoint</li>
</ul>
<h3 id="reliability"><a class="header" href="#reliability">Reliability</a></h3>
<ul>
<li>Set appropriate timeouts based on expected response times</li>
<li>Configure retries for transient failures</li>
<li>Use environment-specific configurations</li>
<li>Validate both success and error scenarios</li>
</ul>
<h3 id="validation"><a class="header" href="#validation">Validation</a></h3>
<ul>
<li>Validate status codes, headers, and body content</li>
<li>Use JSON schema validation for complex responses</li>
<li>Include performance assertions (max_response_time)</li>
<li>Test edge cases and boundary conditions</li>
</ul>
<h3 id="variables-and-environments"><a class="header" href="#variables-and-environments">Variables and Environments</a></h3>
<ul>
<li>Use variables for values that change between environments</li>
<li>Create environment-specific configurations</li>
<li>Avoid hardcoding sensitive information</li>
<li>Use variable interpolation for dynamic values</li>
</ul>
<h2 id="integration-with-cicd"><a class="header" href="#integration-with-cicd">Integration with CI/CD</a></h2>
<p>API tests can be integrated into CI/CD pipelines:</p>
<pre><code class="language-yaml"># Example GitHub Actions workflow step
- name: Run API Tests
  run: |
    qitops api -c tests/configs/api_test.json -e staging --report json --output api-test-results.json
    
- name: Upload Test Results
  uses: actions/upload-artifact@v2
  with:
    name: api-test-results
    path: api-test-results.json
</code></pre>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="common-issues-2"><a class="header" href="#common-issues-2">Common Issues</a></h3>
<ul>
<li><strong>Connection Refused</strong>: Check if the API server is running and accessible</li>
<li><strong>Timeout Errors</strong>: Increase the timeout value or check server performance</li>
<li><strong>Authentication Failures</strong>: Verify credentials and token expiration</li>
<li><strong>Unexpected Responses</strong>: Check if the API contract has changed</li>
<li><strong>SSL/TLS Errors</strong>: Verify certificate validity and trust chain</li>
</ul>
<h3 id="debugging-tips"><a class="header" href="#debugging-tips">Debugging Tips</a></h3>
<ul>
<li>Use the <code>--verbose</code> flag for detailed output</li>
<li>Check the request and response headers</li>
<li>Verify the request body is correctly formatted</li>
<li>Test the API endpoint with a tool like curl or Postman</li>
<li>Check for environment-specific issues</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-collections-5"><a class="header" href="#api-collections-5">API Collections</a></h1>
<p>QitOps provides powerful API collection capabilities that allow you to group related API requests, chain them together, and create complex test workflows.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>API collections in QitOps allow you to:</p>
<ul>
<li>Group related API requests into a single collection</li>
<li>Share variables and authentication across requests</li>
<li>Capture data from responses to use in subsequent requests</li>
<li>Define dependencies between requests</li>
<li>Set up pre-request and post-request scripts</li>
<li>Configure environment-specific variables</li>
<li>Run collections sequentially or in parallel</li>
</ul>
<h2 id="getting-started-2"><a class="header" href="#getting-started-2">Getting Started</a></h2>
<h3 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h3>
<pre><code class="language-bash"># Run an API collection
qitops collection -c tests/configs/api_collection.json

# Run with environment variables
qitops collection -c tests/configs/api_collection.json -v API_KEY=your-api-key

# Run with a specific environment
qitops collection -c tests/configs/api_collection.json -e staging
</code></pre>
<h3 id="command-line-options-2"><a class="header" href="#command-line-options-2">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>-c, --config &lt;FILE&gt;</code></td><td>API collection configuration file</td></tr>
<tr><td><code>-e, --environment &lt;ENV&gt;</code></td><td>Environment to use (default: production)</td></tr>
<tr><td><code>-v, --variable &lt;KEY=VALUE&gt;</code></td><td>Set a variable for the collection</td></tr>
<tr><td><code>--sequential</code></td><td>Run requests sequentially (default)</td></tr>
<tr><td><code>--parallel</code></td><td>Run requests in parallel where possible</td></tr>
<tr><td><code>--stop-on-failure</code></td><td>Stop execution after the first failure</td></tr>
<tr><td><code>--delay &lt;MILLISECONDS&gt;</code></td><td>Delay between requests in milliseconds</td></tr>
<tr><td><code>-r, --report &lt;FORMAT&gt;</code></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td><code>-o, --output &lt;FILE&gt;</code></td><td>Output file for the report</td></tr>
</tbody></table>
</div>
<h2 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h2>
<p>API collections are defined in JSON configuration files that specify the requests, variables, and execution options.</p>
<h3 id="basic-configuration-structure-1"><a class="header" href="#basic-configuration-structure-1">Basic Configuration Structure</a></h3>
<pre><code class="language-json">{
  "name": "GitHub API Collection",
  "description": "A collection of GitHub API tests",
  "version": "1.0.0",
  "variables": {
    "base_url": "https://api.github.com",
    "username": "octocat",
    "repo": "Hello-World"
  },
  "auth": {
    "type": "bearer",
    "token": "{{GITHUB_TOKEN}}"
  },
  "defaults": {
    "headers": {
      "Accept": "application/vnd.github.v3+json",
      "User-Agent": "QitOps-Test"
    },
    "timeout": 30,
    "retries": 3
  },
  "requests": [
    {
      "name": "Get User",
      "description": "Get a GitHub user",
      "id": "get-user",
      "url": "{{base_url}}/users/{{username}}",
      "method": "GET",
      "expected_status": 200,
      "expected_body": {
        "login": "{{username}}",
        "type": "User"
      },
      "capture": {
        "user_id": "$.id",
        "user_url": "$.url"
      }
    },
    {
      "name": "Get User Repos",
      "description": "Get repositories for a user",
      "id": "get-user-repos",
      "url": "{{user_url}}/repos",
      "method": "GET",
      "depends_on": ["get-user"],
      "expected_status": 200
    }
  ],
  "environments": {
    "production": {
      "base_url": "https://api.github.com"
    },
    "staging": {
      "base_url": "https://api.staging.github.com"
    }
  },
  "run_options": {
    "sequential": true,
    "stop_on_failure": true,
    "delay_between_requests_ms": 500
  }
}
</code></pre>
<h3 id="configuration-fields-1"><a class="header" href="#configuration-fields-1">Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Yes</td><td>Name of the collection</td></tr>
<tr><td>description</td><td>string</td><td>No</td><td>Description of the collection</td></tr>
<tr><td>version</td><td>string</td><td>No</td><td>Version of the collection</td></tr>
<tr><td>variables</td><td>object</td><td>No</td><td>Variables to use in the collection</td></tr>
<tr><td>auth</td><td>object</td><td>No</td><td>Authentication configuration</td></tr>
<tr><td>defaults</td><td>object</td><td>No</td><td>Default values for all requests</td></tr>
<tr><td>requests</td><td>array</td><td>Yes</td><td>Array of request objects</td></tr>
<tr><td>environments</td><td>object</td><td>No</td><td>Environment-specific variables</td></tr>
<tr><td>run_options</td><td>object</td><td>No</td><td>Options for running the collection</td></tr>
</tbody></table>
</div>
<h3 id="request-configuration"><a class="header" href="#request-configuration">Request Configuration</a></h3>
<p>Each request in a collection has the following structure:</p>
<pre><code class="language-json">{
  "name": "Get User",
  "description": "Get a GitHub user",
  "id": "get-user",
  "url": "{{base_url}}/users/{{username}}",
  "method": "GET",
  "headers": {
    "Accept": "application/json"
  },
  "body": {
    "param1": "value1",
    "param2": "value2"
  },
  "expected_status": 200,
  "expected_body": {
    "login": "{{username}}",
    "type": "User"
  },
  "expected_headers": {
    "content-type": "application/json"
  },
  "capture": {
    "user_id": "$.id",
    "user_url": "$.url"
  },
  "depends_on": ["another-request-id"],
  "skip_if": "{{condition}}",
  "pre_request_script": "// JavaScript code to run before the request",
  "post_request_script": "// JavaScript code to run after the request"
}
</code></pre>
<h3 id="variable-interpolation"><a class="header" href="#variable-interpolation">Variable Interpolation</a></h3>
<p>QitOps supports variable interpolation in collection configurations:</p>
<ul>
<li><strong>Collection Variables</strong>: <code>{{variable_name}}</code></li>
<li><strong>Environment Variables</strong>: <code>{{ENV_VARIABLE}}</code></li>
<li><strong>Captured Variables</strong>: <code>{{captured_variable}}</code></li>
<li><strong>System Variables</strong>: <code>{{$timestamp}}</code>, <code>{{$random}}</code></li>
</ul>
<h3 id="data-capture"><a class="header" href="#data-capture">Data Capture</a></h3>
<p>You can capture data from responses to use in subsequent requests:</p>
<pre><code class="language-json">"capture": {
  "user_id": "$.id",
  "user_url": "$.url",
  "token": "$.headers.authorization",
  "status": "$.status"
}
</code></pre>
<p>QitOps uses JSONPath expressions to extract data from responses.</p>
<h3 id="request-dependencies"><a class="header" href="#request-dependencies">Request Dependencies</a></h3>
<p>You can define dependencies between requests:</p>
<pre><code class="language-json">"depends_on": ["get-user", "get-auth-token"]
</code></pre>
<p>Dependent requests will only run if all their dependencies have succeeded.</p>
<h2 id="examples-1"><a class="header" href="#examples-1">Examples</a></h2>
<h3 id="github-api-collection"><a class="header" href="#github-api-collection">GitHub API Collection</a></h3>
<pre><code class="language-json">{
  "name": "GitHub API Collection",
  "description": "A collection of GitHub API tests",
  "variables": {
    "base_url": "https://api.github.com",
    "username": "octocat"
  },
  "auth": {
    "type": "bearer",
    "token": "{{GITHUB_TOKEN}}"
  },
  "defaults": {
    "headers": {
      "Accept": "application/vnd.github.v3+json",
      "User-Agent": "QitOps-Test"
    }
  },
  "requests": [
    {
      "name": "Get User",
      "id": "get-user",
      "url": "{{base_url}}/users/{{username}}",
      "method": "GET",
      "expected_status": 200,
      "capture": {
        "user_id": "$.id",
        "repos_url": "$.repos_url"
      }
    },
    {
      "name": "Get User Repos",
      "id": "get-repos",
      "url": "{{repos_url}}",
      "method": "GET",
      "depends_on": ["get-user"],
      "expected_status": 200,
      "capture": {
        "first_repo_name": "$.0.name",
        "first_repo_url": "$.0.url"
      }
    },
    {
      "name": "Get First Repo Details",
      "id": "get-repo-details",
      "url": "{{first_repo_url}}",
      "method": "GET",
      "depends_on": ["get-repos"],
      "expected_status": 200
    }
  ]
}
</code></pre>
<h3 id="e-commerce-api-collection"><a class="header" href="#e-commerce-api-collection">E-commerce API Collection</a></h3>
<pre><code class="language-json">{
  "name": "E-commerce API Collection",
  "description": "Test e-commerce API workflow",
  "variables": {
    "base_url": "https://api.example.com",
    "product_id": "12345",
    "user_id": "user123"
  },
  "auth": {
    "type": "apikey",
    "key": "X-API-Key",
    "value": "{{API_KEY}}",
    "in": "header"
  },
  "requests": [
    {
      "name": "Get Product",
      "id": "get-product",
      "url": "{{base_url}}/products/{{product_id}}",
      "method": "GET",
      "expected_status": 200,
      "capture": {
        "product_price": "$.price",
        "product_name": "$.name"
      }
    },
    {
      "name": "Add to Cart",
      "id": "add-to-cart",
      "url": "{{base_url}}/users/{{user_id}}/cart",
      "method": "POST",
      "body": {
        "product_id": "{{product_id}}",
        "quantity": 1
      },
      "depends_on": ["get-product"],
      "expected_status": 201,
      "capture": {
        "cart_id": "$.cart_id"
      }
    },
    {
      "name": "Get Cart",
      "id": "get-cart",
      "url": "{{base_url}}/users/{{user_id}}/cart/{{cart_id}}",
      "method": "GET",
      "depends_on": ["add-to-cart"],
      "expected_status": 200,
      "expected_body": {
        "items": [
          {
            "product_id": "{{product_id}}",
            "quantity": 1,
            "price": "{{product_price}}"
          }
        ]
      }
    },
    {
      "name": "Checkout",
      "id": "checkout",
      "url": "{{base_url}}/users/{{user_id}}/cart/{{cart_id}}/checkout",
      "method": "POST",
      "body": {
        "payment_method": "credit_card",
        "shipping_address": {
          "street": "123 Main St",
          "city": "Anytown",
          "zip": "12345"
        }
      },
      "depends_on": ["get-cart"],
      "expected_status": 201,
      "capture": {
        "order_id": "$.order_id"
      }
    },
    {
      "name": "Get Order",
      "id": "get-order",
      "url": "{{base_url}}/users/{{user_id}}/orders/{{order_id}}",
      "method": "GET",
      "depends_on": ["checkout"],
      "expected_status": 200,
      "expected_body": {
        "status": "processing",
        "total": "{{product_price}}"
      }
    }
  ]
}
</code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="collection-organization"><a class="header" href="#collection-organization">Collection Organization</a></h3>
<ul>
<li><strong>Group Related Requests</strong>: Group related requests in a single collection</li>
<li><strong>Use Descriptive Names</strong>: Use descriptive names for collections and requests</li>
<li><strong>Include Descriptions</strong>: Include descriptions for collections and requests</li>
<li><strong>Organize by Workflow</strong>: Organize collections by business workflow or feature</li>
</ul>
<h3 id="variables-and-environments-1"><a class="header" href="#variables-and-environments-1">Variables and Environments</a></h3>
<ul>
<li><strong>Use Variables</strong>: Use variables for values that change between environments</li>
<li><strong>Define Environments</strong>: Define environment-specific configurations</li>
<li><strong>Avoid Hardcoding</strong>: Avoid hardcoding sensitive information</li>
<li><strong>Use Variable Interpolation</strong>: Use variable interpolation for dynamic values</li>
</ul>
<h3 id="dependencies-and-data-flow"><a class="header" href="#dependencies-and-data-flow">Dependencies and Data Flow</a></h3>
<ul>
<li><strong>Define Dependencies</strong>: Define clear dependencies between requests</li>
<li><strong>Capture Data</strong>: Capture data from responses to use in subsequent requests</li>
<li><strong>Handle Errors</strong>: Configure how to handle errors in dependent requests</li>
<li><strong>Use Pre/Post Scripts</strong>: Use pre-request and post-request scripts for complex logic</li>
</ul>
<h2 id="integration-with-cicd-1"><a class="header" href="#integration-with-cicd-1">Integration with CI/CD</a></h2>
<p>API collections can be integrated into CI/CD pipelines:</p>
<pre><code class="language-yaml"># Example GitHub Actions workflow step
- name: Run API Collection
  run: |
    qitops collection -c tests/configs/api_collection.json -e staging --report json --output collection-results.json
    
- name: Upload Collection Results
  uses: actions/upload-artifact@v2
  with:
    name: collection-results
    path: collection-results.json
</code></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="common-issues-3"><a class="header" href="#common-issues-3">Common Issues</a></h3>
<ul>
<li><strong>Variable Not Found</strong>: Check that all variables are defined</li>
<li><strong>Dependency Failure</strong>: Check that dependent requests are successful</li>
<li><strong>Capture Failure</strong>: Check that JSONPath expressions are correct</li>
<li><strong>Authentication Issues</strong>: Verify authentication credentials</li>
<li><strong>Environment Mismatch</strong>: Check that environment-specific variables are correct</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-testing-5"><a class="header" href="#performance-testing-5">Performance Testing</a></h1>
<p>QitOps provides powerful performance testing capabilities that allow you to measure the speed, scalability, and stability of your APIs and web services under various load conditions.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>Performance testing in QitOps allows you to:</p>
<ul>
<li>Simulate concurrent users and requests</li>
<li>Measure response times, throughput, and error rates</li>
<li>Test different load profiles (constant, ramping, spike)</li>
<li>Define performance thresholds and success criteria</li>
<li>Generate detailed performance reports</li>
<li>Identify bottlenecks and performance issues</li>
</ul>
<h2 id="getting-started-3"><a class="header" href="#getting-started-3">Getting Started</a></h2>
<h3 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h3>
<pre><code class="language-bash"># Run a basic performance test
qitops performance -c tests/configs/performance_test.json

# Run with custom users and duration
qitops performance -c tests/configs/performance_test.json -u 20 -d 60

# Run with a specific ramp-up time
qitops performance -c tests/configs/performance_test.json -u 10 -d 30 -r 5
</code></pre>
<h3 id="command-line-options-3"><a class="header" href="#command-line-options-3">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>-c, --config &lt;FILE&gt;</code></td><td>Performance test configuration file</td></tr>
<tr><td><code>-u, --users &lt;NUMBER&gt;</code></td><td>Number of concurrent users (overrides config)</td></tr>
<tr><td><code>-d, --duration &lt;SECONDS&gt;</code></td><td>Test duration in seconds (overrides config)</td></tr>
<tr><td><code>-r, --ramp-up &lt;SECONDS&gt;</code></td><td>Ramp-up time in seconds (overrides config)</td></tr>
<tr><td><code>--stream-metrics</code></td><td>Stream metrics to console during test</td></tr>
<tr><td><code>--metrics-interval &lt;SECONDS&gt;</code></td><td>Interval for metrics collection (default: 5)</td></tr>
<tr><td><code>-e, --environment &lt;ENV&gt;</code></td><td>Environment to use (default: production)</td></tr>
<tr><td><code>-r, --report &lt;FORMAT&gt;</code></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td><code>-o, --output &lt;FILE&gt;</code></td><td>Output file for the report</td></tr>
</tbody></table>
</div>
<h2 id="configuration-3"><a class="header" href="#configuration-3">Configuration</a></h2>
<p>Performance tests are defined in JSON configuration files that specify the target, load profile, and success criteria.</p>
<h3 id="basic-configuration-structure-2"><a class="header" href="#basic-configuration-structure-2">Basic Configuration Structure</a></h3>
<pre><code class="language-json">{
  "name": "Sample Performance Test",
  "description": "Load testing a public API endpoint",
  "timeout": 30,
  "retries": 3,
  "environment": "production",
  "target_url": "https://api.example.com/endpoint",
  "method": "GET",
  "headers": {
    "Accept": "application/json"
  },
  "body": {
    "param1": "value1",
    "param2": "value2"
  },
  "concurrent_users": 10,
  "duration_secs": 60,
  "ramp_up_time_secs": 5,
  "success_threshold": 95.0,
  "max_response_time_ms": 500,
  "requests_per_second_threshold": 50
}
</code></pre>
<h3 id="configuration-fields-2"><a class="header" href="#configuration-fields-2">Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Yes</td><td>Name of the test</td></tr>
<tr><td>description</td><td>string</td><td>No</td><td>Description of the test</td></tr>
<tr><td>timeout</td><td>number</td><td>No</td><td>Request timeout in seconds (default: 30)</td></tr>
<tr><td>retries</td><td>number</td><td>No</td><td>Number of retries (default: 3)</td></tr>
<tr><td>environment</td><td>string</td><td>No</td><td>Environment to use (default: production)</td></tr>
<tr><td>target_url</td><td>string</td><td>Yes</td><td>URL to test</td></tr>
<tr><td>method</td><td>string</td><td>Yes</td><td>HTTP method (GET, POST, PUT, DELETE, etc.)</td></tr>
<tr><td>headers</td><td>object</td><td>No</td><td>HTTP headers to send</td></tr>
<tr><td>body</td><td>object/string</td><td>No</td><td>Request body (JSON object or string)</td></tr>
<tr><td>concurrent_users</td><td>number</td><td>Yes</td><td>Number of concurrent users to simulate</td></tr>
<tr><td>duration_secs</td><td>number</td><td>Yes</td><td>Test duration in seconds</td></tr>
<tr><td>ramp_up_time_secs</td><td>number</td><td>No</td><td>Time to ramp up to full user count (default: 0)</td></tr>
<tr><td>success_threshold</td><td>number</td><td>No</td><td>Minimum success rate percentage (default: 95.0)</td></tr>
<tr><td>max_response_time_ms</td><td>number</td><td>No</td><td>Maximum acceptable response time in milliseconds</td></tr>
<tr><td>requests_per_second_threshold</td><td>number</td><td>No</td><td>Minimum requests per second</td></tr>
</tbody></table>
</div>
<h2 id="enhanced-performance-testing-5"><a class="header" href="#enhanced-performance-testing-5">Enhanced Performance Testing</a></h2>
<p>QitOps also supports enhanced performance testing with multiple scenarios, custom load profiles, and detailed metrics.</p>
<h3 id="enhanced-configuration-structure"><a class="header" href="#enhanced-configuration-structure">Enhanced Configuration Structure</a></h3>
<pre><code class="language-json">{
  "name": "Enhanced Performance Test",
  "description": "Advanced load testing with multiple scenarios",
  "version": "1.0.0",
  "variables": {
    "base_url": "https://api.example.com",
    "api_key": "{{API_KEY}}"
  },
  "defaults": {
    "headers": {
      "Accept": "application/json",
      "Authorization": "Bearer {{api_key}}"
    },
    "timeout": 30,
    "retries": 3
  },
  "scenarios": [
    {
      "name": "Light Load",
      "description": "Light load test with 10 users",
      "target_url": "{{base_url}}/endpoint1",
      "method": "GET",
      "concurrent_users": 10,
      "duration_secs": 60,
      "ramp_up_time_secs": 5,
      "success_threshold": 99.0,
      "max_response_time_ms": 200
    },
    {
      "name": "Medium Load",
      "description": "Medium load test with 50 users",
      "target_url": "{{base_url}}/endpoint2",
      "method": "POST",
      "body": {
        "param1": "value1",
        "param2": "value2"
      },
      "concurrent_users": 50,
      "duration_secs": 120,
      "ramp_up_time_secs": 15,
      "success_threshold": 95.0,
      "max_response_time_ms": 500
    },
    {
      "name": "Heavy Load",
      "description": "Heavy load test with 100 users",
      "target_url": "{{base_url}}/endpoint3",
      "method": "GET",
      "concurrent_users": 100,
      "duration_secs": 180,
      "ramp_up_time_secs": 30,
      "success_threshold": 90.0,
      "max_response_time_ms": 1000
    }
  ],
  "load_profile": {
    "type": "ramp-up-down",
    "stages": [
      { "duration_secs": 30, "target_users": 0 },
      { "duration_secs": 60, "target_users": 100 },
      { "duration_secs": 120, "target_users": 100 },
      { "duration_secs": 60, "target_users": 0 }
    ]
  },
  "metrics": {
    "collection_interval_secs": 5,
    "percentiles": [50, 90, 95, 99],
    "tags": ["api", "performance", "load-test"]
  }
}
</code></pre>
<h3 id="load-profiles"><a class="header" href="#load-profiles">Load Profiles</a></h3>
<p>QitOps supports different load profiles to simulate various real-world scenarios:</p>
<h4 id="constant-load"><a class="header" href="#constant-load">Constant Load</a></h4>
<pre><code class="language-json">"load_profile": {
  "type": "constant",
  "users": 50,
  "duration_secs": 300
}
</code></pre>
<h4 id="ramp-up"><a class="header" href="#ramp-up">Ramp-Up</a></h4>
<pre><code class="language-json">"load_profile": {
  "type": "ramp-up",
  "start_users": 0,
  "end_users": 100,
  "duration_secs": 300
}
</code></pre>
<h4 id="ramp-up-down"><a class="header" href="#ramp-up-down">Ramp-Up-Down</a></h4>
<pre><code class="language-json">"load_profile": {
  "type": "ramp-up-down",
  "stages": [
    { "duration_secs": 60, "target_users": 0 },
    { "duration_secs": 120, "target_users": 100 },
    { "duration_secs": 60, "target_users": 0 }
  ]
}
</code></pre>
<h4 id="step"><a class="header" href="#step">Step</a></h4>
<pre><code class="language-json">"load_profile": {
  "type": "step",
  "stages": [
    { "duration_secs": 60, "target_users": 10 },
    { "duration_secs": 60, "target_users": 20 },
    { "duration_secs": 60, "target_users": 50 },
    { "duration_secs": 60, "target_users": 100 }
  ]
}
</code></pre>
<h4 id="spike"><a class="header" href="#spike">Spike</a></h4>
<pre><code class="language-json">"load_profile": {
  "type": "spike",
  "base_users": 10,
  "spike_users": 100,
  "base_duration_secs": 60,
  "spike_duration_secs": 30,
  "cycles": 3
}
</code></pre>
<h2 id="examples-2"><a class="header" href="#examples-2">Examples</a></h2>
<h3 id="basic-api-performance-test"><a class="header" href="#basic-api-performance-test">Basic API Performance Test</a></h3>
<pre><code class="language-json">{
  "name": "Basic API Performance Test",
  "description": "Testing a public API endpoint",
  "target_url": "https://api.example.com/users",
  "method": "GET",
  "headers": {
    "Accept": "application/json"
  },
  "concurrent_users": 10,
  "duration_secs": 60,
  "ramp_up_time_secs": 5,
  "success_threshold": 95.0,
  "max_response_time_ms": 500
}
</code></pre>
<h3 id="post-request-performance-test"><a class="header" href="#post-request-performance-test">POST Request Performance Test</a></h3>
<pre><code class="language-json">{
  "name": "POST Request Performance Test",
  "description": "Testing a POST endpoint",
  "target_url": "https://api.example.com/users",
  "method": "POST",
  "headers": {
    "Content-Type": "application/json",
    "Accept": "application/json"
  },
  "body": {
    "name": "John Doe",
    "email": "john@example.com",
    "age": 30
  },
  "concurrent_users": 20,
  "duration_secs": 120,
  "ramp_up_time_secs": 10,
  "success_threshold": 95.0,
  "max_response_time_ms": 800
}
</code></pre>
<h3 id="multi-scenario-performance-test"><a class="header" href="#multi-scenario-performance-test">Multi-Scenario Performance Test</a></h3>
<pre><code class="language-json">{
  "name": "Multi-Scenario Performance Test",
  "description": "Testing multiple endpoints with different loads",
  "variables": {
    "base_url": "https://api.example.com"
  },
  "defaults": {
    "headers": {
      "Accept": "application/json"
    },
    "timeout": 30
  },
  "scenarios": [
    {
      "name": "Get Users",
      "target_url": "{{base_url}}/users",
      "method": "GET",
      "concurrent_users": 20,
      "duration_secs": 60,
      "success_threshold": 95.0
    },
    {
      "name": "Create User",
      "target_url": "{{base_url}}/users",
      "method": "POST",
      "headers": {
        "Content-Type": "application/json"
      },
      "body": {
        "name": "John Doe",
        "email": "john@example.com"
      },
      "concurrent_users": 10,
      "duration_secs": 60,
      "success_threshold": 90.0
    },
    {
      "name": "Search Users",
      "target_url": "{{base_url}}/users/search?q=john",
      "method": "GET",
      "concurrent_users": 30,
      "duration_secs": 60,
      "success_threshold": 85.0
    }
  ]
}
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="test-design"><a class="header" href="#test-design">Test Design</a></h3>
<ul>
<li><strong>Define Clear Objectives</strong>: Define clear performance objectives for your tests</li>
<li><strong>Start Small</strong>: Start with a small number of users and gradually increase</li>
<li><strong>Test Different Scenarios</strong>: Test different scenarios to understand the performance characteristics of your system</li>
<li><strong>Monitor System Resources</strong>: Monitor system resources during performance tests</li>
</ul>
<h3 id="load-profiles-1"><a class="header" href="#load-profiles-1">Load Profiles</a></h3>
<ul>
<li><strong>Use Appropriate Load Profiles</strong>: Use appropriate load profiles for your tests (constant, ramping, spike)</li>
<li><strong>Set Realistic Ramp-Up Times</strong>: Set realistic ramp-up times to avoid overwhelming your system</li>
<li><strong>Define Thresholds</strong>: Define thresholds for pass/fail criteria</li>
<li><strong>Use Tags</strong>: Use tags to categorize metrics for detailed analysis</li>
</ul>
<h3 id="test-execution"><a class="header" href="#test-execution">Test Execution</a></h3>
<ul>
<li><strong>Run Tests in Isolation</strong>: Run performance tests in isolation to avoid interference</li>
<li><strong>Run Tests Regularly</strong>: Run performance tests regularly to track changes over time</li>
<li><strong>Warm Up the System</strong>: Allow the system to warm up before measuring performance</li>
<li><strong>Consider Time of Day</strong>: Consider the time of day when running tests</li>
</ul>
<h2 id="integration-with-cicd-2"><a class="header" href="#integration-with-cicd-2">Integration with CI/CD</a></h2>
<p>Performance tests can be integrated into CI/CD pipelines:</p>
<pre><code class="language-yaml"># Example GitHub Actions workflow step
- name: Run Performance Tests
  run: |
    qitops performance -c tests/configs/performance_test.json --ci-mode --report json --output perf-results.json
    
- name: Upload Performance Results
  uses: actions/upload-artifact@v2
  with:
    name: performance-results
    path: perf-results.json
</code></pre>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<h3 id="common-issues-4"><a class="header" href="#common-issues-4">Common Issues</a></h3>
<ul>
<li><strong>Connection Refused</strong>: Check if the target server is running and accessible</li>
<li><strong>Timeout Errors</strong>: Increase the timeout value or check server performance</li>
<li><strong>Memory Issues</strong>: Reduce the number of concurrent users or optimize memory usage</li>
<li><strong>CPU Bottlenecks</strong>: Check if the client machine has enough CPU resources</li>
<li><strong>Network Limitations</strong>: Consider running tests from multiple locations</li>
</ul>
<h3 id="performance-analysis"><a class="header" href="#performance-analysis">Performance Analysis</a></h3>
<ul>
<li><strong>Identify Bottlenecks</strong>: Use the performance report to identify bottlenecks</li>
<li><strong>Analyze Response Time Distribution</strong>: Look at the distribution of response times</li>
<li><strong>Check Error Patterns</strong>: Analyze error patterns to identify issues</li>
<li><strong>Compare with Baselines</strong>: Compare results with baseline measurements</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="security-testing-5"><a class="header" href="#security-testing-5">Security Testing</a></h1>
<p>QitOps provides comprehensive security testing capabilities that allow you to identify vulnerabilities, ensure compliance with security standards, and protect your applications from common attacks.</p>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>Security testing in QitOps allows you to:</p>
<ul>
<li>Scan for common vulnerabilities (OWASP Top 10)</li>
<li>Check for secure headers and SSL/TLS configuration</li>
<li>Detect sensitive data exposure</li>
<li>Validate authentication and authorization mechanisms</li>
<li>Perform basic penetration testing</li>
<li>Generate detailed security reports</li>
</ul>
<h2 id="getting-started-4"><a class="header" href="#getting-started-4">Getting Started</a></h2>
<h3 id="basic-usage-3"><a class="header" href="#basic-usage-3">Basic Usage</a></h3>
<pre><code class="language-bash"># Run a security test
qitops security -c tests/configs/security_test.json

# Run with a specific scan depth
qitops security -c tests/configs/security_test.json -d 3

# Run with specific scan types
qitops security -c tests/configs/security_test.json --scan-types headers,ssl
</code></pre>
<h3 id="command-line-options-4"><a class="header" href="#command-line-options-4">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>-c, --config &lt;FILE&gt;</code></td><td>Security test configuration file</td></tr>
<tr><td><code>-d, --depth &lt;NUMBER&gt;</code></td><td>Scan depth (1-5, default: 2)</td></tr>
<tr><td><code>--scan-types &lt;TYPES&gt;</code></td><td>Comma-separated list of scan types</td></tr>
<tr><td><code>--max-findings &lt;NUMBER&gt;</code></td><td>Maximum number of findings to report</td></tr>
<tr><td><code>--severity &lt;LEVEL&gt;</code></td><td>Minimum severity level to report (low, medium, high, critical)</td></tr>
<tr><td><code>-e, --environment &lt;ENV&gt;</code></td><td>Environment to use (default: production)</td></tr>
<tr><td><code>-r, --report &lt;FORMAT&gt;</code></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td><code>-o, --output &lt;FILE&gt;</code></td><td>Output file for the report</td></tr>
</tbody></table>
</div>
<h2 id="configuration-4"><a class="header" href="#configuration-4">Configuration</a></h2>
<p>Security tests are defined in JSON configuration files that specify the target, scan types, and severity thresholds.</p>
<h3 id="basic-configuration-structure-3"><a class="header" href="#basic-configuration-structure-3">Basic Configuration Structure</a></h3>
<pre><code class="language-json">{
  "name": "Security Scan",
  "description": "Comprehensive security scan of the API",
  "timeout": 30,
  "retries": 3,
  "environment": "production",
  "target_url": "https://api.example.com",
  "headers": {
    "Accept": "application/json"
  },
  "auth": {
    "type": "bearer",
    "token": "your-token"
  },
  "scan_types": [
    "headers",
    "ssl",
    "vulnerabilities",
    "sensitive-data"
  ],
  "scan_depth": 2,
  "max_high_severity_findings": 0,
  "max_medium_severity_findings": 5,
  "severity_threshold": "low"
}
</code></pre>
<h3 id="configuration-fields-3"><a class="header" href="#configuration-fields-3">Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Yes</td><td>Name of the test</td></tr>
<tr><td>description</td><td>string</td><td>No</td><td>Description of the test</td></tr>
<tr><td>timeout</td><td>number</td><td>No</td><td>Request timeout in seconds (default: 30)</td></tr>
<tr><td>retries</td><td>number</td><td>No</td><td>Number of retries (default: 3)</td></tr>
<tr><td>environment</td><td>string</td><td>No</td><td>Environment to use (default: production)</td></tr>
<tr><td>target_url</td><td>string</td><td>Yes</td><td>URL to test</td></tr>
<tr><td>headers</td><td>object</td><td>No</td><td>HTTP headers to send</td></tr>
<tr><td>auth</td><td>object</td><td>No</td><td>Authentication configuration</td></tr>
<tr><td>scan_types</td><td>array</td><td>No</td><td>Types of scans to perform (default: all)</td></tr>
<tr><td>scan_depth</td><td>number</td><td>No</td><td>Depth of the scan (1-5, default: 2)</td></tr>
<tr><td>max_high_severity_findings</td><td>number</td><td>No</td><td>Maximum allowed high severity findings (default: 0)</td></tr>
<tr><td>max_medium_severity_findings</td><td>number</td><td>No</td><td>Maximum allowed medium severity findings (default: 5)</td></tr>
<tr><td>severity_threshold</td><td>string</td><td>No</td><td>Minimum severity level to report (default: “low”)</td></tr>
</tbody></table>
</div>
<h3 id="authentication-1"><a class="header" href="#authentication-1">Authentication</a></h3>
<p>QitOps supports various authentication methods for security testing:</p>
<h4 id="basic-authentication-1"><a class="header" href="#basic-authentication-1">Basic Authentication</a></h4>
<pre><code class="language-json">"auth": {
  "type": "basic",
  "username": "user",
  "password": "pass"
}
</code></pre>
<h4 id="bearer-token-1"><a class="header" href="#bearer-token-1">Bearer Token</a></h4>
<pre><code class="language-json">"auth": {
  "type": "bearer",
  "token": "your-token"
}
</code></pre>
<h4 id="api-key-1"><a class="header" href="#api-key-1">API Key</a></h4>
<pre><code class="language-json">"auth": {
  "type": "apikey",
  "key": "X-API-Key",
  "value": "your-api-key",
  "in": "header"  // or "query"
}
</code></pre>
<h4 id="oauth2-1"><a class="header" href="#oauth2-1">OAuth2</a></h4>
<pre><code class="language-json">"auth": {
  "type": "oauth2",
  "token_url": "https://auth.example.com/token",
  "client_id": "your-client-id",
  "client_secret": "your-client-secret",
  "scope": "read write"
}
</code></pre>
<h2 id="scan-types"><a class="header" href="#scan-types">Scan Types</a></h2>
<p>QitOps supports various types of security scans:</p>
<h3 id="headers-security"><a class="header" href="#headers-security">Headers Security</a></h3>
<p>Checks for secure HTTP headers:</p>
<ul>
<li>Content-Security-Policy</li>
<li>X-Content-Type-Options</li>
<li>X-Frame-Options</li>
<li>X-XSS-Protection</li>
<li>Strict-Transport-Security</li>
<li>Referrer-Policy</li>
<li>Permissions-Policy</li>
</ul>
<h3 id="ssltls-security"><a class="header" href="#ssltls-security">SSL/TLS Security</a></h3>
<p>Checks for secure SSL/TLS configuration:</p>
<ul>
<li>Protocol versions (TLS 1.2+)</li>
<li>Cipher suites</li>
<li>Certificate validity</li>
<li>Certificate chain</li>
<li>Key strength</li>
<li>OCSP stapling</li>
<li>Perfect forward secrecy</li>
</ul>
<h3 id="vulnerabilities"><a class="header" href="#vulnerabilities">Vulnerabilities</a></h3>
<p>Scans for common vulnerabilities:</p>
<ul>
<li>SQL Injection</li>
<li>Cross-Site Scripting (XSS)</li>
<li>Cross-Site Request Forgery (CSRF)</li>
<li>Server-Side Request Forgery (SSRF)</li>
<li>XML External Entity (XXE)</li>
<li>Command Injection</li>
<li>Path Traversal</li>
<li>Insecure Deserialization</li>
</ul>
<h3 id="sensitive-data-exposure"><a class="header" href="#sensitive-data-exposure">Sensitive Data Exposure</a></h3>
<p>Checks for sensitive data in responses:</p>
<ul>
<li>Credit card numbers</li>
<li>Social security numbers</li>
<li>API keys and tokens</li>
<li>Passwords</li>
<li>Email addresses</li>
<li>Private keys</li>
<li>Internal IP addresses</li>
</ul>
<h3 id="authentication-and-authorization"><a class="header" href="#authentication-and-authorization">Authentication and Authorization</a></h3>
<p>Tests authentication and authorization mechanisms:</p>
<ul>
<li>Brute force protection</li>
<li>Session management</li>
<li>Password policies</li>
<li>Multi-factor authentication</li>
<li>Role-based access control</li>
</ul>
<h2 id="examples-3"><a class="header" href="#examples-3">Examples</a></h2>
<h3 id="basic-security-scan"><a class="header" href="#basic-security-scan">Basic Security Scan</a></h3>
<pre><code class="language-json">{
  "name": "Basic Security Scan",
  "description": "Basic security scan of a public API",
  "target_url": "https://api.example.com",
  "scan_types": [
    "headers",
    "ssl"
  ],
  "scan_depth": 1,
  "severity_threshold": "medium"
}
</code></pre>
<h3 id="comprehensive-security-scan"><a class="header" href="#comprehensive-security-scan">Comprehensive Security Scan</a></h3>
<pre><code class="language-json">{
  "name": "Comprehensive Security Scan",
  "description": "Detailed security scan with authentication",
  "target_url": "https://api.example.com",
  "headers": {
    "Accept": "application/json",
    "User-Agent": "QitOps-SecurityTest"
  },
  "auth": {
    "type": "bearer",
    "token": "your-token"
  },
  "scan_types": [
    "headers",
    "ssl",
    "vulnerabilities",
    "sensitive-data",
    "authentication"
  ],
  "scan_depth": 3,
  "max_high_severity_findings": 0,
  "max_medium_severity_findings": 3,
  "severity_threshold": "low"
}
</code></pre>
<h3 id="api-security-scan"><a class="header" href="#api-security-scan">API Security Scan</a></h3>
<pre><code class="language-json">{
  "name": "API Security Scan",
  "description": "Security scan focused on API vulnerabilities",
  "target_url": "https://api.example.com",
  "headers": {
    "Content-Type": "application/json",
    "Accept": "application/json"
  },
  "auth": {
    "type": "apikey",
    "key": "X-API-Key",
    "value": "your-api-key",
    "in": "header"
  },
  "scan_types": [
    "vulnerabilities",
    "sensitive-data",
    "authentication"
  ],
  "scan_depth": 2,
  "endpoints": [
    {
      "path": "/users",
      "method": "GET",
      "params": {
        "limit": "10"
      }
    },
    {
      "path": "/users",
      "method": "POST",
      "body": {
        "name": "Test User",
        "email": "test@example.com"
      }
    }
  ]
}
</code></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="test-design-1"><a class="header" href="#test-design-1">Test Design</a></h3>
<ul>
<li><strong>Define Security Requirements</strong>: Define clear security requirements for your tests</li>
<li><strong>Test Different Scan Types</strong>: Test different scan types to identify different types of vulnerabilities</li>
<li><strong>Set Severity Thresholds</strong>: Set severity thresholds for pass/fail criteria</li>
<li><strong>Regular Testing</strong>: Perform security tests regularly to identify new vulnerabilities</li>
</ul>
<h3 id="authentication-2"><a class="header" href="#authentication-2">Authentication</a></h3>
<ul>
<li><strong>Test Authentication</strong>: Test authentication mechanisms to ensure they are secure</li>
<li><strong>Test Authorization</strong>: Test authorization to ensure users can only access resources they are authorized to access</li>
<li><strong>Test Input Validation</strong>: Test input validation to prevent injection attacks</li>
<li><strong>Test Error Handling</strong>: Test error handling to ensure sensitive information is not leaked</li>
</ul>
<h3 id="test-execution-1"><a class="header" href="#test-execution-1">Test Execution</a></h3>
<ul>
<li><strong>Run Tests in Isolation</strong>: Run security tests in isolation to avoid interference</li>
<li><strong>Run Tests Regularly</strong>: Run security tests regularly to identify new vulnerabilities</li>
<li><strong>Scan Different Environments</strong>: Scan different environments (development, staging, production)</li>
<li><strong>Follow Up on Findings</strong>: Follow up on security findings to ensure they are addressed</li>
</ul>
<h2 id="integration-with-cicd-3"><a class="header" href="#integration-with-cicd-3">Integration with CI/CD</a></h2>
<p>Security tests can be integrated into CI/CD pipelines:</p>
<pre><code class="language-yaml"># Example GitHub Actions workflow step
- name: Run Security Tests
  run: |
    qitops security -c tests/configs/security_test.json --ci-mode --report json --output security-results.json
    
- name: Upload Security Results
  uses: actions/upload-artifact@v2
  with:
    name: security-results
    path: security-results.json
</code></pre>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="common-issues-5"><a class="header" href="#common-issues-5">Common Issues</a></h3>
<ul>
<li><strong>False Positives</strong>: Security scans may report false positives</li>
<li><strong>Scan Depth</strong>: Higher scan depths may take longer to complete</li>
<li><strong>Authentication Issues</strong>: Ensure authentication credentials are valid</li>
<li><strong>Rate Limiting</strong>: Some targets may rate limit security scans</li>
<li><strong>Firewall Blocking</strong>: Firewalls may block security scans</li>
</ul>
<h3 id="security-analysis"><a class="header" href="#security-analysis">Security Analysis</a></h3>
<ul>
<li><strong>Prioritize Findings</strong>: Prioritize findings based on severity and impact</li>
<li><strong>Verify Findings</strong>: Verify findings to ensure they are not false positives</li>
<li><strong>Document Findings</strong>: Document findings and remediation steps</li>
<li><strong>Track Progress</strong>: Track progress in addressing security findings</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="web-testing-5"><a class="header" href="#web-testing-5">Web Testing</a></h1>
<p>QitOps provides powerful web testing capabilities that allow you to automate browser interactions, validate web applications, and ensure your websites function correctly across different scenarios.</p>
<h2 id="overview-4"><a class="header" href="#overview-4">Overview</a></h2>
<p>Web testing in QitOps uses headless browser automation to interact with web pages, perform actions, and validate expected behaviors. This approach allows you to:</p>
<ul>
<li>Test complete user journeys through your web application</li>
<li>Validate UI elements and their properties</li>
<li>Capture screenshots for visual verification</li>
<li>Test responsive design across different viewport sizes</li>
<li>Verify page content, titles, and URLs</li>
<li>Automate form submissions and user interactions</li>
</ul>
<h2 id="getting-started-5"><a class="header" href="#getting-started-5">Getting Started</a></h2>
<h3 id="basic-usage-4"><a class="header" href="#basic-usage-4">Basic Usage</a></h3>
<pre><code class="language-bash"># Run a web test
qitops web -c tests/configs/web_test.json

# Run in headless mode (default)
qitops web -c tests/configs/web_test.json --headless

# Run with browser visible
qitops web -c tests/configs/web_test.json --no-headless

# Run with custom viewport
qitops web -c tests/configs/web_test.json --width 1920 --height 1080
</code></pre>
<h3 id="command-line-options-5"><a class="header" href="#command-line-options-5">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>-c, --config &lt;FILE&gt;</code></td><td>Web test configuration file</td></tr>
<tr><td><code>--headless</code></td><td>Run in headless mode (default: true)</td></tr>
<tr><td><code>--no-headless</code></td><td>Run with browser visible</td></tr>
<tr><td><code>--width &lt;PIXELS&gt;</code></td><td>Viewport width in pixels</td></tr>
<tr><td><code>--height &lt;PIXELS&gt;</code></td><td>Viewport height in pixels</td></tr>
<tr><td><code>--device &lt;DEVICE&gt;</code></td><td>Emulate a specific device (e.g., “iPhone 12”, “iPad”)</td></tr>
<tr><td><code>--timeout &lt;SECONDS&gt;</code></td><td>Default timeout for actions and assertions</td></tr>
<tr><td><code>--screenshots</code></td><td>Capture screenshots during test execution</td></tr>
<tr><td><code>--screenshots-dir &lt;DIR&gt;</code></td><td>Directory to save screenshots</td></tr>
<tr><td><code>-r, --report &lt;FORMAT&gt;</code></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td><code>-o, --output &lt;FILE&gt;</code></td><td>Output file for the report</td></tr>
</tbody></table>
</div>
<h2 id="configuration-5"><a class="header" href="#configuration-5">Configuration</a></h2>
<p>Web tests are defined in JSON configuration files that specify the target URL, actions to perform, and assertions to validate.</p>
<h3 id="basic-configuration-structure-4"><a class="header" href="#basic-configuration-structure-4">Basic Configuration Structure</a></h3>
<pre><code class="language-json">{
  "name": "Sample Web Test",
  "description": "Testing a public website",
  "timeout": 30,
  "retries": 3,
  "target_url": "https://example.com",
  "viewport": {
    "width": 1280,
    "height": 800,
    "device_scale_factor": 1.0,
    "is_mobile": false
  },
  "wait_for_selector": "body",
  "wait_timeout_secs": 10,
  "screenshots": true,
  "user_agent": "QitOps-WebTester/1.0",
  "assertions": [
    {
      "assertion_type": "title",
      "expected_value": "Example Domain",
      "comparison": "contains"
    },
    {
      "assertion_type": "element",
      "selector": "h1",
      "expected_value": "true"
    }
  ],
  "actions": [
    {
      "action_type": "wait",
      "wait_time_ms": 1000
    },
    {
      "action_type": "click",
      "selector": "a"
    }
  ]
}
</code></pre>
<h3 id="configuration-fields-4"><a class="header" href="#configuration-fields-4">Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Yes</td><td>Name of the test</td></tr>
<tr><td>description</td><td>string</td><td>No</td><td>Description of the test</td></tr>
<tr><td>timeout</td><td>number</td><td>No</td><td>Default timeout in seconds (default: 30)</td></tr>
<tr><td>retries</td><td>number</td><td>No</td><td>Number of retries (default: 3)</td></tr>
<tr><td>target_url</td><td>string</td><td>Yes</td><td>URL to test</td></tr>
<tr><td>viewport</td><td>object</td><td>No</td><td>Viewport configuration</td></tr>
<tr><td>wait_for_selector</td><td>string</td><td>No</td><td>Selector to wait for before starting test</td></tr>
<tr><td>wait_timeout_secs</td><td>number</td><td>No</td><td>Timeout for initial wait (default: 10)</td></tr>
<tr><td>screenshots</td><td>boolean</td><td>No</td><td>Whether to capture screenshots (default: false)</td></tr>
<tr><td>user_agent</td><td>string</td><td>No</td><td>Custom user agent string</td></tr>
<tr><td>assertions</td><td>array</td><td>No</td><td>List of assertions to validate</td></tr>
<tr><td>actions</td><td>array</td><td>No</td><td>List of actions to perform</td></tr>
</tbody></table>
</div>
<h3 id="viewport-configuration-1"><a class="header" href="#viewport-configuration-1">Viewport Configuration</a></h3>
<pre><code class="language-json">"viewport": {
  "width": 1280,
  "height": 800,
  "device_scale_factor": 1.0,
  "is_mobile": false
}
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td>width</td><td>number</td><td>Viewport width in pixels</td></tr>
<tr><td>height</td><td>number</td><td>Viewport height in pixels</td></tr>
<tr><td>device_scale_factor</td><td>number</td><td>Device scale factor (1.0 for desktop, 2.0+ for high-DPI)</td></tr>
<tr><td>is_mobile</td><td>boolean</td><td>Whether to emulate a mobile device</td></tr>
</tbody></table>
</div>
<h2 id="actions"><a class="header" href="#actions">Actions</a></h2>
<p>Actions define the steps to perform during the test, such as clicking elements, typing text, or navigating to different pages.</p>
<h3 id="available-actions"><a class="header" href="#available-actions">Available Actions</a></h3>
<h4 id="click"><a class="header" href="#click">Click</a></h4>
<pre><code class="language-json">{
  "action_type": "click",
  "selector": "button.submit",
  "timeout_ms": 5000,
  "button": "left",
  "click_count": 1,
  "delay_ms": 0
}
</code></pre>
<h4 id="type"><a class="header" href="#type">Type</a></h4>
<pre><code class="language-json">{
  "action_type": "type",
  "selector": "input[name='username']",
  "text": "testuser",
  "delay_ms": 50
}
</code></pre>
<h4 id="navigate"><a class="header" href="#navigate">Navigate</a></h4>
<pre><code class="language-json">{
  "action_type": "navigate",
  "url": "https://example.com/login",
  "wait_until": "networkidle0"
}
</code></pre>
<h4 id="wait"><a class="header" href="#wait">Wait</a></h4>
<pre><code class="language-json">{
  "action_type": "wait",
  "wait_time_ms": 1000
}
</code></pre>
<h4 id="wait-for-selector"><a class="header" href="#wait-for-selector">Wait For Selector</a></h4>
<pre><code class="language-json">{
  "action_type": "wait_for_selector",
  "selector": "#content",
  "timeout_ms": 5000,
  "visible": true
}
</code></pre>
<h4 id="select-option"><a class="header" href="#select-option">Select Option</a></h4>
<pre><code class="language-json">{
  "action_type": "select",
  "selector": "select#country",
  "value": "US"
}
</code></pre>
<h4 id="checkuncheck"><a class="header" href="#checkuncheck">Check/Uncheck</a></h4>
<pre><code class="language-json">{
  "action_type": "check",
  "selector": "input[type='checkbox']",
  "checked": true
}
</code></pre>
<h4 id="screenshot"><a class="header" href="#screenshot">Screenshot</a></h4>
<pre><code class="language-json">{
  "action_type": "screenshot",
  "name": "login-page",
  "full_page": true
}
</code></pre>
<h4 id="scroll"><a class="header" href="#scroll">Scroll</a></h4>
<pre><code class="language-json">{
  "action_type": "scroll",
  "x": 0,
  "y": 500
}
</code></pre>
<h4 id="hover"><a class="header" href="#hover">Hover</a></h4>
<pre><code class="language-json">{
  "action_type": "hover",
  "selector": ".dropdown-menu"
}
</code></pre>
<h2 id="assertions"><a class="header" href="#assertions">Assertions</a></h2>
<p>Assertions validate that the web page meets expected conditions.</p>
<h3 id="available-assertions"><a class="header" href="#available-assertions">Available Assertions</a></h3>
<h4 id="title"><a class="header" href="#title">Title</a></h4>
<pre><code class="language-json">{
  "assertion_type": "title",
  "expected_value": "Dashboard",
  "comparison": "equals"
}
</code></pre>
<h4 id="url"><a class="header" href="#url">URL</a></h4>
<pre><code class="language-json">{
  "assertion_type": "url",
  "expected_value": "https://example.com/dashboard",
  "comparison": "contains"
}
</code></pre>
<h4 id="element"><a class="header" href="#element">Element</a></h4>
<pre><code class="language-json">{
  "assertion_type": "element",
  "selector": ".user-profile",
  "expected_value": "true"
}
</code></pre>
<h4 id="text-content"><a class="header" href="#text-content">Text Content</a></h4>
<pre><code class="language-json">{
  "assertion_type": "text",
  "selector": "h1",
  "expected_value": "Welcome to Dashboard",
  "comparison": "equals"
}
</code></pre>
<h4 id="attribute"><a class="header" href="#attribute">Attribute</a></h4>
<pre><code class="language-json">{
  "assertion_type": "attribute",
  "selector": "img.logo",
  "attribute": "src",
  "expected_value": "/images/logo.png",
  "comparison": "contains"
}
</code></pre>
<h4 id="count"><a class="header" href="#count">Count</a></h4>
<pre><code class="language-json">{
  "assertion_type": "count",
  "selector": "table tr",
  "expected_value": 5,
  "comparison": "greater_than"
}
</code></pre>
<h4 id="css-property"><a class="header" href="#css-property">CSS Property</a></h4>
<pre><code class="language-json">{
  "assertion_type": "css",
  "selector": ".error-message",
  "property": "color",
  "expected_value": "rgb(255, 0, 0)",
  "comparison": "equals"
}
</code></pre>
<h3 id="comparison-types"><a class="header" href="#comparison-types">Comparison Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td>equals</td><td>Exact match</td></tr>
<tr><td>contains</td><td>String contains</td></tr>
<tr><td>starts_with</td><td>String starts with</td></tr>
<tr><td>ends_with</td><td>String ends with</td></tr>
<tr><td>matches</td><td>Regex match</td></tr>
<tr><td>greater_than</td><td>Numeric greater than</td></tr>
<tr><td>less_than</td><td>Numeric less than</td></tr>
<tr><td>greater_than_or_equal</td><td>Numeric greater than or equal</td></tr>
<tr><td>less_than_or_equal</td><td>Numeric less than or equal</td></tr>
</tbody></table>
</div>
<h2 id="examples-4"><a class="header" href="#examples-4">Examples</a></h2>
<h3 id="login-form-test"><a class="header" href="#login-form-test">Login Form Test</a></h3>
<pre><code class="language-json">{
  "name": "Login Form Test",
  "description": "Test the login functionality",
  "target_url": "https://example.com/login",
  "viewport": {
    "width": 1280,
    "height": 800
  },
  "wait_for_selector": "form",
  "screenshots": true,
  "actions": [
    {
      "action_type": "type",
      "selector": "input[name='username']",
      "text": "testuser"
    },
    {
      "action_type": "type",
      "selector": "input[name='password']",
      "text": "password123"
    },
    {
      "action_type": "screenshot",
      "name": "before-login"
    },
    {
      "action_type": "click",
      "selector": "button[type='submit']"
    },
    {
      "action_type": "wait_for_selector",
      "selector": ".dashboard",
      "timeout_ms": 5000
    },
    {
      "action_type": "screenshot",
      "name": "after-login"
    }
  ],
  "assertions": [
    {
      "assertion_type": "url",
      "expected_value": "/dashboard",
      "comparison": "contains"
    },
    {
      "assertion_type": "element",
      "selector": ".user-profile",
      "expected_value": "true"
    },
    {
      "assertion_type": "text",
      "selector": ".welcome-message",
      "expected_value": "Welcome, Test User",
      "comparison": "contains"
    }
  ]
}
</code></pre>
<h3 id="responsive-design-test"><a class="header" href="#responsive-design-test">Responsive Design Test</a></h3>
<pre><code class="language-json">{
  "name": "Responsive Design Test",
  "description": "Test responsive behavior across different devices",
  "target_url": "https://example.com",
  "screenshots": true,
  "actions": [
    {
      "action_type": "set_viewport",
      "width": 1920,
      "height": 1080,
      "device_scale_factor": 1.0,
      "is_mobile": false
    },
    {
      "action_type": "screenshot",
      "name": "desktop-view"
    },
    {
      "action_type": "set_viewport",
      "width": 768,
      "height": 1024,
      "device_scale_factor": 2.0,
      "is_mobile": true
    },
    {
      "action_type": "screenshot",
      "name": "tablet-view"
    },
    {
      "action_type": "set_viewport",
      "width": 375,
      "height": 812,
      "device_scale_factor": 3.0,
      "is_mobile": true
    },
    {
      "action_type": "screenshot",
      "name": "mobile-view"
    }
  ],
  "assertions": [
    {
      "assertion_type": "css",
      "selector": ".mobile-menu",
      "property": "display",
      "expected_value": "block",
      "comparison": "equals"
    }
  ]
}
</code></pre>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<h3 id="selector-strategy"><a class="header" href="#selector-strategy">Selector Strategy</a></h3>
<ul>
<li>Use stable selectors that are less likely to change</li>
<li>Prefer IDs and data attributes over classes or XPaths</li>
<li>Add test-specific attributes like <code>data-testid="login-button"</code> to your application</li>
<li>Use specific selectors to avoid ambiguity</li>
</ul>
<h3 id="test-organization-1"><a class="header" href="#test-organization-1">Test Organization</a></h3>
<ul>
<li>Group related tests in separate configuration files</li>
<li>Use descriptive names for tests and screenshots</li>
<li>Structure tests to follow user journeys</li>
<li>Keep tests focused on specific functionality</li>
</ul>
<h3 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h3>
<ul>
<li>Use headless mode for CI/CD environments</li>
<li>Minimize unnecessary actions and waits</li>
<li>Use appropriate timeouts for your application</li>
<li>Consider network conditions when testing</li>
</ul>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<ul>
<li>Add appropriate waits before interactions</li>
<li>Use retries for flaky operations</li>
<li>Capture screenshots at failure points</li>
<li>Add detailed assertions to pinpoint issues</li>
</ul>
<h2 id="integration-with-cicd-4"><a class="header" href="#integration-with-cicd-4">Integration with CI/CD</a></h2>
<p>Web tests can be integrated into CI/CD pipelines:</p>
<pre><code class="language-yaml"># Example GitHub Actions workflow step
- name: Run Web Tests
  run: |
    qitops web -c tests/configs/web_test.json --headless --screenshots --report html --output web-test-report.html
    
- name: Upload Test Report
  uses: actions/upload-artifact@v2
  with:
    name: web-test-report
    path: web-test-report.html
    
- name: Upload Screenshots
  uses: actions/upload-artifact@v2
  with:
    name: web-test-screenshots
    path: screenshots/
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ai-features-1"><a class="header" href="#ai-features-1">AI Features</a></h1>
<p>QitOps includes powerful AI features that can help you generate test configurations, analyze test results, and suggest improvements to your tests. These features are designed to work completely offline with local LLM models, ensuring your data never leaves your machine.</p>
<h2 id="installation-2"><a class="header" href="#installation-2">Installation</a></h2>
<p>To use the AI features, you need to install QitOps with the <code>ai</code> feature flag:</p>
<pre><code class="language-bash"># Install from crates.io with AI features
cargo install qitops --features ai

# Or build from source with AI features
cargo build --features ai
</code></pre>
<h2 id="supported-llm-models"><a class="header" href="#supported-llm-models">Supported LLM Models</a></h2>
<p>QitOps supports a variety of local LLM models for its AI features. These models run entirely on your local machine, ensuring privacy and offline operation.</p>
<h3 id="llama-models"><a class="header" href="#llama-models">LLaMA Models</a></h3>
<ul>
<li><strong>LLaMA 1</strong>: The original Meta AI model (7B, 13B, 33B, 65B parameters)</li>
<li><strong>LLaMA 2</strong>: Improved version with longer context (7B, 13B, 70B parameters)</li>
<li><strong>LLaMA 3</strong>: Latest version with enhanced capabilities (8B, 70B parameters)</li>
<li><strong>Code LLaMA</strong>: Specialized for code generation and analysis</li>
</ul>
<h3 id="mistral-models"><a class="header" href="#mistral-models">Mistral Models</a></h3>
<ul>
<li><strong>Mistral 7B</strong>: Efficient base model with strong performance</li>
<li><strong>Mixtral 8x7B</strong>: Mixture-of-experts model with enhanced capabilities</li>
<li><strong>Mistral Instruct</strong>: Fine-tuned for instruction following</li>
<li><strong>Mistral Small</strong>: Smaller, faster models for resource-constrained environments</li>
</ul>
<h3 id="phi-models"><a class="header" href="#phi-models">Phi Models</a></h3>
<ul>
<li><strong>Phi-1</strong>: Microsoft’s small but capable model (1.3B parameters)</li>
<li><strong>Phi-2</strong>: Improved version with enhanced reasoning (2.7B parameters)</li>
<li><strong>Phi-3</strong>: Latest version with advanced capabilities (3.8B, 14B parameters)</li>
</ul>
<h3 id="other-supported-models"><a class="header" href="#other-supported-models">Other Supported Models</a></h3>
<ul>
<li><strong>GPT-J</strong>: EleutherAI’s open-source GPT model (6B parameters)</li>
<li><strong>GPT4All</strong>: Locally running assistant models</li>
<li><strong>Falcon</strong>: Technology Innovation Institute’s models</li>
<li><strong>MPT</strong>: MosaicML’s Pretrained Transformer models</li>
<li><strong>RWKV</strong>: RNN with transformer-like capabilities</li>
<li><strong>Qwen</strong>: Alibaba’s series of multilingual models</li>
</ul>
<h3 id="model-format-support"><a class="header" href="#model-format-support">Model Format Support</a></h3>
<ul>
<li><strong>GGUF</strong>: Primary supported format for efficient inference</li>
<li><strong>GGML</strong>: Legacy format (automatically converted to GGUF)</li>
<li><strong>ONNX</strong>: Support via external runtime</li>
</ul>
<h3 id="recommended-models-for-different-use-cases"><a class="header" href="#recommended-models-for-different-use-cases">Recommended Models for Different Use Cases</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Use Case</th><th>Recommended Model</th><th>Size</th><th>Performance</th></tr></thead><tbody>
<tr><td>Test Generation</td><td>Phi-2</td><td>2.7GB</td><td>Good balance of size and quality</td></tr>
<tr><td>Results Analysis</td><td>Mistral 7B</td><td>4.1GB</td><td>Strong reasoning capabilities</td></tr>
<tr><td>Improvement Suggestions</td><td>LLaMA 2 13B</td><td>8.2GB</td><td>Detailed, high-quality suggestions</td></tr>
<tr><td>Resource-Constrained</td><td>Phi-1</td><td>1.5GB</td><td>Works on machines with limited RAM</td></tr>
<tr><td>Best Quality</td><td>Mixtral 8x7B</td><td>26GB</td><td>Highest quality results (requires 32GB+ RAM)</td></tr>
</tbody></table>
</div>
<h3 id="where-to-download-models"><a class="header" href="#where-to-download-models">Where to Download Models</a></h3>
<p>Models can be downloaded from:</p>
<ul>
<li><a href="https://huggingface.co/models">Hugging Face</a> - Search for GGUF versions</li>
<li><a href="https://huggingface.co/TheBloke">TheBloke’s repositories</a> - Pre-converted GGUF models</li>
<li><a href="https://ollama.com/library">Ollama Library</a> - Easy model management</li>
</ul>
<h3 id="model-quantization-options"><a class="header" href="#model-quantization-options">Model Quantization Options</a></h3>
<p>QitOps supports various quantization levels to balance quality and resource usage:</p>
<div class="table-wrapper"><table><thead><tr><th>Quantization</th><th>File Size</th><th>RAM Usage</th><th>Quality</th><th>Speed</th></tr></thead><tbody>
<tr><td>Q4_K_M</td><td>Smallest</td><td>Lowest</td><td>Good</td><td>Fastest</td></tr>
<tr><td>Q5_K_M</td><td>Small</td><td>Low</td><td>Better</td><td>Fast</td></tr>
<tr><td>Q6_K</td><td>Medium</td><td>Medium</td><td>Very Good</td><td>Medium</td></tr>
<tr><td>Q8_0</td><td>Large</td><td>High</td><td>Excellent</td><td>Slower</td></tr>
</tbody></table>
</div>
<p>Example model selection with quantization:</p>
<pre><code class="language-bash"># Use a smaller, faster model
qitops generate --test-type api --description "Test the login API" --model phi --model-path models/phi-2.Q4_K_M.gguf

# Use a higher quality model
qitops analyze --results test_results.json --output analysis.md --model mistral --model-path models/mistral-7b.Q8_0.gguf
</code></pre>
<h2 id="local-llm-integration-options"><a class="header" href="#local-llm-integration-options">Local LLM Integration Options</a></h2>
<p>QitOps provides several ways to integrate with local LLMs:</p>
<h3 id="1-direct-model-loading"><a class="header" href="#1-direct-model-loading">1. Direct Model Loading</a></h3>
<p>Load models directly from local files:</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --model llama --model-path /path/to/model.gguf
</code></pre>
<h3 id="2-ollama-integration"><a class="header" href="#2-ollama-integration">2. Ollama Integration</a></h3>
<p>Connect to Ollama for local model inference:</p>
<pre><code class="language-bash"># Start Ollama server
ollama serve

# Pull a model
ollama pull llama2

# Use Ollama with QitOps
export QITOPS_OLLAMA_URL="http://localhost:11434"
qitops generate --test-type api --description "Test description" --model ollama:llama2
</code></pre>
<h3 id="3-custom-model-path"><a class="header" href="#3-custom-model-path">3. Custom Model Path</a></h3>
<p>Specify a custom path to your model files:</p>
<pre><code class="language-bash">qitops generate --test-type api --description "Test description" --model custom --model-path /path/to/custom/model.gguf
</code></pre>
<h2 id="offline-operation"><a class="header" href="#offline-operation">Offline Operation</a></h2>
<p>QitOps AI features can work completely offline:</p>
<pre><code class="language-bash"># Set environment variables for offline mode
export QITOPS_OFFLINE=true
export QITOPS_MODEL_PATH="/path/to/model.gguf"

# Run AI features offline
qitops analyze --results test_results.json --output analysis.md
</code></pre>
<h2 id="ai-features-2"><a class="header" href="#ai-features-2">AI Features</a></h2>
<h2 id="test-configuration-generation"><a class="header" href="#test-configuration-generation">Test Configuration Generation</a></h2>
<p>QitOps can automatically generate test configurations from natural language descriptions, saving you time and effort in creating test files manually. This feature leverages local LLMs to understand your testing requirements and produce appropriate JSON configurations.</p>
<h3 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h3>
<ol>
<li>You provide a natural language description of the test you want to create</li>
<li>QitOps processes this description using a local LLM</li>
<li>The LLM generates a complete JSON configuration file based on your description</li>
<li>The configuration is saved to the specified output file</li>
</ol>
<h3 id="basic-usage-5"><a class="header" href="#basic-usage-5">Basic Usage</a></h3>
<pre><code class="language-bash"># Generate an API test configuration
qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output github_test.json

# Generate a performance test configuration
qitops generate --test-type performance --description "Load test for an e-commerce checkout API with 100 concurrent users" --output perf_test.json

# Generate a security test configuration
qitops generate --test-type security --description "Security scan for a banking API" --output security_test.json

# Generate a web test configuration
qitops generate --test-type web --description "Test the checkout flow of an e-commerce website" --output web_test.json
</code></pre>
<h3 id="command-line-options-6"><a class="header" href="#command-line-options-6">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--test-type &lt;TYPE&gt;</code></td><td>Type of test to generate (api, performance, security, web)</td></tr>
<tr><td><code>--description &lt;TEXT&gt;</code></td><td>Natural language description of the test</td></tr>
<tr><td><code>--output &lt;FILE&gt;</code></td><td>Output file for the generated configuration</td></tr>
<tr><td><code>--model &lt;MODEL&gt;</code></td><td>LLM model to use (default: auto)</td></tr>
<tr><td><code>--model-path &lt;PATH&gt;</code></td><td>Path to the model file</td></tr>
<tr><td><code>--temperature &lt;FLOAT&gt;</code></td><td>Temperature for generation (0.0-1.0)</td></tr>
<tr><td><code>--context-size &lt;INT&gt;</code></td><td>Context size in tokens</td></tr>
<tr><td><code>--max-tokens &lt;INT&gt;</code></td><td>Maximum tokens for generation</td></tr>
<tr><td><code>--system-prompt &lt;TEXT&gt;</code></td><td>Custom system prompt for the model</td></tr>
</tbody></table>
</div>
<h3 id="writing-effective-descriptions"><a class="header" href="#writing-effective-descriptions">Writing Effective Descriptions</a></h3>
<p>The quality of the generated configuration depends on the clarity and specificity of your description. Here are some tips for writing effective descriptions:</p>
<h4 id="for-api-tests"><a class="header" href="#for-api-tests">For API Tests:</a></h4>
<ul>
<li>Specify the endpoint URL and HTTP method</li>
<li>Mention any required headers or authentication</li>
<li>Describe the expected response status and content</li>
<li>Include any specific validation requirements</li>
</ul>
<p>Example: “Test the GitHub API to fetch user information for ‘octocat’ using GET request to /users/octocat endpoint. Verify that the response status is 200 and the response contains the correct login name and user type.”</p>
<h4 id="for-performance-tests"><a class="header" href="#for-performance-tests">For Performance Tests:</a></h4>
<ul>
<li>Specify the target URL and HTTP method</li>
<li>Mention the number of concurrent users</li>
<li>Describe the test duration and ramp-up time</li>
<li>Include any performance thresholds</li>
</ul>
<p>Example: “Load test the checkout API at https://api.example.com/checkout with 100 concurrent users for 5 minutes. Use a 30-second ramp-up time. The API should handle at least 50 requests per second with a response time under 200ms.”</p>
<h4 id="for-security-tests"><a class="header" href="#for-security-tests">For Security Tests:</a></h4>
<ul>
<li>Specify the target URL or application</li>
<li>Mention the types of security checks to perform</li>
<li>Describe any authentication requirements</li>
<li>Include any specific vulnerability concerns</li>
</ul>
<p>Example: “Security scan the banking API at https://api.bank.com/v1 focusing on SQL injection, XSS, and authentication vulnerabilities. Use Bearer token authentication and check for sensitive data exposure in responses.”</p>
<h4 id="for-web-tests"><a class="header" href="#for-web-tests">For Web Tests:</a></h4>
<ul>
<li>Specify the target website URL</li>
<li>Describe the user journey or actions to test</li>
<li>Mention any specific elements to interact with</li>
<li>Include validation criteria</li>
</ul>
<p>Example: “Test the checkout flow of an e-commerce website at https://shop.example.com. Add a product to the cart, proceed to checkout, fill in shipping and payment information, and complete the purchase. Verify that the order confirmation page shows the correct order details.”</p>
<h3 id="example-generated-configurations"><a class="header" href="#example-generated-configurations">Example Generated Configurations</a></h3>
<h4 id="api-test-configuration-2"><a class="header" href="#api-test-configuration-2">API Test Configuration</a></h4>
<pre><code class="language-json">{
  "name": "GitHub User API Test",
  "description": "Test the GitHub API to fetch user information",
  "url": "https://api.github.com/users/octocat",
  "method": "GET",
  "headers": {
    "Accept": "application/vnd.github.v3+json",
    "User-Agent": "QitOps-Test"
  },
  "expected_status": 200,
  "expected_body": {
    "login": "octocat",
    "type": "User"
  },
  "timeout": 30,
  "retries": 3
}
</code></pre>
<h4 id="performance-test-configuration-2"><a class="header" href="#performance-test-configuration-2">Performance Test Configuration</a></h4>
<pre><code class="language-json">{
  "name": "E-commerce Checkout API Load Test",
  "description": "Load test for an e-commerce checkout API with 100 concurrent users",
  "target_url": "https://api.example.com/checkout",
  "method": "POST",
  "headers": {
    "Content-Type": "application/json",
    "Accept": "application/json"
  },
  "body": {
    "cart_id": "{{cart_id}}",
    "payment_method": "credit_card",
    "shipping_method": "standard"
  },
  "concurrent_users": 100,
  "duration_secs": 300,
  "ramp_up_time_secs": 30,
  "success_threshold": 95.0,
  "max_response_time_ms": 200,
  "requests_per_second_threshold": 50
}
</code></pre>
<h3 id="customizing-generation"><a class="header" href="#customizing-generation">Customizing Generation</a></h3>
<p>You can customize the generation process by adjusting the model parameters:</p>
<pre><code class="language-bash"># Use a specific model with custom parameters
qitops generate --test-type api \
  --description "Test the login API with different credentials" \
  --output login_test.json \
  --model llama \
  --model-path models/llama-2-7b.gguf \
  --temperature 0.8 \
  --context-size 4096 \
  --max-tokens 2048
</code></pre>
<h3 id="post-generation-editing"><a class="header" href="#post-generation-editing">Post-Generation Editing</a></h3>
<p>Generated configurations are meant to be starting points. You may want to:</p>
<ol>
<li>Review and edit the generated configuration</li>
<li>Add or modify specific fields</li>
<li>Adjust validation criteria</li>
<li>Add environment-specific variables</li>
</ol>
<h3 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h3>
<ul>
<li>Start with detailed, specific descriptions</li>
<li>Review generated configurations before using them</li>
<li>Use lower temperature (0.3-0.5) for more deterministic results</li>
<li>Use higher temperature (0.7-0.9) for more creative variations</li>
<li>Keep descriptions focused on one test scenario at a time</li>
<li>Specify concrete details like URLs, methods, and expected responses</li>
<li>Use the generated configurations as starting points, not final products</li>
</ul>
<h2 id="test-results-analysis"><a class="header" href="#test-results-analysis">Test Results Analysis</a></h2>
<p>QitOps can analyze your test results using AI to identify patterns, issues, and insights that might not be immediately obvious. This feature helps you understand test outcomes and make data-driven decisions about your testing strategy.</p>
<h3 id="how-it-works-1"><a class="header" href="#how-it-works-1">How It Works</a></h3>
<ol>
<li>You provide a JSON file containing test results</li>
<li>QitOps processes these results using a local LLM</li>
<li>The LLM generates a comprehensive analysis report</li>
<li>The analysis is saved to the specified output file (typically in Markdown format)</li>
</ol>
<h3 id="basic-usage-6"><a class="header" href="#basic-usage-6">Basic Usage</a></h3>
<pre><code class="language-bash"># Analyze test results
qitops analyze --results test_results.json --output analysis.md

# Analyze with a specific model
qitops analyze --results test_results.json --output analysis.md --model llama --model-path /path/to/model.gguf
</code></pre>
<h3 id="command-line-options-7"><a class="header" href="#command-line-options-7">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--results &lt;FILE&gt;</code></td><td>JSON file containing test results</td></tr>
<tr><td><code>--output &lt;FILE&gt;</code></td><td>Output file for the analysis report</td></tr>
<tr><td><code>--model &lt;MODEL&gt;</code></td><td>LLM model to use (default: auto)</td></tr>
<tr><td><code>--model-path &lt;PATH&gt;</code></td><td>Path to the model file</td></tr>
<tr><td><code>--format &lt;FORMAT&gt;</code></td><td>Output format (markdown, html, json)</td></tr>
<tr><td><code>--temperature &lt;FLOAT&gt;</code></td><td>Temperature for generation (0.0-1.0)</td></tr>
<tr><td><code>--context-size &lt;INT&gt;</code></td><td>Context size in tokens</td></tr>
<tr><td><code>--max-tokens &lt;INT&gt;</code></td><td>Maximum tokens for generation</td></tr>
<tr><td><code>--system-prompt &lt;TEXT&gt;</code></td><td>Custom system prompt for the model</td></tr>
</tbody></table>
</div>
<h3 id="analysis-content"><a class="header" href="#analysis-content">Analysis Content</a></h3>
<p>The generated analysis report typically includes:</p>
<h4 id="1-executive-summary"><a class="header" href="#1-executive-summary">1. Executive Summary</a></h4>
<ul>
<li>Overall success rate</li>
<li>Number of tests run</li>
<li>Key findings and insights</li>
<li>Critical issues identified</li>
</ul>
<h4 id="2-test-results-overview"><a class="header" href="#2-test-results-overview">2. Test Results Overview</a></h4>
<ul>
<li>Distribution of test statuses (success, failure, error)</li>
<li>Average response times</li>
<li>Success rates by test type</li>
<li>Temporal patterns (if timestamps are available)</li>
</ul>
<h4 id="3-detailed-breakdown"><a class="header" href="#3-detailed-breakdown">3. Detailed Breakdown</a></h4>
<ul>
<li>Analysis of each failed test</li>
<li>Common failure patterns</li>
<li>Root cause analysis</li>
<li>Error categorization</li>
</ul>
<h4 id="4-performance-analysis"><a class="header" href="#4-performance-analysis">4. Performance Analysis</a></h4>
<ul>
<li>Response time statistics</li>
<li>Performance bottlenecks</li>
<li>Throughput analysis</li>
<li>Resource utilization patterns</li>
</ul>
<h4 id="5-recommendations"><a class="header" href="#5-recommendations">5. Recommendations</a></h4>
<ul>
<li>Suggestions for fixing failed tests</li>
<li>Performance optimization opportunities</li>
<li>Test coverage improvements</li>
<li>Testing strategy recommendations</li>
</ul>
<h3 id="example-analysis-report"><a class="header" href="#example-analysis-report">Example Analysis Report</a></h3>
<pre><code class="language-markdown"># Test Results Analysis

## Executive Summary

Analyzed 25 test results with an overall success rate of 84% (21/25 tests passed).
The average response time was 187ms, with 3 tests exceeding the 500ms threshold.
The main issues were related to authentication failures and timeout errors.

## Test Results Overview

| Status | Count | Percentage |
|--------|-------|------------|
| Success | 21 | 84% |
| Failure | 3 | 12% |
| Error | 1 | 4% |

### Success Rate by Test Type
- API Tests: 90% (18/20)
- Performance Tests: 75% (3/4)
- Security Tests: 0% (0/1)

## Detailed Breakdown

### Failed Tests Analysis

1. **API-Test-003**: Authentication failure
   - Error: "Unauthorized (401)"
   - Possible cause: Expired API token or incorrect credentials
   - Recommendation: Verify and update the authentication token

2. **API-Test-012**: Unexpected response format
   - Error: "Expected field 'user_id' not found in response"
   - Possible cause: API response structure has changed
   - Recommendation: Update the expected response structure in the test configuration

3. **Perf-Test-002**: Timeout error
   - Error: "Request timed out after 30 seconds"
   - Possible cause: Server under heavy load or network issues
   - Recommendation: Increase the timeout threshold or investigate server performance

## Performance Analysis

- 90th percentile response time: 342ms
- Slowest endpoint: /api/users/search (avg: 412ms)
- Fastest endpoint: /api/health (avg: 42ms)
- 3 tests exceeded the 500ms threshold

## Recommendations

1. **Fix Authentication Issues**
   - Implement token refresh mechanism
   - Add pre-test validation of authentication credentials

2. **Improve Error Handling**
   - Add more specific assertions for response structure
   - Implement retry logic for transient failures

3. **Performance Optimization**
   - Review the /api/users/search endpoint for optimization opportunities
   - Consider caching frequently accessed resources
   - Implement pagination for large result sets

4. **Test Coverage Improvements**
   - Add more security tests (currently only 1)
   - Increase test coverage for error conditions
   - Add tests for edge cases identified in this analysis
</code></pre>
<h3 id="input-format-requirements"><a class="header" href="#input-format-requirements">Input Format Requirements</a></h3>
<p>The analysis feature expects test results in a specific JSON format:</p>
<pre><code class="language-json">[
  {
    "test_id": "api-test-001",
    "name": "User API Test",
    "description": "Test the user API endpoint",
    "timestamp": "2025-05-10T12:34:56Z",
    "duration_ms": 156,
    "status": "success",
    "url": "https://api.example.com/users/123",
    "method": "GET",
    "request_headers": {
      "Accept": "application/json",
      "Authorization": "Bearer token123"
    },
    "response_status": 200,
    "response_headers": {
      "content-type": "application/json"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 200,
        "result": "pass"
      },
      {
        "type": "json",
        "path": "$.id",
        "expected": 123,
        "actual": 123,
        "result": "pass"
      }
    ]
  },
  {
    "test_id": "api-test-002",
    "name": "Invalid User API Test",
    "description": "Test the user API with invalid ID",
    "timestamp": "2025-05-10T12:35:12Z",
    "duration_ms": 134,
    "status": "failure",
    "url": "https://api.example.com/users/999",
    "method": "GET",
    "request_headers": {
      "Accept": "application/json",
      "Authorization": "Bearer token123"
    },
    "response_status": 404,
    "response_headers": {
      "content-type": "application/json"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 404,
        "result": "fail"
      }
    ],
    "error": "Expected status 200 but got 404"
  }
]
</code></pre>
<h3 id="best-practices-7"><a class="header" href="#best-practices-7">Best Practices</a></h3>
<ul>
<li>Include as much detail as possible in your test results</li>
<li>Run analysis after each test suite execution</li>
<li>Compare analyses over time to identify trends</li>
<li>Use the analysis to prioritize test improvements</li>
<li>Share analysis reports with your team for collaborative debugging</li>
<li>Customize the analysis by adjusting the temperature parameter</li>
<li>Use lower temperatures (0.3-0.5) for more factual, concise analyses</li>
<li>Use higher temperatures (0.7-0.9) for more creative, detailed analyses</li>
</ul>
<h2 id="improvement-suggestions"><a class="header" href="#improvement-suggestions">Improvement Suggestions</a></h2>
<p>QitOps can generate actionable suggestions to improve your tests based on test results and industry best practices. This feature helps you continuously enhance your testing strategy and address issues before they become critical problems.</p>
<h3 id="how-it-works-2"><a class="header" href="#how-it-works-2">How It Works</a></h3>
<ol>
<li>You provide a JSON file containing test results</li>
<li>QitOps analyzes these results using a local LLM</li>
<li>The LLM generates specific, actionable improvement suggestions</li>
<li>The suggestions are saved to the specified output file</li>
</ol>
<h3 id="basic-usage-7"><a class="header" href="#basic-usage-7">Basic Usage</a></h3>
<pre><code class="language-bash"># Generate improvement suggestions
qitops improve --results test_results.json --output improvements.md

# Generate suggestions with a specific model
qitops improve --results test_results.json --output improvements.md --model llama --model-path /path/to/model.gguf
</code></pre>
<h3 id="command-line-options-8"><a class="header" href="#command-line-options-8">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--results &lt;FILE&gt;</code></td><td>JSON file containing test results</td></tr>
<tr><td><code>--output &lt;FILE&gt;</code></td><td>Output file for the improvement suggestions</td></tr>
<tr><td><code>--model &lt;MODEL&gt;</code></td><td>LLM model to use (default: auto)</td></tr>
<tr><td><code>--model-path &lt;PATH&gt;</code></td><td>Path to the model file</td></tr>
<tr><td><code>--format &lt;FORMAT&gt;</code></td><td>Output format (markdown, html, json)</td></tr>
<tr><td><code>--focus &lt;AREA&gt;</code></td><td>Focus area for suggestions (performance, reliability, coverage, all)</td></tr>
<tr><td><code>--temperature &lt;FLOAT&gt;</code></td><td>Temperature for generation (0.0-1.0)</td></tr>
<tr><td><code>--context-size &lt;INT&gt;</code></td><td>Context size in tokens</td></tr>
<tr><td><code>--max-tokens &lt;INT&gt;</code></td><td>Maximum tokens for generation</td></tr>
<tr><td><code>--system-prompt &lt;TEXT&gt;</code></td><td>Custom system prompt for the model</td></tr>
</tbody></table>
</div>
<h3 id="improvement-categories"><a class="header" href="#improvement-categories">Improvement Categories</a></h3>
<p>The generated suggestions typically cover the following areas:</p>
<h4 id="1-performance-optimizations"><a class="header" href="#1-performance-optimizations">1. Performance Optimizations</a></h4>
<ul>
<li>Response time improvements</li>
<li>Resource utilization efficiency</li>
<li>Concurrency and parallelism recommendations</li>
<li>Caching strategies</li>
<li>Database query optimizations</li>
<li>Network latency reduction</li>
</ul>
<h4 id="2-reliability-enhancements"><a class="header" href="#2-reliability-enhancements">2. Reliability Enhancements</a></h4>
<ul>
<li>Error handling improvements</li>
<li>Retry mechanisms</li>
<li>Timeout configurations</li>
<li>Fault tolerance strategies</li>
<li>Resilience patterns</li>
<li>Circuit breaker implementations</li>
</ul>
<h4 id="3-coverage-improvements"><a class="header" href="#3-coverage-improvements">3. Coverage Improvements</a></h4>
<ul>
<li>Missing test scenarios</li>
<li>Edge case coverage</li>
<li>Error condition testing</li>
<li>Boundary value testing</li>
<li>Security vulnerability testing</li>
<li>Cross-functional testing</li>
</ul>
<h4 id="4-best-practices"><a class="header" href="#4-best-practices">4. Best Practices</a></h4>
<ul>
<li>Test organization and structure</li>
<li>Naming conventions</li>
<li>Documentation improvements</li>
<li>Assertion strategies</li>
<li>Test data management</li>
<li>CI/CD integration</li>
</ul>
<h3 id="example-improvement-suggestions"><a class="header" href="#example-improvement-suggestions">Example Improvement Suggestions</a></h3>
<pre><code class="language-markdown"># Test Improvement Suggestions

## Executive Summary

Based on the analysis of 25 test results, we've identified several opportunities for improvement across performance, reliability, coverage, and best practices. Implementing these suggestions will help enhance the effectiveness and efficiency of your testing suite.

## Performance Optimizations

1. **Optimize Slow Endpoints**
   - The `/api/users/search` endpoint has an average response time of 412ms, which is significantly higher than other endpoints.
   - Suggestion: Review the implementation of this endpoint, focusing on database query optimization and potential caching.
   - Implementation: Add query indexing for frequently searched fields and implement a Redis cache for common search queries.

2. **Implement Connection Pooling**
   - Multiple tests show connection establishment overhead.
   - Suggestion: Implement connection pooling to reuse connections across tests.
   - Implementation: Configure a connection pool with appropriate min/max settings based on your concurrency requirements.

3. **Reduce Payload Sizes**
   - Several API responses exceed 100KB in size.
   - Suggestion: Implement pagination and field filtering to reduce payload sizes.
   - Implementation: Add `limit`, `offset`, and `fields` query parameters to your API endpoints.

## Reliability Enhancements

1. **Improve Authentication Handling**
   - 3 tests failed due to authentication issues.
   - Suggestion: Implement token refresh and pre-test authentication validation.
   - Implementation: Add a token refresh mechanism that automatically renews expired tokens before test execution.

2. **Add Retry Logic for Transient Failures**
   - Several timeout errors appear to be transient.
   - Suggestion: Implement exponential backoff retry logic for network-related failures.
   - Implementation: Add a retry decorator/wrapper that retries failed requests with increasing delays.

3. **Enhance Error Handling**
   - Error messages are inconsistent and sometimes not actionable.
   - Suggestion: Standardize error handling and improve error messages.
   - Implementation: Create a centralized error handler that provides consistent, detailed error information.

## Coverage Improvements

1. **Add Security Testing**
   - Only 1 security test was found in the results.
   - Suggestion: Expand security testing to cover authentication, authorization, input validation, and data protection.
   - Implementation: Add tests for OWASP Top 10 vulnerabilities relevant to your application.

2. **Increase Edge Case Coverage**
   - Most tests focus on happy paths with valid inputs.
   - Suggestion: Add tests for boundary conditions, invalid inputs, and error scenarios.
   - Implementation: For each API endpoint, add tests with empty values, extremely large values, special characters, and malformed requests.

3. **Add Load and Stress Testing**
   - Current performance tests use relatively low concurrency (max 100 users).
   - Suggestion: Add high-concurrency load tests and stress tests to identify breaking points.
   - Implementation: Create load test scenarios with gradually increasing concurrency until performance degrades.

## Best Practices

1. **Improve Test Organization**
   - Tests are not consistently organized by feature or functionality.
   - Suggestion: Reorganize tests into logical groups based on functionality.
   - Implementation: Create a directory structure that mirrors your application's architecture.

2. **Enhance Test Data Management**
   - Test data is hardcoded in many tests.
   - Suggestion: Implement a test data management strategy with fixtures or factories.
   - Implementation: Create a test data generator that produces consistent, realistic test data.

3. **Add Documentation**
   - Many tests lack clear documentation about their purpose and expected behavior.
   - Suggestion: Add descriptive comments and documentation to all tests.
   - Implementation: Standardize on a documentation format that includes purpose, prerequisites, and expected outcomes.

## Implementation Roadmap

We recommend implementing these improvements in the following order:

1. **Immediate (1-2 weeks)**
   - Fix authentication handling issues
   - Add retry logic for transient failures
   - Improve error messages

2. **Short-term (2-4 weeks)**
   - Optimize slow endpoints
   - Enhance test organization
   - Add basic security tests

3. **Medium-term (1-3 months)**
   - Implement connection pooling
   - Add edge case coverage
   - Improve test data management

4. **Long-term (3+ months)**
   - Reduce payload sizes
   - Add comprehensive load and stress testing
   - Enhance documentation
</code></pre>
<h3 id="integration-with-cicd-5"><a class="header" href="#integration-with-cicd-5">Integration with CI/CD</a></h3>
<p>You can integrate the improvement suggestions feature into your CI/CD pipeline to automatically generate suggestions after test runs:</p>
<pre><code class="language-yaml"># Example GitHub Actions workflow step
- name: Generate Test Improvement Suggestions
  run: |
    qitops improve --results test-results.json --output improvements.md

- name: Upload Improvement Suggestions
  uses: actions/upload-artifact@v2
  with:
    name: test-improvements
    path: improvements.md
</code></pre>
<h3 id="best-practices-8"><a class="header" href="#best-practices-8">Best Practices</a></h3>
<ul>
<li>Run the improvement suggestions tool regularly (weekly or after major test runs)</li>
<li>Prioritize suggestions based on their impact and implementation effort</li>
<li>Create tickets or tasks for implementing high-priority suggestions</li>
<li>Track the implementation of suggestions over time</li>
<li>Re-run the tool after implementing suggestions to measure progress</li>
<li>Customize the focus area based on your current priorities</li>
<li>Use the suggestions as input for sprint planning and technical debt discussions</li>
<li>Share the suggestions with your team to foster a culture of continuous improvement</li>
</ul>
<h2 id="model-parameter-customization"><a class="header" href="#model-parameter-customization">Model Parameter Customization</a></h2>
<p>Customize model parameters to fine-tune the AI behavior:</p>
<pre><code class="language-bash"># Set temperature (controls randomness, 0.0-1.0)
qitops generate --test-type api --description "Test description" --temperature 0.7

# Set context size (in tokens)
qitops generate --test-type api --description "Test description" --context-size 4096

# Set maximum tokens for generation
qitops generate --test-type api --description "Test description" --max-tokens 2048

# Set system prompt
qitops generate --test-type api --description "Test description" --system-prompt "You are a testing expert."
</code></pre>
<h2 id="testing-ai-features-1"><a class="header" href="#testing-ai-features-1">Testing AI Features</a></h2>
<p>You can test the AI features using the provided test script:</p>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/qitops/qitops-cli-tools.git
cd qitops-cli-tools

# Build with AI features
cargo build --features ai

# Run the test script
./test_local_ai.sh
</code></pre>
<p>The test script will:</p>
<ol>
<li>Set up environment variables for offline mode</li>
<li>Create a directory for test outputs</li>
<li>Test all AI features (generation, analysis, improvement)</li>
<li>Show the generated files</li>
</ol>
<h2 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h2>
<h3 id="model-loading-issues"><a class="header" href="#model-loading-issues">Model Loading Issues</a></h3>
<p>If you encounter issues loading a model:</p>
<pre><code class="language-bash"># Check if the model file exists
ls -la /path/to/model.gguf

# Try a different model format
qitops generate --test-type api --description "Test description" --model llama --model-path /path/to/different/model.gguf
</code></pre>
<h3 id="ollama-connection-issues"><a class="header" href="#ollama-connection-issues">Ollama Connection Issues</a></h3>
<p>If you have trouble connecting to Ollama:</p>
<pre><code class="language-bash"># Check if Ollama is running
curl http://localhost:11434/api/version

# Check available models
ollama list

# Pull the model if it's not available
ollama pull llama2
</code></pre>
<h3 id="memory-issues"><a class="header" href="#memory-issues">Memory Issues</a></h3>
<p>If you encounter memory issues with large models:</p>
<pre><code class="language-bash"># Use a smaller model
qitops generate --test-type api --description "Test description" --model phi --model-path /path/to/phi-2.gguf

# Reduce context size
qitops generate --test-type api --description "Test description" --context-size 2048
</code></pre>
<h2 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h2>
<p>QitOps supports the following environment variables for AI features:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Default</th></tr></thead><tbody>
<tr><td><code>QITOPS_OFFLINE</code></td><td>Run in offline mode</td><td><code>false</code></td></tr>
<tr><td><code>QITOPS_MODEL_PATH</code></td><td>Path to the model file</td><td>None</td></tr>
<tr><td><code>QITOPS_OLLAMA_URL</code></td><td>URL for Ollama server</td><td><code>http://localhost:11434</code></td></tr>
<tr><td><code>QITOPS_TEMPERATURE</code></td><td>Temperature for generation</td><td><code>0.7</code></td></tr>
<tr><td><code>QITOPS_CONTEXT_SIZE</code></td><td>Context size in tokens</td><td><code>4096</code></td></tr>
<tr><td><code>QITOPS_MAX_TOKENS</code></td><td>Maximum tokens for generation</td><td><code>2048</code></td></tr>
<tr><td><code>QITOPS_SYSTEM_PROMPT</code></td><td>System prompt for the model</td><td>Default system prompt</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="test-configuration-generation"><a class="header" href="#test-configuration-generation">Test Configuration Generation</a></h1>
<p>QitOps can automatically generate test configurations from natural language descriptions, saving you time and effort in creating test files manually. This feature leverages local LLMs to understand your testing requirements and produce appropriate JSON configurations.</p>
<h2 id="how-it-works-3"><a class="header" href="#how-it-works-3">How It Works</a></h2>
<ol>
<li>You provide a natural language description of the test you want to create</li>
<li>QitOps processes this description using a local LLM</li>
<li>The LLM generates a complete JSON configuration file based on your description</li>
<li>The configuration is saved to the specified output file</li>
</ol>
<h2 id="basic-usage-8"><a class="header" href="#basic-usage-8">Basic Usage</a></h2>
<pre><code class="language-bash"># Generate an API test configuration
qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output github_test.json

# Generate a performance test configuration
qitops generate --test-type performance --description "Load test for an e-commerce checkout API with 100 concurrent users" --output perf_test.json

# Generate a security test configuration
qitops generate --test-type security --description "Security scan for a banking API" --output security_test.json

# Generate a web test configuration
qitops generate --test-type web --description "Test the checkout flow of an e-commerce website" --output web_test.json
</code></pre>
<h2 id="command-line-options-9"><a class="header" href="#command-line-options-9">Command-Line Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--test-type &lt;TYPE&gt;</code></td><td>Type of test to generate (api, performance, security, web)</td></tr>
<tr><td><code>--description &lt;TEXT&gt;</code></td><td>Natural language description of the test</td></tr>
<tr><td><code>--output &lt;FILE&gt;</code></td><td>Output file for the generated configuration</td></tr>
<tr><td><code>--model &lt;MODEL&gt;</code></td><td>LLM model to use (default: auto)</td></tr>
<tr><td><code>--model-path &lt;PATH&gt;</code></td><td>Path to the model file</td></tr>
<tr><td><code>--temperature &lt;FLOAT&gt;</code></td><td>Temperature for generation (0.0-1.0)</td></tr>
<tr><td><code>--context-size &lt;INT&gt;</code></td><td>Context size in tokens</td></tr>
<tr><td><code>--max-tokens &lt;INT&gt;</code></td><td>Maximum tokens for generation</td></tr>
<tr><td><code>--system-prompt &lt;TEXT&gt;</code></td><td>Custom system prompt for the model</td></tr>
</tbody></table>
</div>
<h2 id="writing-effective-descriptions-1"><a class="header" href="#writing-effective-descriptions-1">Writing Effective Descriptions</a></h2>
<p>The quality of the generated configuration depends on the clarity and specificity of your description. Here are some tips for writing effective descriptions:</p>
<h3 id="for-api-tests-1"><a class="header" href="#for-api-tests-1">For API Tests:</a></h3>
<ul>
<li>Specify the endpoint URL and HTTP method</li>
<li>Mention any required headers or authentication</li>
<li>Describe the expected response status and content</li>
<li>Include any specific validation requirements</li>
</ul>
<p>Example: “Test the GitHub API to fetch user information for ‘octocat’ using GET request to /users/octocat endpoint. Verify that the response status is 200 and the response contains the correct login name and user type.”</p>
<h3 id="for-performance-tests-1"><a class="header" href="#for-performance-tests-1">For Performance Tests:</a></h3>
<ul>
<li>Specify the target URL and HTTP method</li>
<li>Mention the number of concurrent users</li>
<li>Describe the test duration and ramp-up time</li>
<li>Include any performance thresholds</li>
</ul>
<p>Example: “Load test the checkout API at https://api.example.com/checkout with 100 concurrent users for 5 minutes. Use a 30-second ramp-up time. The API should handle at least 50 requests per second with a response time under 200ms.”</p>
<h3 id="for-security-tests-1"><a class="header" href="#for-security-tests-1">For Security Tests:</a></h3>
<ul>
<li>Specify the target URL or application</li>
<li>Mention the types of security checks to perform</li>
<li>Describe any authentication requirements</li>
<li>Include any specific vulnerability concerns</li>
</ul>
<p>Example: “Security scan the banking API at https://api.bank.com/v1 focusing on SQL injection, XSS, and authentication vulnerabilities. Use Bearer token authentication and check for sensitive data exposure in responses.”</p>
<h3 id="for-web-tests-1"><a class="header" href="#for-web-tests-1">For Web Tests:</a></h3>
<ul>
<li>Specify the target website URL</li>
<li>Describe the user journey or actions to test</li>
<li>Mention any specific elements to interact with</li>
<li>Include validation criteria</li>
</ul>
<p>Example: “Test the checkout flow of an e-commerce website at https://shop.example.com. Add a product to the cart, proceed to checkout, fill in shipping and payment information, and complete the purchase. Verify that the order confirmation page shows the correct order details.”</p>
<h2 id="example-generated-configurations-1"><a class="header" href="#example-generated-configurations-1">Example Generated Configurations</a></h2>
<h3 id="api-test-configuration-3"><a class="header" href="#api-test-configuration-3">API Test Configuration</a></h3>
<pre><code class="language-json">{
  "name": "GitHub User API Test",
  "description": "Test the GitHub API to fetch user information",
  "url": "https://api.github.com/users/octocat",
  "method": "GET",
  "headers": {
    "Accept": "application/vnd.github.v3+json",
    "User-Agent": "QitOps-Test"
  },
  "expected_status": 200,
  "expected_body": {
    "login": "octocat",
    "type": "User"
  },
  "timeout": 30,
  "retries": 3
}
</code></pre>
<h3 id="performance-test-configuration-3"><a class="header" href="#performance-test-configuration-3">Performance Test Configuration</a></h3>
<pre><code class="language-json">{
  "name": "E-commerce Checkout API Load Test",
  "description": "Load test for an e-commerce checkout API with 100 concurrent users",
  "target_url": "https://api.example.com/checkout",
  "method": "POST",
  "headers": {
    "Content-Type": "application/json",
    "Accept": "application/json"
  },
  "body": {
    "cart_id": "{{cart_id}}",
    "payment_method": "credit_card",
    "shipping_method": "standard"
  },
  "concurrent_users": 100,
  "duration_secs": 300,
  "ramp_up_time_secs": 30,
  "success_threshold": 95.0,
  "max_response_time_ms": 200,
  "requests_per_second_threshold": 50
}
</code></pre>
<h2 id="customizing-generation-1"><a class="header" href="#customizing-generation-1">Customizing Generation</a></h2>
<p>You can customize the generation process by adjusting the model parameters:</p>
<pre><code class="language-bash"># Use a specific model with custom parameters
qitops generate --test-type api \
  --description "Test the login API with different credentials" \
  --output login_test.json \
  --model llama \
  --model-path models/llama-2-7b.gguf \
  --temperature 0.8 \
  --context-size 4096 \
  --max-tokens 2048
</code></pre>
<h2 id="post-generation-editing-1"><a class="header" href="#post-generation-editing-1">Post-Generation Editing</a></h2>
<p>Generated configurations are meant to be starting points. You may want to:</p>
<ol>
<li>Review and edit the generated configuration</li>
<li>Add or modify specific fields</li>
<li>Adjust validation criteria</li>
<li>Add environment-specific variables</li>
</ol>
<h2 id="best-practices-9"><a class="header" href="#best-practices-9">Best Practices</a></h2>
<ul>
<li>Start with detailed, specific descriptions</li>
<li>Review generated configurations before using them</li>
<li>Use lower temperature (0.3-0.5) for more deterministic results</li>
<li>Use higher temperature (0.7-0.9) for more creative variations</li>
<li>Keep descriptions focused on one test scenario at a time</li>
<li>Specify concrete details like URLs, methods, and expected responses</li>
<li>Use the generated configurations as starting points, not final products</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="test-results-analysis"><a class="header" href="#test-results-analysis">Test Results Analysis</a></h1>
<p>QitOps can analyze your test results using AI to identify patterns, issues, and insights that might not be immediately obvious. This feature helps you understand test outcomes and make data-driven decisions about your testing strategy.</p>
<h2 id="how-it-works-4"><a class="header" href="#how-it-works-4">How It Works</a></h2>
<ol>
<li>You provide a JSON file containing test results</li>
<li>QitOps processes these results using a local LLM</li>
<li>The LLM generates a comprehensive analysis report</li>
<li>The analysis is saved to the specified output file (typically in Markdown format)</li>
</ol>
<h2 id="basic-usage-9"><a class="header" href="#basic-usage-9">Basic Usage</a></h2>
<pre><code class="language-bash"># Analyze test results
qitops analyze --results test_results.json --output analysis.md

# Analyze with a specific model
qitops analyze --results test_results.json --output analysis.md --model llama --model-path /path/to/model.gguf
</code></pre>
<h2 id="command-line-options-10"><a class="header" href="#command-line-options-10">Command-Line Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--results &lt;FILE&gt;</code></td><td>JSON file containing test results</td></tr>
<tr><td><code>--output &lt;FILE&gt;</code></td><td>Output file for the analysis report</td></tr>
<tr><td><code>--model &lt;MODEL&gt;</code></td><td>LLM model to use (default: auto)</td></tr>
<tr><td><code>--model-path &lt;PATH&gt;</code></td><td>Path to the model file</td></tr>
<tr><td><code>--format &lt;FORMAT&gt;</code></td><td>Output format (markdown, html, json)</td></tr>
<tr><td><code>--temperature &lt;FLOAT&gt;</code></td><td>Temperature for generation (0.0-1.0)</td></tr>
<tr><td><code>--context-size &lt;INT&gt;</code></td><td>Context size in tokens</td></tr>
<tr><td><code>--max-tokens &lt;INT&gt;</code></td><td>Maximum tokens for generation</td></tr>
<tr><td><code>--system-prompt &lt;TEXT&gt;</code></td><td>Custom system prompt for the model</td></tr>
</tbody></table>
</div>
<h2 id="analysis-content-1"><a class="header" href="#analysis-content-1">Analysis Content</a></h2>
<p>The generated analysis report typically includes:</p>
<h3 id="1-executive-summary-1"><a class="header" href="#1-executive-summary-1">1. Executive Summary</a></h3>
<ul>
<li>Overall success rate</li>
<li>Number of tests run</li>
<li>Key findings and insights</li>
<li>Critical issues identified</li>
</ul>
<h3 id="2-test-results-overview-1"><a class="header" href="#2-test-results-overview-1">2. Test Results Overview</a></h3>
<ul>
<li>Distribution of test statuses (success, failure, error)</li>
<li>Average response times</li>
<li>Success rates by test type</li>
<li>Temporal patterns (if timestamps are available)</li>
</ul>
<h3 id="3-detailed-breakdown-1"><a class="header" href="#3-detailed-breakdown-1">3. Detailed Breakdown</a></h3>
<ul>
<li>Analysis of each failed test</li>
<li>Common failure patterns</li>
<li>Root cause analysis</li>
<li>Error categorization</li>
</ul>
<h3 id="4-performance-analysis-1"><a class="header" href="#4-performance-analysis-1">4. Performance Analysis</a></h3>
<ul>
<li>Response time statistics</li>
<li>Performance bottlenecks</li>
<li>Throughput analysis</li>
<li>Resource utilization patterns</li>
</ul>
<h3 id="5-recommendations-1"><a class="header" href="#5-recommendations-1">5. Recommendations</a></h3>
<ul>
<li>Suggestions for fixing failed tests</li>
<li>Performance optimization opportunities</li>
<li>Test coverage improvements</li>
<li>Testing strategy recommendations</li>
</ul>
<h2 id="example-analysis-report-1"><a class="header" href="#example-analysis-report-1">Example Analysis Report</a></h2>
<pre><code class="language-markdown"># Test Results Analysis

## Executive Summary

Analyzed 25 test results with an overall success rate of 84% (21/25 tests passed).
The average response time was 187ms, with 3 tests exceeding the 500ms threshold.
The main issues were related to authentication failures and timeout errors.

## Test Results Overview

| Status | Count | Percentage |
|--------|-------|------------|
| Success | 21 | 84% |
| Failure | 3 | 12% |
| Error | 1 | 4% |

### Success Rate by Test Type
- API Tests: 90% (18/20)
- Performance Tests: 75% (3/4)
- Security Tests: 0% (0/1)

## Detailed Breakdown

### Failed Tests Analysis

1. **API-Test-003**: Authentication failure
   - Error: "Unauthorized (401)"
   - Possible cause: Expired API token or incorrect credentials
   - Recommendation: Verify and update the authentication token

2. **API-Test-012**: Unexpected response format
   - Error: "Expected field 'user_id' not found in response"
   - Possible cause: API response structure has changed
   - Recommendation: Update the expected response structure in the test configuration

3. **Perf-Test-002**: Timeout error
   - Error: "Request timed out after 30 seconds"
   - Possible cause: Server under heavy load or network issues
   - Recommendation: Increase the timeout threshold or investigate server performance

## Performance Analysis

- 90th percentile response time: 342ms
- Slowest endpoint: /api/users/search (avg: 412ms)
- Fastest endpoint: /api/health (avg: 42ms)
- 3 tests exceeded the 500ms threshold

## Recommendations

1. **Fix Authentication Issues**
   - Implement token refresh mechanism
   - Add pre-test validation of authentication credentials

2. **Improve Error Handling**
   - Add more specific assertions for response structure
   - Implement retry logic for transient failures

3. **Performance Optimization**
   - Review the /api/users/search endpoint for optimization opportunities
   - Consider caching frequently accessed resources
   - Implement pagination for large result sets

4. **Test Coverage Improvements**
   - Add more security tests (currently only 1)
   - Increase test coverage for error conditions
   - Add tests for edge cases identified in this analysis
</code></pre>
<h2 id="input-format-requirements-1"><a class="header" href="#input-format-requirements-1">Input Format Requirements</a></h2>
<p>The analysis feature expects test results in a specific JSON format:</p>
<pre><code class="language-json">[
  {
    "test_id": "api-test-001",
    "name": "User API Test",
    "description": "Test the user API endpoint",
    "timestamp": "2025-05-10T12:34:56Z",
    "duration_ms": 156,
    "status": "success",
    "url": "https://api.example.com/users/123",
    "method": "GET",
    "request_headers": {
      "Accept": "application/json",
      "Authorization": "Bearer token123"
    },
    "response_status": 200,
    "response_headers": {
      "content-type": "application/json"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 200,
        "result": "pass"
      },
      {
        "type": "json",
        "path": "$.id",
        "expected": 123,
        "actual": 123,
        "result": "pass"
      }
    ]
  },
  {
    "test_id": "api-test-002",
    "name": "Invalid User API Test",
    "description": "Test the user API with invalid ID",
    "timestamp": "2025-05-10T12:35:12Z",
    "duration_ms": 134,
    "status": "failure",
    "url": "https://api.example.com/users/999",
    "method": "GET",
    "request_headers": {
      "Accept": "application/json",
      "Authorization": "Bearer token123"
    },
    "response_status": 404,
    "response_headers": {
      "content-type": "application/json"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 404,
        "result": "fail"
      }
    ],
    "error": "Expected status 200 but got 404"
  }
]
</code></pre>
<h2 id="best-practices-10"><a class="header" href="#best-practices-10">Best Practices</a></h2>
<ul>
<li>Include as much detail as possible in your test results</li>
<li>Run analysis after each test suite execution</li>
<li>Compare analyses over time to identify trends</li>
<li>Use the analysis to prioritize test improvements</li>
<li>Share analysis reports with your team for collaborative debugging</li>
<li>Customize the analysis by adjusting the temperature parameter</li>
<li>Use lower temperatures (0.3-0.5) for more factual, concise analyses</li>
<li>Use higher temperatures (0.7-0.9) for more creative, detailed analyses</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="improvement-suggestions"><a class="header" href="#improvement-suggestions">Improvement Suggestions</a></h1>
<p>QitOps can generate actionable suggestions to improve your tests based on test results and industry best practices. This feature helps you continuously enhance your testing strategy and address issues before they become critical problems.</p>
<h2 id="how-it-works-5"><a class="header" href="#how-it-works-5">How It Works</a></h2>
<ol>
<li>You provide a JSON file containing test results</li>
<li>QitOps analyzes these results using a local LLM</li>
<li>The LLM generates specific, actionable improvement suggestions</li>
<li>The suggestions are saved to the specified output file</li>
</ol>
<h2 id="basic-usage-10"><a class="header" href="#basic-usage-10">Basic Usage</a></h2>
<pre><code class="language-bash"># Generate improvement suggestions
qitops improve --results test_results.json --output improvements.md

# Generate suggestions with a specific model
qitops improve --results test_results.json --output improvements.md --model llama --model-path /path/to/model.gguf
</code></pre>
<h2 id="command-line-options-11"><a class="header" href="#command-line-options-11">Command-Line Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--results &lt;FILE&gt;</code></td><td>JSON file containing test results</td></tr>
<tr><td><code>--output &lt;FILE&gt;</code></td><td>Output file for the improvement suggestions</td></tr>
<tr><td><code>--model &lt;MODEL&gt;</code></td><td>LLM model to use (default: auto)</td></tr>
<tr><td><code>--model-path &lt;PATH&gt;</code></td><td>Path to the model file</td></tr>
<tr><td><code>--format &lt;FORMAT&gt;</code></td><td>Output format (markdown, html, json)</td></tr>
<tr><td><code>--focus &lt;AREA&gt;</code></td><td>Focus area for suggestions (performance, reliability, coverage, all)</td></tr>
<tr><td><code>--temperature &lt;FLOAT&gt;</code></td><td>Temperature for generation (0.0-1.0)</td></tr>
<tr><td><code>--context-size &lt;INT&gt;</code></td><td>Context size in tokens</td></tr>
<tr><td><code>--max-tokens &lt;INT&gt;</code></td><td>Maximum tokens for generation</td></tr>
<tr><td><code>--system-prompt &lt;TEXT&gt;</code></td><td>Custom system prompt for the model</td></tr>
</tbody></table>
</div>
<h2 id="improvement-categories-1"><a class="header" href="#improvement-categories-1">Improvement Categories</a></h2>
<p>The generated suggestions typically cover the following areas:</p>
<h3 id="1-performance-optimizations-1"><a class="header" href="#1-performance-optimizations-1">1. Performance Optimizations</a></h3>
<ul>
<li>Response time improvements</li>
<li>Resource utilization efficiency</li>
<li>Concurrency and parallelism recommendations</li>
<li>Caching strategies</li>
<li>Database query optimizations</li>
<li>Network latency reduction</li>
</ul>
<h3 id="2-reliability-enhancements-1"><a class="header" href="#2-reliability-enhancements-1">2. Reliability Enhancements</a></h3>
<ul>
<li>Error handling improvements</li>
<li>Retry mechanisms</li>
<li>Timeout configurations</li>
<li>Fault tolerance strategies</li>
<li>Resilience patterns</li>
<li>Circuit breaker implementations</li>
</ul>
<h3 id="3-coverage-improvements-1"><a class="header" href="#3-coverage-improvements-1">3. Coverage Improvements</a></h3>
<ul>
<li>Missing test scenarios</li>
<li>Edge case coverage</li>
<li>Error condition testing</li>
<li>Boundary value testing</li>
<li>Security vulnerability testing</li>
<li>Cross-functional testing</li>
</ul>
<h3 id="4-best-practices-1"><a class="header" href="#4-best-practices-1">4. Best Practices</a></h3>
<ul>
<li>Test organization and structure</li>
<li>Naming conventions</li>
<li>Documentation improvements</li>
<li>Assertion strategies</li>
<li>Test data management</li>
<li>CI/CD integration</li>
</ul>
<h2 id="example-improvement-suggestions-1"><a class="header" href="#example-improvement-suggestions-1">Example Improvement Suggestions</a></h2>
<pre><code class="language-markdown"># Test Improvement Suggestions

## Executive Summary

Based on the analysis of 25 test results, we've identified several opportunities for improvement across performance, reliability, coverage, and best practices. Implementing these suggestions will help enhance the effectiveness and efficiency of your testing suite.

## Performance Optimizations

1. **Optimize Slow Endpoints**
   - The `/api/users/search` endpoint has an average response time of 412ms, which is significantly higher than other endpoints.
   - Suggestion: Review the implementation of this endpoint, focusing on database query optimization and potential caching.
   - Implementation: Add query indexing for frequently searched fields and implement a Redis cache for common search queries.

2. **Implement Connection Pooling**
   - Multiple tests show connection establishment overhead.
   - Suggestion: Implement connection pooling to reuse connections across tests.
   - Implementation: Configure a connection pool with appropriate min/max settings based on your concurrency requirements.

3. **Reduce Payload Sizes**
   - Several API responses exceed 100KB in size.
   - Suggestion: Implement pagination and field filtering to reduce payload sizes.
   - Implementation: Add `limit`, `offset`, and `fields` query parameters to your API endpoints.

## Reliability Enhancements

1. **Improve Authentication Handling**
   - 3 tests failed due to authentication issues.
   - Suggestion: Implement token refresh and pre-test authentication validation.
   - Implementation: Add a token refresh mechanism that automatically renews expired tokens before test execution.

2. **Add Retry Logic for Transient Failures**
   - Several timeout errors appear to be transient.
   - Suggestion: Implement exponential backoff retry logic for network-related failures.
   - Implementation: Add a retry decorator/wrapper that retries failed requests with increasing delays.

3. **Enhance Error Handling**
   - Error messages are inconsistent and sometimes not actionable.
   - Suggestion: Standardize error handling and improve error messages.
   - Implementation: Create a centralized error handler that provides consistent, detailed error information.

## Coverage Improvements

1. **Add Security Testing**
   - Only 1 security test was found in the results.
   - Suggestion: Expand security testing to cover authentication, authorization, input validation, and data protection.
   - Implementation: Add tests for OWASP Top 10 vulnerabilities relevant to your application.

2. **Increase Edge Case Coverage**
   - Most tests focus on happy paths with valid inputs.
   - Suggestion: Add tests for boundary conditions, invalid inputs, and error scenarios.
   - Implementation: For each API endpoint, add tests with empty values, extremely large values, special characters, and malformed requests.

3. **Add Load and Stress Testing**
   - Current performance tests use relatively low concurrency (max 100 users).
   - Suggestion: Add high-concurrency load tests and stress tests to identify breaking points.
   - Implementation: Create load test scenarios with gradually increasing concurrency until performance degrades.

## Best Practices

1. **Improve Test Organization**
   - Tests are not consistently organized by feature or functionality.
   - Suggestion: Reorganize tests into logical groups based on functionality.
   - Implementation: Create a directory structure that mirrors your application's architecture.

2. **Enhance Test Data Management**
   - Test data is hardcoded in many tests.
   - Suggestion: Implement a test data management strategy with fixtures or factories.
   - Implementation: Create a test data generator that produces consistent, realistic test data.

3. **Add Documentation**
   - Many tests lack clear documentation about their purpose and expected behavior.
   - Suggestion: Add descriptive comments and documentation to all tests.
   - Implementation: Standardize on a documentation format that includes purpose, prerequisites, and expected outcomes.

## Implementation Roadmap

We recommend implementing these improvements in the following order:

1. **Immediate (1-2 weeks)**
   - Fix authentication handling issues
   - Add retry logic for transient failures
   - Improve error messages

2. **Short-term (2-4 weeks)**
   - Optimize slow endpoints
   - Enhance test organization
   - Add basic security tests

3. **Medium-term (1-3 months)**
   - Implement connection pooling
   - Add edge case coverage
   - Improve test data management

4. **Long-term (3+ months)**
   - Reduce payload sizes
   - Add comprehensive load and stress testing
   - Enhance documentation
</code></pre>
<h2 id="integration-with-cicd-6"><a class="header" href="#integration-with-cicd-6">Integration with CI/CD</a></h2>
<p>You can integrate the improvement suggestions feature into your CI/CD pipeline to automatically generate suggestions after test runs:</p>
<pre><code class="language-yaml"># Example GitHub Actions workflow step
- name: Generate Test Improvement Suggestions
  run: |
    qitops improve --results test_results.json --output improvements.md
    
- name: Upload Improvement Suggestions
  uses: actions/upload-artifact@v2
  with:
    name: test-improvements
    path: improvements.md
</code></pre>
<h2 id="best-practices-11"><a class="header" href="#best-practices-11">Best Practices</a></h2>
<ul>
<li>Run the improvement suggestions tool regularly (weekly or after major test runs)</li>
<li>Prioritize suggestions based on their impact and implementation effort</li>
<li>Create tickets or tasks for implementing high-priority suggestions</li>
<li>Track the implementation of suggestions over time</li>
<li>Re-run the tool after implementing suggestions to measure progress</li>
<li>Customize the focus area based on your current priorities</li>
<li>Use the suggestions as input for sprint planning and technical debt discussions</li>
<li>Share the suggestions with your team to foster a culture of continuous improvement</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="supported-llm-models"><a class="header" href="#supported-llm-models">Supported LLM Models</a></h1>
<p>QitOps supports a variety of local LLM models for its AI features. These models run entirely on your local machine, ensuring privacy and offline operation.</p>
<h2 id="llama-models-1"><a class="header" href="#llama-models-1">LLaMA Models</a></h2>
<ul>
<li><strong>LLaMA 1</strong>: The original Meta AI model (7B, 13B, 33B, 65B parameters)</li>
<li><strong>LLaMA 2</strong>: Improved version with longer context (7B, 13B, 70B parameters)</li>
<li><strong>LLaMA 3</strong>: Latest version with enhanced capabilities (8B, 70B parameters)</li>
<li><strong>Code LLaMA</strong>: Specialized for code generation and analysis</li>
</ul>
<h2 id="mistral-models-1"><a class="header" href="#mistral-models-1">Mistral Models</a></h2>
<ul>
<li><strong>Mistral 7B</strong>: Efficient base model with strong performance</li>
<li><strong>Mixtral 8x7B</strong>: Mixture-of-experts model with enhanced capabilities</li>
<li><strong>Mistral Instruct</strong>: Fine-tuned for instruction following</li>
<li><strong>Mistral Small</strong>: Smaller, faster models for resource-constrained environments</li>
</ul>
<h2 id="phi-models-1"><a class="header" href="#phi-models-1">Phi Models</a></h2>
<ul>
<li><strong>Phi-1</strong>: Microsoft’s small but capable model (1.3B parameters)</li>
<li><strong>Phi-2</strong>: Improved version with enhanced reasoning (2.7B parameters)</li>
<li><strong>Phi-3</strong>: Latest version with advanced capabilities (3.8B, 14B parameters)</li>
</ul>
<h2 id="other-supported-models-1"><a class="header" href="#other-supported-models-1">Other Supported Models</a></h2>
<ul>
<li><strong>GPT-J</strong>: EleutherAI’s open-source GPT model (6B parameters)</li>
<li><strong>GPT4All</strong>: Locally running assistant models</li>
<li><strong>Falcon</strong>: Technology Innovation Institute’s models</li>
<li><strong>MPT</strong>: MosaicML’s Pretrained Transformer models</li>
<li><strong>RWKV</strong>: RNN with transformer-like capabilities</li>
<li><strong>Qwen</strong>: Alibaba’s series of multilingual models</li>
</ul>
<h2 id="model-format-support-1"><a class="header" href="#model-format-support-1">Model Format Support</a></h2>
<ul>
<li><strong>GGUF</strong>: Primary supported format for efficient inference</li>
<li><strong>GGML</strong>: Legacy format (automatically converted to GGUF)</li>
<li><strong>ONNX</strong>: Support via external runtime</li>
</ul>
<h2 id="recommended-models-for-different-use-cases-1"><a class="header" href="#recommended-models-for-different-use-cases-1">Recommended Models for Different Use Cases</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Use Case</th><th>Recommended Model</th><th>Size</th><th>Performance</th></tr></thead><tbody>
<tr><td>Test Generation</td><td>Phi-2</td><td>2.7GB</td><td>Good balance of size and quality</td></tr>
<tr><td>Results Analysis</td><td>Mistral 7B</td><td>4.1GB</td><td>Strong reasoning capabilities</td></tr>
<tr><td>Improvement Suggestions</td><td>LLaMA 2 13B</td><td>8.2GB</td><td>Detailed, high-quality suggestions</td></tr>
<tr><td>Resource-Constrained</td><td>Phi-1</td><td>1.5GB</td><td>Works on machines with limited RAM</td></tr>
<tr><td>Best Quality</td><td>Mixtral 8x7B</td><td>26GB</td><td>Highest quality results (requires 32GB+ RAM)</td></tr>
</tbody></table>
</div>
<h2 id="where-to-download-models-1"><a class="header" href="#where-to-download-models-1">Where to Download Models</a></h2>
<p>Models can be downloaded from:</p>
<ul>
<li><a href="https://huggingface.co/models">Hugging Face</a> - Search for GGUF versions</li>
<li><a href="https://huggingface.co/TheBloke">TheBloke’s repositories</a> - Pre-converted GGUF models</li>
<li><a href="https://ollama.com/library">Ollama Library</a> - Easy model management</li>
</ul>
<h2 id="model-quantization-options-1"><a class="header" href="#model-quantization-options-1">Model Quantization Options</a></h2>
<p>QitOps supports various quantization levels to balance quality and resource usage:</p>
<div class="table-wrapper"><table><thead><tr><th>Quantization</th><th>File Size</th><th>RAM Usage</th><th>Quality</th><th>Speed</th></tr></thead><tbody>
<tr><td>Q4_K_M</td><td>Smallest</td><td>Lowest</td><td>Good</td><td>Fastest</td></tr>
<tr><td>Q5_K_M</td><td>Small</td><td>Low</td><td>Better</td><td>Fast</td></tr>
<tr><td>Q6_K</td><td>Medium</td><td>Medium</td><td>Very Good</td><td>Medium</td></tr>
<tr><td>Q8_0</td><td>Large</td><td>High</td><td>Excellent</td><td>Slower</td></tr>
</tbody></table>
</div>
<p>Example model selection with quantization:</p>
<pre><code class="language-bash"># Use a smaller, faster model
qitops generate --test-type api --description "Test the login API" --model phi --model-path models/phi-2.Q4_K_M.gguf

# Use a higher quality model
qitops analyze --results test_results.json --output analysis.md --model mistral --model-path models/mistral-7b.Q8_0.gguf
</code></pre>
<h2 id="model-configuration"><a class="header" href="#model-configuration">Model Configuration</a></h2>
<p>QitOps allows you to configure various model parameters:</p>
<pre><code class="language-bash"># Set context size
qitops generate --test-type api --description "Test the login API" --context-size 8192

# Set temperature
qitops analyze --results test_results.json --output analysis.md --temperature 0.7

# Set maximum tokens
qitops improve --results test_results.json --output improvements.md --max-tokens 4096
</code></pre>
<h2 id="using-ollama-models"><a class="header" href="#using-ollama-models">Using Ollama Models</a></h2>
<p>QitOps can use models managed by Ollama:</p>
<pre><code class="language-bash"># Use an Ollama model
qitops generate --test-type api --description "Test the login API" --model ollama:phi

# Use a specific Ollama model version
qitops analyze --results test_results.json --output analysis.md --model ollama:mistral:7b-instruct
</code></pre>
<h2 id="using-local-model-files"><a class="header" href="#using-local-model-files">Using Local Model Files</a></h2>
<p>QitOps can use model files stored locally:</p>
<pre><code class="language-bash"># Use a local model file
qitops generate --test-type api --description "Test the login API" --model-path /path/to/models/phi-2.gguf

# Use a local model with specific parameters
qitops analyze --results test_results.json --output analysis.md --model-path /path/to/models/mistral-7b.gguf --context-size 4096 --temperature 0.5
</code></pre>
<h2 id="model-performance-considerations"><a class="header" href="#model-performance-considerations">Model Performance Considerations</a></h2>
<ul>
<li><strong>Memory Usage</strong>: Larger models require more RAM</li>
<li><strong>Disk Space</strong>: Model files can be large (1-30GB)</li>
<li><strong>CPU vs. GPU</strong>: GPU acceleration significantly improves performance</li>
<li><strong>Quantization</strong>: Lower quantization reduces quality but improves speed and reduces memory usage</li>
<li><strong>Context Size</strong>: Larger context sizes require more memory but can improve results for complex tasks</li>
</ul>
<h2 id="troubleshooting-7"><a class="header" href="#troubleshooting-7">Troubleshooting</a></h2>
<h3 id="common-issues-6"><a class="header" href="#common-issues-6">Common Issues</a></h3>
<ul>
<li><strong>Out of Memory</strong>: Try a smaller model or lower quantization</li>
<li><strong>Slow Generation</strong>: Use GPU acceleration or a smaller model</li>
<li><strong>Poor Quality Results</strong>: Try a larger model or higher quantization</li>
<li><strong>Model Not Found</strong>: Check the model path and ensure the file exists</li>
<li><strong>Unsupported Format</strong>: Ensure the model is in GGUF format</li>
</ul>
<h3 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h3>
<ul>
<li><strong>GPU Acceleration</strong>: Enable GPU acceleration for faster inference</li>
<li><strong>Batch Processing</strong>: Process multiple requests in batch for better throughput</li>
<li><strong>Quantization</strong>: Use appropriate quantization for your hardware</li>
<li><strong>Context Size</strong>: Use the smallest context size that works for your use case</li>
<li><strong>Model Selection</strong>: Choose the smallest model that provides acceptable quality</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-ai-features-2"><a class="header" href="#testing-ai-features-2">Testing AI Features</a></h1>
<p>This guide provides detailed instructions on how to test the AI features of QitOps locally. These features include test configuration generation, test results analysis, and improvement suggestions.</p>
<h2 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h2>
<p>Before testing the AI features, make sure you have:</p>
<ol>
<li>
<p><strong>QitOps built with AI features</strong>:</p>
<pre><code class="language-bash">cargo build --features ai
</code></pre>
</li>
<li>
<p><strong>A local LLM setup</strong> (one of the following):</p>
<ul>
<li><strong>Ollama</strong>: For easy local LLM management</li>
<li><strong>Direct model files</strong>: GGUF format models</li>
<li><strong>Mock implementation</strong>: For testing without a real model</li>
</ul>
</li>
</ol>
<h2 id="option-1-testing-with-ollama"><a class="header" href="#option-1-testing-with-ollama">Option 1: Testing with Ollama</a></h2>
<p><a href="https://ollama.ai/">Ollama</a> provides an easy way to run local LLMs. It’s recommended for testing as it handles model management and provides a simple API.</p>
<h3 id="step-1-install-ollama"><a class="header" href="#step-1-install-ollama">Step 1: Install Ollama</a></h3>
<pre><code class="language-bash"># Linux
curl -fsSL https://ollama.ai/install.sh | sh

# macOS
brew install ollama

# Windows
# Download from https://ollama.ai/download
</code></pre>
<h3 id="step-2-start-ollama-server"><a class="header" href="#step-2-start-ollama-server">Step 2: Start Ollama Server</a></h3>
<pre><code class="language-bash">ollama serve
</code></pre>
<h3 id="step-3-pull-a-model"><a class="header" href="#step-3-pull-a-model">Step 3: Pull a Model</a></h3>
<p>Pull a small model for testing:</p>
<pre><code class="language-bash"># Pull a small model (recommended for testing)
ollama pull phi

# Or pull a larger model for better results
ollama pull llama2
</code></pre>
<h3 id="step-4-test-ai-features-with-ollama"><a class="header" href="#step-4-test-ai-features-with-ollama">Step 4: Test AI Features with Ollama</a></h3>
<pre><code class="language-bash"># Test configuration generation
cargo run --features ai -- generate --test-type api --description "Test the Twitter API to fetch user timeline" --output twitter_api_test.json --model ollama:phi

# Test results analysis
cargo run --features ai -- analyze --results sample_test_results.json --output test_analysis.md --model ollama:phi

# Test improvement suggestions
cargo run --features ai -- improve --results sample_test_results.json --output test_improvements.md --model ollama:phi
</code></pre>
<h2 id="option-2-testing-with-direct-model-files"><a class="header" href="#option-2-testing-with-direct-model-files">Option 2: Testing with Direct Model Files</a></h2>
<p>If you prefer to use model files directly, you can download GGUF format models and use them with QitOps.</p>
<h3 id="step-1-download-a-model"><a class="header" href="#step-1-download-a-model">Step 1: Download a Model</a></h3>
<p>Download a GGUF model from Hugging Face or other sources:</p>
<pre><code class="language-bash"># Create a models directory
mkdir -p models

# Download a model (example using wget)
wget https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf -O models/phi-2.gguf
</code></pre>
<h3 id="step-2-test-ai-features-with-direct-model-files"><a class="header" href="#step-2-test-ai-features-with-direct-model-files">Step 2: Test AI Features with Direct Model Files</a></h3>
<pre><code class="language-bash"># Test configuration generation
cargo run --features ai -- generate --test-type api --description "Test the Twitter API to fetch user timeline" --output twitter_api_test.json --model custom --model-path models/phi-2.gguf

# Test results analysis
cargo run --features ai -- analyze --results sample_test_results.json --output test_analysis.md --model custom --model-path models/phi-2.gguf

# Test improvement suggestions
cargo run --features ai -- improve --results sample_test_results.json --output test_improvements.md --model custom --model-path models/phi-2.gguf
</code></pre>
<h2 id="option-3-testing-with-mock-implementation"><a class="header" href="#option-3-testing-with-mock-implementation">Option 3: Testing with Mock Implementation</a></h2>
<p>For quick testing without a real model, you can use the built-in mock implementation.</p>
<h3 id="step-1-create-sample-test-results"><a class="header" href="#step-1-create-sample-test-results">Step 1: Create Sample Test Results</a></h3>
<p>Create a sample test results file for testing analysis and improvement features:</p>
<pre><code class="language-bash">cat &gt; sample_test_results.json &lt;&lt; EOF
[
  {
    "test_id": "api-test-1",
    "name": "GitHub User API Test",
    "description": "Test the GitHub API to fetch user information",
    "timestamp": "2025-05-10T21:15:00Z",
    "duration_ms": 190,
    "status": "success",
    "url": "https://api.github.com/users/octocat",
    "method": "GET",
    "request_headers": {
      "Accept": "application/vnd.github.v3+json",
      "User-Agent": "QitOps-Test"
    },
    "response_status": 200,
    "response_headers": {
      "content-type": "application/json; charset=utf-8",
      "cache-control": "public, max-age=60, s-maxage=60"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 200,
        "result": "pass"
      },
      {
        "type": "json",
        "path": "$.login",
        "expected": "octocat",
        "actual": "octocat",
        "result": "pass"
      }
    ]
  },
  {
    "test_id": "api-test-2",
    "name": "GitHub Non-existent User Test",
    "description": "Test the GitHub API with a non-existent user",
    "timestamp": "2025-05-10T21:15:02Z",
    "duration_ms": 180,
    "status": "failure",
    "url": "https://api.github.com/users/non-existent-user-12345",
    "method": "GET",
    "request_headers": {
      "Accept": "application/vnd.github.v3+json",
      "User-Agent": "QitOps-Test"
    },
    "response_status": 404,
    "response_headers": {
      "content-type": "application/json; charset=utf-8",
      "cache-control": "public, max-age=60, s-maxage=60"
    },
    "assertions": [
      {
        "type": "status",
        "expected": 200,
        "actual": 404,
        "result": "fail"
      }
    ],
    "error": "Expected status 200 but got 404"
  }
]
EOF
</code></pre>
<h3 id="step-2-test-ai-features-with-mock-implementation"><a class="header" href="#step-2-test-ai-features-with-mock-implementation">Step 2: Test AI Features with Mock Implementation</a></h3>
<pre><code class="language-bash"># Test configuration generation
cargo run --features ai -- generate --test-type api --description "Test the Twitter API to fetch user timeline" --output twitter_api_test.json

# Test results analysis
cargo run --features ai -- analyze --results sample_test_results.json --output test_analysis.md

# Test improvement suggestions
cargo run --features ai -- improve --results sample_test_results.json --output test_improvements.md
</code></pre>
<h2 id="automated-testing-script"><a class="header" href="#automated-testing-script">Automated Testing Script</a></h2>
<p>For convenience, you can use the provided test script to test all AI features at once:</p>
<pre><code class="language-bash"># Download the test script
curl -O https://raw.githubusercontent.com/qitops/qitops-cli-tools/master/test_local_ai.sh
chmod +x test_local_ai.sh

# Run the test script
./test_local_ai.sh
</code></pre>
<p>The test script will:</p>
<ol>
<li>Set up environment variables for offline mode</li>
<li>Create a directory for test outputs</li>
<li>Test all AI features (generation, analysis, improvement)</li>
<li>Show the generated files</li>
</ol>
<h2 id="verifying-test-results"><a class="header" href="#verifying-test-results">Verifying Test Results</a></h2>
<p>After running the tests, you should check the generated files:</p>
<pre><code class="language-bash"># Check the generated API test configuration
cat twitter_api_test.json

# Check the test analysis
cat test_analysis.md

# Check the improvement suggestions
cat test_improvements.md
</code></pre>
<p>The generated files should contain:</p>
<ol>
<li>
<p><strong>API Test Configuration</strong>:</p>
<ul>
<li>URL, method, headers, and assertions</li>
<li>Properly formatted JSON</li>
</ul>
</li>
<li>
<p><strong>Test Analysis</strong>:</p>
<ul>
<li>Overview of test results</li>
<li>Details about performance and status codes</li>
<li>Recommendations for improvement</li>
</ul>
</li>
<li>
<p><strong>Improvement Suggestions</strong>:</p>
<ul>
<li>Performance optimizations</li>
<li>Reliability enhancements</li>
<li>Coverage improvements</li>
</ul>
</li>
</ol>
<h2 id="troubleshooting-8"><a class="header" href="#troubleshooting-8">Troubleshooting</a></h2>
<h3 id="model-loading-issues-1"><a class="header" href="#model-loading-issues-1">Model Loading Issues</a></h3>
<p>If you encounter issues loading a model:</p>
<pre><code class="language-bash"># Check if the model file exists
ls -la models/phi-2.gguf

# Try with verbose logging
RUST_LOG=debug cargo run --features ai -- generate --test-type api --description "Test description" --model custom --model-path models/phi-2.gguf
</code></pre>
<h3 id="ollama-connection-issues-1"><a class="header" href="#ollama-connection-issues-1">Ollama Connection Issues</a></h3>
<p>If you have trouble connecting to Ollama:</p>
<pre><code class="language-bash"># Check if Ollama is running
curl http://localhost:11434/api/version

# Check available models
ollama list

# Pull the model if it's not available
ollama pull phi
</code></pre>
<h3 id="memory-issues-1"><a class="header" href="#memory-issues-1">Memory Issues</a></h3>
<p>If you encounter memory issues with large models:</p>
<pre><code class="language-bash"># Use a smaller model
ollama pull tinyllama
cargo run --features ai -- generate --test-type api --description "Test description" --model ollama:tinyllama

# Or reduce context size
cargo run --features ai -- generate --test-type api --description "Test description" --context-size 2048
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="usage-guide"><a class="header" href="#usage-guide">Usage Guide</a></h1>
<p>This page provides detailed information on using QitOps for different testing scenarios.</p>
<h2 id="command-line-interface"><a class="header" href="#command-line-interface">Command Line Interface</a></h2>
<p>QitOps provides a unified command-line interface for all testing types:</p>
<pre><code class="language-bash">qitops [global options] &lt;command&gt; [command options]
</code></pre>
<h3 id="global-options-1"><a class="header" href="#global-options-1">Global Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td>-r, –report <FORMAT></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td>-o, –output <FILE></td><td>Output file for the report</td></tr>
<tr><td>–ci-mode</td><td>Run in CI mode (reduced output, exit code based on test results)</td></tr>
<tr><td>-e, –environment <ENV></td><td>Environment to use (default: production)</td></tr>
<tr><td>-v, –verbose</td><td>Enable verbose output</td></tr>
<tr><td>-h, –help</td><td>Show help</td></tr>
<tr><td>-V, –version</td><td>Show version</td></tr>
</tbody></table>
</div>
<h3 id="commands"><a class="header" href="#commands">Commands</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Command</th><th>Description</th></tr></thead><tbody>
<tr><td>api</td><td>Run API tests</td></tr>
<tr><td>collection</td><td>Run API collection tests</td></tr>
<tr><td>performance</td><td>Run performance tests</td></tr>
<tr><td>security</td><td>Run security tests</td></tr>
<tr><td>web</td><td>Run web tests</td></tr>
<tr><td>data-driven</td><td>Run data-driven tests</td></tr>
<tr><td>generate</td><td>Generate test configurations using AI</td></tr>
<tr><td>analyze</td><td>Analyze test results using AI</td></tr>
<tr><td>improve</td><td>Generate improvement suggestions using AI</td></tr>
</tbody></table>
</div>
<h2 id="api-testing-6"><a class="header" href="#api-testing-6">API Testing</a></h2>
<pre><code class="language-bash"># Run a single API test
qitops api -c tests/configs/api_test.json

# Run tests in a specific environment
qitops api -c tests/configs/api_test.json -e production

# Run with custom variables
qitops api -c tests/configs/api_test.json -v base_url=https://api.example.com -v api_key=12345
</code></pre>
<h2 id="api-collection-testing"><a class="header" href="#api-collection-testing">API Collection Testing</a></h2>
<pre><code class="language-bash"># Run an API collection
qitops collection -c tests/configs/api_collection.json

# Run with environment variables
qitops collection -c tests/configs/api_collection.json -v API_KEY=your-api-key

# Run with a specific environment
qitops collection -c tests/configs/api_collection.json -e staging
</code></pre>
<h2 id="performance-testing-6"><a class="header" href="#performance-testing-6">Performance Testing</a></h2>
<pre><code class="language-bash"># Run a basic performance test
qitops performance -c tests/configs/performance_test.json -u 10 -d 30

# Run with custom users and duration
qitops performance -c tests/configs/performance_test.json -u 20 -d 60

# Run with a specific ramp-up time
qitops performance -c tests/configs/performance_test.json -u 10 -d 30 -r 5
</code></pre>
<h2 id="enhanced-performance-testing-6"><a class="header" href="#enhanced-performance-testing-6">Enhanced Performance Testing</a></h2>
<pre><code class="language-bash"># Run an enhanced performance test with multiple scenarios
qitops performance -c tests/configs/enhanced_performance_test.json

# Run with streaming metrics
qitops performance -c tests/configs/enhanced_performance_test.json --stream-metrics

# Run with custom metrics interval
qitops performance -c tests/configs/enhanced_performance_test.json --metrics-interval 10
</code></pre>
<h2 id="security-testing-6"><a class="header" href="#security-testing-6">Security Testing</a></h2>
<pre><code class="language-bash"># Run a security test
qitops security -c tests/configs/security_test.json

# Run with a specific scan depth
qitops security -c tests/configs/security_test.json -d 3

# Run with specific scan types
qitops security -c tests/configs/security_test.json --scan-types headers,ssl
</code></pre>
<h2 id="web-testing-6"><a class="header" href="#web-testing-6">Web Testing</a></h2>
<pre><code class="language-bash"># Run a web test
qitops web -c tests/configs/web_test.json

# Run in headless mode
qitops web -c tests/configs/web_test.json --headless

# Run with custom viewport
qitops web -c tests/configs/web_test.json --width 1920 --height 1080
</code></pre>
<h2 id="data-driven-testing-5"><a class="header" href="#data-driven-testing-5">Data-Driven Testing</a></h2>
<pre><code class="language-bash"># Run data-driven tests with CSV data
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv

# Run data-driven tests with JSON data
qitops data-driven -c tests/configs/data_driven_collection.json -d tests/data/products.json -t json

# Run with a limit on iterations
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv --limit 10

# Run with stop-on-failure
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv --stop-on-failure
</code></pre>
<h2 id="ai-features-3"><a class="header" href="#ai-features-3">AI Features</a></h2>
<pre><code class="language-bash"># Generate an API test configuration
qitops generate --test-type api --description "Test the GitHub API to fetch user information" --output github_test.json

# Generate a performance test configuration
qitops generate --test-type performance --description "Load test for a web service" --output performance_test.json

# Analyze test results
qitops analyze --results test_result.json --output analysis.md

# Generate improvement suggestions
qitops improve --results test_result.json --output improvements.md

# Use a custom AI model
qitops generate --test-type api --description "Test description" --model custom --model-path /path/to/model.gguf
</code></pre>
<h2 id="cicd-integration-4"><a class="header" href="#cicd-integration-4">CI/CD Integration</a></h2>
<pre><code class="language-bash"># Run in CI mode with JSON report
qitops --ci-mode -r json -o results.json api -c tests/configs/api_test.json

# Run in CI mode with XML report (JUnit format)
qitops --ci-mode -r xml -o test-results.xml api -c tests/configs/api_test.json

# Run in CI mode with HTML report
qitops --ci-mode -r html -o report.html api -c tests/configs/api_test.json
</code></pre>
<h2 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h2>
<p>QitOps supports the following environment variables:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th></tr></thead><tbody>
<tr><td>QITOPS_ENV</td><td>Default environment to use</td></tr>
<tr><td>QITOPS_REPORT_FORMAT</td><td>Default report format</td></tr>
<tr><td>QITOPS_OUTPUT_FILE</td><td>Default output file</td></tr>
<tr><td>QITOPS_CI_MODE</td><td>Run in CI mode if set to “true”</td></tr>
<tr><td>QITOPS_VERBOSE</td><td>Enable verbose output if set to “true”</td></tr>
<tr><td>QITOPS_CONFIG_DIR</td><td>Directory containing configuration files</td></tr>
<tr><td>QITOPS_DATA_DIR</td><td>Directory containing data files</td></tr>
<tr><td>QITOPS_MODEL_PATH</td><td>Path to AI model weights</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-reference-1"><a class="header" href="#configuration-reference-1">Configuration Reference</a></h1>
<p>This page provides detailed information on configuring QitOps for different test types.</p>
<h2 id="api-test-configuration-4"><a class="header" href="#api-test-configuration-4">API Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Example API Test",
    "description": "Test description",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "url": "https://api.example.com",
    "method": "GET",
    "headers": {
        "Accept": "application/json",
        "User-Agent": "QitOps-Test"
    },
    "expected_status": 200,
    "expected_body": {
        "field1": "value1",
        "field2": "value2"
    },
    "max_response_time": 2,
    "expected_headers": {
        "content-type": "application/json",
        "cache-control": "no-cache"
    },
    "retry": {
        "max_retries": 3,
        "initial_delay_ms": 100,
        "max_delay_ms": 1000,
        "retry_status_codes": [408, 429, 500, 502, 503, 504],
        "retry_on_timeout": true,
        "retry_on_connection_error": true
    }
}
</code></pre>
<h3 id="api-test-configuration-fields"><a class="header" href="#api-test-configuration-fields">API Test Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td>name</td><td>string</td><td>Yes</td><td>Name of the test</td></tr>
<tr><td>description</td><td>string</td><td>No</td><td>Description of the test</td></tr>
<tr><td>timeout</td><td>number</td><td>No</td><td>Request timeout in seconds (default: 30)</td></tr>
<tr><td>retries</td><td>number</td><td>No</td><td>Number of retries (default: 3)</td></tr>
<tr><td>environment</td><td>string</td><td>No</td><td>Environment to use (default: production)</td></tr>
<tr><td>url</td><td>string</td><td>Yes</td><td>URL to test</td></tr>
<tr><td>method</td><td>string</td><td>Yes</td><td>HTTP method (GET, POST, PUT, DELETE, etc.)</td></tr>
<tr><td>headers</td><td>object</td><td>No</td><td>HTTP headers to send</td></tr>
<tr><td>body</td><td>object/string</td><td>No</td><td>Request body (JSON object or string)</td></tr>
<tr><td>expected_status</td><td>number</td><td>No</td><td>Expected HTTP status code (default: 200)</td></tr>
<tr><td>expected_body</td><td>object/string</td><td>No</td><td>Expected response body (JSON object or string)</td></tr>
<tr><td>max_response_time</td><td>number</td><td>No</td><td>Maximum acceptable response time in seconds</td></tr>
<tr><td>expected_headers</td><td>object</td><td>No</td><td>Expected response headers</td></tr>
<tr><td>retry</td><td>object</td><td>No</td><td>Retry configuration</td></tr>
</tbody></table>
</div>
<h2 id="api-collection-configuration-2"><a class="header" href="#api-collection-configuration-2">API Collection Configuration</a></h2>
<pre><code class="language-json">{
    "name": "GitHub API Collection",
    "description": "A collection of GitHub API tests",
    "version": "1.0.0",
    "variables": {
        "base_url": "https://api.github.com",
        "username": "octocat",
        "repo": "Hello-World"
    },
    "auth": {
        "type": "bearer",
        "token": "{{GITHUB_TOKEN}}"
    },
    "defaults": {
        "headers": {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "QitOps-Test"
        },
        "timeout": 30,
        "retries": 3
    },
    "requests": [
        {
            "name": "Get User",
            "description": "Get a GitHub user",
            "id": "get-user",
            "url": "{{base_url}}/users/{{username}}",
            "method": "GET",
            "expected_status": 200,
            "expected_body": {
                "login": "{{username}}",
                "type": "User"
            },
            "capture": {
                "user_id": "$.id",
                "user_url": "$.url"
            }
        },
        {
            "name": "Get User Repos",
            "description": "Get repositories for a user",
            "id": "get-user-repos",
            "url": "{{user_url}}/repos",
            "method": "GET",
            "depends_on": ["get-user"],
            "expected_status": 200
        }
    ],
    "environments": {
        "production": {
            "base_url": "https://api.github.com"
        },
        "staging": {
            "base_url": "https://api.staging.github.com"
        }
    },
    "run_options": {
        "sequential": true,
        "stop_on_failure": true,
        "delay_between_requests_ms": 500
    }
}
</code></pre>
<h2 id="performance-test-configuration-4"><a class="header" href="#performance-test-configuration-4">Performance Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Sample Performance Test",
    "description": "Load testing a public API endpoint",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com/endpoint",
    "method": "GET",
    "headers": {
        "Accept": "application/json"
    },
    "success_threshold": 95.0,
    "ramp_up_time_secs": 5
}
</code></pre>
<h2 id="security-test-configuration-2"><a class="header" href="#security-test-configuration-2">Security Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Security Scan",
    "description": "Comprehensive security scan of the API",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://api.example.com",
    "headers": {
        "Accept": "application/json"
    },
    "auth": {
        "type": "bearer",
        "token": "your-token"
    },
    "scan_types": [
        "headers",
        "ssl",
        "vulnerabilities",
        "sensitive-data"
    ],
    "max_high_severity_findings": 0
}
</code></pre>
<h2 id="web-test-configuration-2"><a class="header" href="#web-test-configuration-2">Web Test Configuration</a></h2>
<pre><code class="language-json">{
    "name": "Sample Web Test",
    "description": "Testing a public website",
    "timeout": 30,
    "retries": 3,
    "environment": "production",
    "target_url": "https://example.com",
    "viewport": {
        "width": 1280,
        "height": 800,
        "device_scale_factor": 1.0,
        "is_mobile": false
    },
    "wait_for_selector": "body",
    "wait_timeout_secs": 10,
    "screenshots": true,
    "user_agent": "QitOps-WebTester/1.0",
    "assertions": [
        {
            "assertion_type": "title",
            "expected_value": "Example Domain",
            "comparison": "contains"
        },
        {
            "assertion_type": "element",
            "selector": "h1",
            "expected_value": "true"
        }
    ],
    "actions": [
        {
            "action_type": "wait",
            "wait_time_ms": 1000
        },
        {
            "action_type": "click",
            "selector": "a"
        }
    ]
}
</code></pre>
<h2 id="ai-configuration-2"><a class="header" href="#ai-configuration-2">AI Configuration</a></h2>
<pre><code class="language-json">{
    "model_type": "llama",
    "model_path": "/usr/local/share/models/llama-2-7b-chat.gguf",
    "context_size": 4096,
    "temperature": 0.7,
    "max_tokens": 2048,
    "system_prompt": "You are an AI assistant specialized in software testing. Your task is to help generate test configurations, analyze test results, and suggest improvements."
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="best-practices-12"><a class="header" href="#best-practices-12">Best Practices</a></h1>
<p>This page provides recommendations on how to use QitOps effectively.</p>
<h2 id="general-best-practices"><a class="header" href="#general-best-practices">General Best Practices</a></h2>
<h3 id="configuration-management"><a class="header" href="#configuration-management">Configuration Management</a></h3>
<ul>
<li><strong>Use Version Control</strong>: Store your test configurations in a version control system like Git.</li>
<li><strong>Environment-Specific Configurations</strong>: Use environment-specific configurations for different environments (development, staging, production).</li>
<li><strong>Parameterize Configurations</strong>: Use variables and environment variables to parameterize your configurations.</li>
<li><strong>Validate Configurations</strong>: Use the JSON schema validation feature to validate your configurations.</li>
</ul>
<h3 id="test-organization-2"><a class="header" href="#test-organization-2">Test Organization</a></h3>
<ul>
<li><strong>Group Related Tests</strong>: Group related tests into collections or directories.</li>
<li><strong>Use Descriptive Names</strong>: Use descriptive names for your tests and collections.</li>
<li><strong>Include Descriptions</strong>: Include descriptions for your tests and collections to document their purpose.</li>
<li><strong>Tag Tests</strong>: Use tags to categorize tests for easier filtering and reporting.</li>
</ul>
<h3 id="cicd-integration-5"><a class="header" href="#cicd-integration-5">CI/CD Integration</a></h3>
<ul>
<li><strong>Use CI Mode</strong>: Use the <code>--ci-mode</code> flag when running tests in CI/CD pipelines.</li>
<li><strong>Generate Reports</strong>: Generate reports in a format that can be consumed by your CI/CD system.</li>
<li><strong>Set Exit Codes</strong>: Use exit codes to determine the success or failure of your tests.</li>
<li><strong>Store Artifacts</strong>: Store test results and reports as artifacts for historical analysis.</li>
</ul>
<h2 id="api-testing-best-practices"><a class="header" href="#api-testing-best-practices">API Testing Best Practices</a></h2>
<h3 id="test-design-2"><a class="header" href="#test-design-2">Test Design</a></h3>
<ul>
<li><strong>Test Happy Paths</strong>: Test the expected behavior of your API.</li>
<li><strong>Test Edge Cases</strong>: Test edge cases and error conditions.</li>
<li><strong>Test Performance</strong>: Test the performance of your API under different loads.</li>
<li><strong>Test Security</strong>: Test the security of your API.</li>
</ul>
<h3 id="request-configuration-1"><a class="header" href="#request-configuration-1">Request Configuration</a></h3>
<ul>
<li><strong>Set Timeouts</strong>: Set appropriate timeouts for your requests.</li>
<li><strong>Configure Retries</strong>: Configure retries for transient failures.</li>
<li><strong>Set Headers</strong>: Set appropriate headers for your requests.</li>
<li><strong>Validate Responses</strong>: Validate response status codes, headers, and bodies.</li>
</ul>
<h3 id="collections"><a class="header" href="#collections">Collections</a></h3>
<ul>
<li><strong>Define Dependencies</strong>: Define dependencies between requests to create test workflows.</li>
<li><strong>Capture Data</strong>: Capture data from responses to use in subsequent requests.</li>
<li><strong>Use Variables</strong>: Use variables to parameterize your requests.</li>
<li><strong>Set Default Headers</strong>: Set default headers for all requests in a collection.</li>
</ul>
<h2 id="performance-testing-best-practices"><a class="header" href="#performance-testing-best-practices">Performance Testing Best Practices</a></h2>
<h3 id="test-design-3"><a class="header" href="#test-design-3">Test Design</a></h3>
<ul>
<li><strong>Define Clear Objectives</strong>: Define clear performance objectives for your tests.</li>
<li><strong>Start Small</strong>: Start with a small number of users and gradually increase.</li>
<li><strong>Test Different Scenarios</strong>: Test different scenarios to understand the performance characteristics of your system.</li>
<li><strong>Monitor System Resources</strong>: Monitor system resources during performance tests.</li>
</ul>
<h3 id="load-profiles-2"><a class="header" href="#load-profiles-2">Load Profiles</a></h3>
<ul>
<li><strong>Use Appropriate Load Profiles</strong>: Use appropriate load profiles for your tests (constant, ramping, spike).</li>
<li><strong>Set Realistic Ramp-Up Times</strong>: Set realistic ramp-up times to avoid overwhelming your system.</li>
<li><strong>Define Thresholds</strong>: Define thresholds for pass/fail criteria.</li>
<li><strong>Use Tags</strong>: Use tags to categorize metrics for detailed analysis.</li>
</ul>
<h2 id="security-testing-best-practices"><a class="header" href="#security-testing-best-practices">Security Testing Best Practices</a></h2>
<h3 id="test-design-4"><a class="header" href="#test-design-4">Test Design</a></h3>
<ul>
<li><strong>Define Security Requirements</strong>: Define clear security requirements for your tests.</li>
<li><strong>Test Different Scan Types</strong>: Test different scan types to identify different types of vulnerabilities.</li>
<li><strong>Set Severity Thresholds</strong>: Set severity thresholds for pass/fail criteria.</li>
<li><strong>Regular Testing</strong>: Perform security tests regularly to identify new vulnerabilities.</li>
</ul>
<h3 id="authentication-3"><a class="header" href="#authentication-3">Authentication</a></h3>
<ul>
<li><strong>Test Authentication</strong>: Test authentication mechanisms to ensure they are secure.</li>
<li><strong>Test Authorization</strong>: Test authorization to ensure users can only access resources they are authorized to access.</li>
<li><strong>Test Input Validation</strong>: Test input validation to prevent injection attacks.</li>
<li><strong>Test Error Handling</strong>: Test error handling to ensure sensitive information is not leaked.</li>
</ul>
<h2 id="web-testing-best-practices"><a class="header" href="#web-testing-best-practices">Web Testing Best Practices</a></h2>
<h3 id="test-design-5"><a class="header" href="#test-design-5">Test Design</a></h3>
<ul>
<li><strong>Test Different Browsers</strong>: Test your web application in different browsers.</li>
<li><strong>Test Different Devices</strong>: Test your web application on different devices.</li>
<li><strong>Test Responsive Design</strong>: Test your web application’s responsive design.</li>
<li><strong>Test Accessibility</strong>: Test your web application’s accessibility.</li>
</ul>
<h3 id="test-automation"><a class="header" href="#test-automation">Test Automation</a></h3>
<ul>
<li><strong>Use Selectors</strong>: Use selectors to identify elements on the page.</li>
<li><strong>Set Wait Conditions</strong>: Set wait conditions to ensure elements are loaded before interacting with them.</li>
<li><strong>Capture Screenshots</strong>: Capture screenshots to document test results.</li>
<li><strong>Test User Flows</strong>: Test common user flows to ensure they work as expected.</li>
</ul>
<h2 id="ai-features-best-practices"><a class="header" href="#ai-features-best-practices">AI Features Best Practices</a></h2>
<h3 id="test-generation"><a class="header" href="#test-generation">Test Generation</a></h3>
<ul>
<li><strong>Provide Clear Descriptions</strong>: Provide clear descriptions when generating tests.</li>
<li><strong>Review Generated Tests</strong>: Review generated tests to ensure they meet your requirements.</li>
<li><strong>Customize Generated Tests</strong>: Customize generated tests to fit your specific needs.</li>
<li><strong>Use as Starting Points</strong>: Use generated tests as starting points for more complex tests.</li>
</ul>
<h3 id="test-analysis"><a class="header" href="#test-analysis">Test Analysis</a></h3>
<ul>
<li><strong>Analyze Test Results</strong>: Analyze test results to identify patterns and issues.</li>
<li><strong>Implement Suggestions</strong>: Implement improvement suggestions to enhance your tests.</li>
<li><strong>Combine with Manual Analysis</strong>: Combine AI analysis with manual analysis for comprehensive insights.</li>
<li><strong>Iterate and Improve</strong>: Use analysis results to iterate and improve your tests.</li>
</ul>
<h2 id="data-driven-testing-best-practices"><a class="header" href="#data-driven-testing-best-practices">Data-Driven Testing Best Practices</a></h2>
<h3 id="test-design-6"><a class="header" href="#test-design-6">Test Design</a></h3>
<ul>
<li><strong>Use Appropriate Data Formats</strong>: Use appropriate data formats (CSV, JSON) for your tests.</li>
<li><strong>Structure Data Properly</strong>: Structure your data properly to ensure it can be used effectively.</li>
<li><strong>Include Edge Cases</strong>: Include edge cases in your data to test boundary conditions.</li>
<li><strong>Parameterize Tests</strong>: Parameterize your tests to use data from external sources.</li>
</ul>
<h3 id="test-execution-2"><a class="header" href="#test-execution-2">Test Execution</a></h3>
<ul>
<li><strong>Set Iteration Limits</strong>: Set limits on the number of iterations to avoid long-running tests.</li>
<li><strong>Configure Stop-on-Failure</strong>: Configure whether to stop on failure or continue with other iterations.</li>
<li><strong>Generate Detailed Reports</strong>: Generate detailed reports for each iteration.</li>
<li><strong>Analyze Aggregate Results</strong>: Analyze aggregate results to identify patterns and issues.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cicd-integration-6"><a class="header" href="#cicd-integration-6">CI/CD Integration</a></h1>
<p>QitOps is designed to integrate seamlessly with CI/CD pipelines, allowing you to automate testing as part of your development workflow.</p>
<h2 id="overview-5"><a class="header" href="#overview-5">Overview</a></h2>
<p>CI/CD integration with QitOps allows you to:</p>
<ul>
<li>Run tests automatically on code changes</li>
<li>Validate API functionality before deployment</li>
<li>Ensure performance meets requirements</li>
<li>Identify security vulnerabilities early</li>
<li>Generate test reports for review</li>
<li>Fail builds when tests don’t meet criteria</li>
</ul>
<h2 id="getting-started-6"><a class="header" href="#getting-started-6">Getting Started</a></h2>
<h3 id="basic-usage-11"><a class="header" href="#basic-usage-11">Basic Usage</a></h3>
<pre><code class="language-bash"># Run in CI mode with JSON report
qitops --ci-mode -r json -o results.json api -c tests/configs/api_test.json

# Run in CI mode with XML report (JUnit format)
qitops --ci-mode -r xml -o test-results.xml api -c tests/configs/api_test.json

# Run in CI mode with HTML report
qitops --ci-mode -r html -o report.html api -c tests/configs/api_test.json
</code></pre>
<h3 id="ci-mode-options"><a class="header" href="#ci-mode-options">CI Mode Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--ci-mode</code></td><td>Run in CI mode (reduced output, exit code based on test results)</td></tr>
<tr><td><code>-r, --report &lt;FORMAT&gt;</code></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td><code>-o, --output &lt;FILE&gt;</code></td><td>Output file for the report</td></tr>
<tr><td><code>--fail-on-error</code></td><td>Exit with non-zero code on any test failure</td></tr>
<tr><td><code>--fail-threshold &lt;PERCENT&gt;</code></td><td>Exit with non-zero code if success rate is below threshold</td></tr>
</tbody></table>
</div>
<h2 id="github-actions-integration"><a class="header" href="#github-actions-integration">GitHub Actions Integration</a></h2>
<p>QitOps can be easily integrated with GitHub Actions workflows.</p>
<h3 id="basic-workflow"><a class="header" href="#basic-workflow">Basic Workflow</a></h3>
<pre><code class="language-yaml">name: QitOps Tests

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Install QitOps
        run: |
          curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
          chmod +x /usr/local/bin/qitops
      
      - name: Run API Tests
        run: |
          qitops --ci-mode -r xml -o api-test-results.xml api -c tests/configs/api_test.json
      
      - name: Upload Test Results
        uses: actions/upload-artifact@v2
        with:
          name: api-test-results
          path: api-test-results.xml
</code></pre>
<h3 id="complete-workflow"><a class="header" href="#complete-workflow">Complete Workflow</a></h3>
<pre><code class="language-yaml">name: QitOps Complete Test Suite

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Install QitOps
        run: |
          curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
          chmod +x /usr/local/bin/qitops
      
      - name: Run API Tests
        run: |
          qitops --ci-mode -r xml -o api-test-results.xml api -c tests/configs/api_test.json
      
      - name: Run API Collection Tests
        run: |
          qitops --ci-mode -r xml -o collection-test-results.xml collection -c tests/configs/api_collection.json
      
      - name: Run Performance Tests
        run: |
          qitops --ci-mode -r json -o performance-test-results.json performance -c tests/configs/performance_test.json
      
      - name: Run Security Tests
        run: |
          qitops --ci-mode -r json -o security-test-results.json security -c tests/configs/security_test.json
      
      - name: Run Web Tests
        run: |
          qitops --ci-mode -r html -o web-test-results.html web -c tests/configs/web_test.json
      
      - name: Upload Test Results
        uses: actions/upload-artifact@v2
        with:
          name: test-results
          path: |
            api-test-results.xml
            collection-test-results.xml
            performance-test-results.json
            security-test-results.json
            web-test-results.html
</code></pre>
<h2 id="gitlab-ci-integration"><a class="header" href="#gitlab-ci-integration">GitLab CI Integration</a></h2>
<p>QitOps can also be integrated with GitLab CI/CD pipelines.</p>
<h3 id="basic-pipeline"><a class="header" href="#basic-pipeline">Basic Pipeline</a></h3>
<pre><code class="language-yaml">stages:
  - test

api-tests:
  stage: test
  image: ubuntu:latest
  script:
    - apt-get update &amp;&amp; apt-get install -y curl
    - curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
    - chmod +x /usr/local/bin/qitops
    - qitops --ci-mode -r json -o api-test-results.json api -c tests/configs/api_test.json
  artifacts:
    paths:
      - api-test-results.json
</code></pre>
<h3 id="complete-pipeline"><a class="header" href="#complete-pipeline">Complete Pipeline</a></h3>
<pre><code class="language-yaml">stages:
  - test
  - performance
  - security

api-tests:
  stage: test
  image: ubuntu:latest
  script:
    - apt-get update &amp;&amp; apt-get install -y curl
    - curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
    - chmod +x /usr/local/bin/qitops
    - qitops --ci-mode -r json -o api-test-results.json api -c tests/configs/api_test.json
  artifacts:
    paths:
      - api-test-results.json

collection-tests:
  stage: test
  image: ubuntu:latest
  script:
    - apt-get update &amp;&amp; apt-get install -y curl
    - curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
    - chmod +x /usr/local/bin/qitops
    - qitops --ci-mode -r json -o collection-test-results.json collection -c tests/configs/api_collection.json
  artifacts:
    paths:
      - collection-test-results.json

performance-tests:
  stage: performance
  image: ubuntu:latest
  script:
    - apt-get update &amp;&amp; apt-get install -y curl
    - curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
    - chmod +x /usr/local/bin/qitops
    - qitops --ci-mode -r json -o performance-test-results.json performance -c tests/configs/performance_test.json
  artifacts:
    paths:
      - performance-test-results.json

security-tests:
  stage: security
  image: ubuntu:latest
  script:
    - apt-get update &amp;&amp; apt-get install -y curl
    - curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
    - chmod +x /usr/local/bin/qitops
    - qitops --ci-mode -r json -o security-test-results.json security -c tests/configs/security_test.json
  artifacts:
    paths:
      - security-test-results.json
</code></pre>
<h2 id="jenkins-integration"><a class="header" href="#jenkins-integration">Jenkins Integration</a></h2>
<p>QitOps can be integrated with Jenkins pipelines.</p>
<h3 id="jenkinsfile-example"><a class="header" href="#jenkinsfile-example">Jenkinsfile Example</a></h3>
<pre><code class="language-groovy">pipeline {
    agent any
    
    stages {
        stage('Install QitOps') {
            steps {
                sh '''
                curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
                chmod +x /usr/local/bin/qitops
                '''
            }
        }
        
        stage('API Tests') {
            steps {
                sh 'qitops --ci-mode -r xml -o api-test-results.xml api -c tests/configs/api_test.json'
            }
            post {
                always {
                    junit 'api-test-results.xml'
                }
            }
        }
        
        stage('Performance Tests') {
            steps {
                sh 'qitops --ci-mode -r json -o performance-test-results.json performance -c tests/configs/performance_test.json'
            }
            post {
                always {
                    archiveArtifacts artifacts: 'performance-test-results.json', fingerprint: true
                }
            }
        }
        
        stage('Security Tests') {
            steps {
                sh 'qitops --ci-mode -r json -o security-test-results.json security -c tests/configs/security_test.json'
            }
            post {
                always {
                    archiveArtifacts artifacts: 'security-test-results.json', fingerprint: true
                }
            }
        }
    }
}
</code></pre>
<h2 id="circleci-integration"><a class="header" href="#circleci-integration">CircleCI Integration</a></h2>
<p>QitOps can be integrated with CircleCI workflows.</p>
<h3 id="configyml-example"><a class="header" href="#configyml-example">config.yml Example</a></h3>
<pre><code class="language-yaml">version: 2.1

jobs:
  api-tests:
    docker:
      - image: cimg/base:2021.04
    steps:
      - checkout
      - run:
          name: Install QitOps
          command: |
            curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
            chmod +x /usr/local/bin/qitops
      - run:
          name: Run API Tests
          command: |
            qitops --ci-mode -r xml -o api-test-results.xml api -c tests/configs/api_test.json
      - store_artifacts:
          path: api-test-results.xml
      - store_test_results:
          path: api-test-results.xml

  performance-tests:
    docker:
      - image: cimg/base:2021.04
    steps:
      - checkout
      - run:
          name: Install QitOps
          command: |
            curl -sSL https://github.com/qitops/qitops-cli-tools/releases/latest/download/qitops-linux-x86_64 -o /usr/local/bin/qitops
            chmod +x /usr/local/bin/qitops
      - run:
          name: Run Performance Tests
          command: |
            qitops --ci-mode -r json -o performance-test-results.json performance -c tests/configs/performance_test.json
      - store_artifacts:
          path: performance-test-results.json

workflows:
  version: 2
  test:
    jobs:
      - api-tests
      - performance-tests
</code></pre>
<h2 id="best-practices-13"><a class="header" href="#best-practices-13">Best Practices</a></h2>
<h3 id="test-organization-3"><a class="header" href="#test-organization-3">Test Organization</a></h3>
<ul>
<li><strong>Group Related Tests</strong>: Group related tests in separate configuration files</li>
<li><strong>Use Environment Variables</strong>: Use environment variables for sensitive information</li>
<li><strong>Parameterize Configurations</strong>: Use variables and environment variables to parameterize your configurations</li>
<li><strong>Use CI-Specific Configurations</strong>: Create CI-specific configurations for different environments</li>
</ul>
<h3 id="cicd-integration-7"><a class="header" href="#cicd-integration-7">CI/CD Integration</a></h3>
<ul>
<li><strong>Use CI Mode</strong>: Always use the <code>--ci-mode</code> flag when running tests in CI/CD pipelines</li>
<li><strong>Generate Reports</strong>: Generate reports in a format that can be consumed by your CI/CD system</li>
<li><strong>Set Exit Codes</strong>: Use exit codes to determine the success or failure of your tests</li>
<li><strong>Store Artifacts</strong>: Store test results and reports as artifacts for historical analysis</li>
</ul>
<h3 id="performance-considerations-1"><a class="header" href="#performance-considerations-1">Performance Considerations</a></h3>
<ul>
<li><strong>Optimize Test Execution</strong>: Optimize test execution to reduce CI/CD pipeline time</li>
<li><strong>Run Tests in Parallel</strong>: Run tests in parallel where possible</li>
<li><strong>Use Caching</strong>: Use caching to speed up test execution</li>
<li><strong>Limit Test Scope</strong>: Limit test scope based on changes to reduce execution time</li>
</ul>
<h2 id="troubleshooting-9"><a class="header" href="#troubleshooting-9">Troubleshooting</a></h2>
<h3 id="common-issues-7"><a class="header" href="#common-issues-7">Common Issues</a></h3>
<ul>
<li><strong>Exit Codes</strong>: QitOps returns non-zero exit codes on test failures when <code>--ci-mode</code> is used</li>
<li><strong>Report Formats</strong>: Different CI/CD systems support different report formats</li>
<li><strong>Environment Variables</strong>: Ensure environment variables are properly set in your CI/CD environment</li>
<li><strong>Permissions</strong>: Ensure QitOps has the necessary permissions to run tests</li>
</ul>
<h3 id="cicd-system-specific-issues"><a class="header" href="#cicd-system-specific-issues">CI/CD System-Specific Issues</a></h3>
<ul>
<li><strong>GitHub Actions</strong>: Use the <code>actions/upload-artifact</code> action to store test results</li>
<li><strong>GitLab CI</strong>: Use the <code>artifacts</code> section to store test results</li>
<li><strong>Jenkins</strong>: Use the <code>junit</code> step to process XML test results</li>
<li><strong>CircleCI</strong>: Use the <code>store_test_results</code> step to process test results</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-driven-testing-6"><a class="header" href="#data-driven-testing-6">Data-Driven Testing</a></h1>
<p>Data-driven testing allows you to run the same test with multiple sets of data, making it easy to test different scenarios without duplicating test configurations. QitOps provides robust support for data-driven testing with CSV and JSON data sources.</p>
<h2 id="overview-6"><a class="header" href="#overview-6">Overview</a></h2>
<p>Data-driven testing in QitOps works by:</p>
<ol>
<li>Creating a test configuration template with placeholders</li>
<li>Providing a data source (CSV or JSON) with values for the placeholders</li>
<li>Running the test for each row/entry in the data source</li>
<li>Generating a report with results for each iteration</li>
</ol>
<p>This approach is particularly useful for:</p>
<ul>
<li>Testing APIs with different input parameters</li>
<li>Validating business logic with multiple test cases</li>
<li>Performance testing with various payload sizes</li>
<li>Security testing with different authentication credentials</li>
<li>Web testing with different user journeys</li>
</ul>
<h2 id="getting-started-7"><a class="header" href="#getting-started-7">Getting Started</a></h2>
<h3 id="basic-usage-12"><a class="header" href="#basic-usage-12">Basic Usage</a></h3>
<pre><code class="language-bash"># Run data-driven tests with CSV data
qitops data-driven -c tests/configs/data_driven_api_test.json -d tests/data/users.csv -t csv

# Run data-driven tests with JSON data
qitops data-driven -c tests/configs/data_driven_collection.json -d tests/data/products.json -t json
</code></pre>
<h3 id="command-line-options-12"><a class="header" href="#command-line-options-12">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>-c, --config &lt;FILE&gt;</code></td><td>Test configuration file</td></tr>
<tr><td><code>-d, --data &lt;FILE&gt;</code></td><td>Data source file (CSV or JSON)</td></tr>
<tr><td><code>-t, --type &lt;TYPE&gt;</code></td><td>Data source type (csv or json)</td></tr>
<tr><td><code>--limit &lt;NUMBER&gt;</code></td><td>Maximum number of iterations to run</td></tr>
<tr><td><code>--stop-on-failure</code></td><td>Stop execution after the first failure</td></tr>
<tr><td><code>--delay &lt;MILLISECONDS&gt;</code></td><td>Delay between iterations in milliseconds</td></tr>
<tr><td><code>-r, --report &lt;FORMAT&gt;</code></td><td>Report format (json, html, xml, csv)</td></tr>
<tr><td><code>-o, --output &lt;FILE&gt;</code></td><td>Output file for the report</td></tr>
</tbody></table>
</div>
<h2 id="configuration-templates"><a class="header" href="#configuration-templates">Configuration Templates</a></h2>
<p>Test configuration templates use the <code>{{variable}}</code> syntax for placeholders that will be replaced with values from the data source.</p>
<h3 id="example-api-test-template"><a class="header" href="#example-api-test-template">Example API Test Template</a></h3>
<pre><code class="language-json">{
  "name": "User API Test - {{username}}",
  "description": "Test the user API for {{username}}",
  "url": "https://api.example.com/users/{{username}}",
  "method": "GET",
  "headers": {
    "Authorization": "Bearer {{token}}",
    "Accept": "application/json"
  },
  "expected_status": {{expected_status}},
  "expected_body": {
    "username": "{{username}}",
    "email": "{{email}}",
    "role": "{{role}}"
  }
}
</code></pre>
<h3 id="example-api-collection-template"><a class="header" href="#example-api-collection-template">Example API Collection Template</a></h3>
<pre><code class="language-json">{
  "name": "Product API Collection - {{product_id}}",
  "description": "Test product API flows for {{product_name}}",
  "variables": {
    "base_url": "https://api.example.com",
    "product_id": "{{product_id}}",
    "product_name": "{{product_name}}",
    "price": {{price}}
  },
  "requests": [
    {
      "name": "Get Product",
      "id": "get-product",
      "url": "{{base_url}}/products/{{product_id}}",
      "method": "GET",
      "expected_status": 200,
      "expected_body": {
        "id": "{{product_id}}",
        "name": "{{product_name}}",
        "price": {{price}}
      },
      "capture": {
        "product_url": "$.url"
      }
    },
    {
      "name": "Get Product Reviews",
      "id": "get-product-reviews",
      "url": "{{product_url}}/reviews",
      "method": "GET",
      "depends_on": ["get-product"],
      "expected_status": 200
    }
  ]
}
</code></pre>
<h2 id="data-sources"><a class="header" href="#data-sources">Data Sources</a></h2>
<h3 id="csv-data-source"><a class="header" href="#csv-data-source">CSV Data Source</a></h3>
<p>CSV files should have a header row with column names that match the placeholder names in the template.</p>
<p>Example <code>users.csv</code>:</p>
<pre><code class="language-csv">username,email,role,token,expected_status
user1,user1@example.com,user,token123,200
user2,user2@example.com,admin,token456,200
nonexistent,,,token789,404
</code></pre>
<h3 id="json-data-source"><a class="header" href="#json-data-source">JSON Data Source</a></h3>
<p>JSON data sources can be either an array of objects or a single object with arrays as values.</p>
<p>Example <code>products.json</code> (array of objects):</p>
<pre><code class="language-json">[
  {
    "product_id": "prod-001",
    "product_name": "Smartphone",
    "price": 999.99,
    "category": "electronics"
  },
  {
    "product_id": "prod-002",
    "product_name": "Laptop",
    "price": 1499.99,
    "category": "electronics"
  },
  {
    "product_id": "prod-003",
    "product_name": "Headphones",
    "price": 199.99,
    "category": "accessories"
  }
]
</code></pre>
<p>Example <code>test_matrix.json</code> (object with arrays):</p>
<pre><code class="language-json">{
  "product_id": ["prod-001", "prod-002", "prod-003"],
  "product_name": ["Smartphone", "Laptop", "Headphones"],
  "price": [999.99, 1499.99, 199.99],
  "category": ["electronics", "electronics", "accessories"]
}
</code></pre>
<h2 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h2>
<h3 id="iteration-control"><a class="header" href="#iteration-control">Iteration Control</a></h3>
<p>Control the number of iterations and behavior on failure:</p>
<pre><code class="language-bash"># Limit to first 10 iterations
qitops data-driven -c config.json -d data.csv -t csv --limit 10

# Stop on first failure
qitops data-driven -c config.json -d data.csv -t csv --stop-on-failure

# Add delay between iterations (500ms)
qitops data-driven -c config.json -d data.csv -t csv --delay 500
</code></pre>
<h3 id="data-transformation"><a class="header" href="#data-transformation">Data Transformation</a></h3>
<p>QitOps supports basic data transformation using template functions:</p>
<pre><code class="language-json">{
  "url": "https://api.example.com/users/{{lowercase:username}}",
  "headers": {
    "Authorization": "Bearer {{uppercase:token}}"
  },
  "body": {
    "timestamp": "{{now}}",
    "random_id": "{{uuid}}",
    "formatted_price": "{{format_number:price}}"
  }
}
</code></pre>
<p>Available functions:</p>
<ul>
<li><code>lowercase</code>: Convert to lowercase</li>
<li><code>uppercase</code>: Convert to uppercase</li>
<li><code>now</code>: Current timestamp</li>
<li><code>uuid</code>: Generate a UUID</li>
<li><code>format_number</code>: Format a number with commas</li>
<li><code>base64_encode</code>: Encode to Base64</li>
<li><code>base64_decode</code>: Decode from Base64</li>
<li><code>url_encode</code>: URL encode a string</li>
<li><code>url_decode</code>: URL decode a string</li>
</ul>
<h3 id="environment-variables-2"><a class="header" href="#environment-variables-2">Environment Variables</a></h3>
<p>You can use environment variables in your data sources:</p>
<pre><code class="language-bash"># Set environment variables
export API_TOKEN="your-secret-token"
export API_URL="https://api.example.com"

# Run with environment variables
qitops data-driven -c config.json -d data.csv -t csv
</code></pre>
<p>In your CSV file:</p>
<pre><code class="language-csv">username,token,api_url
user1,${API_TOKEN},${API_URL}/users
user2,${API_TOKEN},${API_URL}/admin
</code></pre>
<h2 id="reporting"><a class="header" href="#reporting">Reporting</a></h2>
<p>Generate detailed reports for data-driven tests:</p>
<pre><code class="language-bash"># Generate JSON report
qitops data-driven -c config.json -d data.csv -t csv -r json -o report.json

# Generate HTML report
qitops data-driven -c config.json -d data.csv -t csv -r html -o report.html

# Generate CSV report
qitops data-driven -c config.json -d data.csv -t csv -r csv -o results.csv
</code></pre>
<p>The reports include:</p>
<ul>
<li>Summary of all iterations</li>
<li>Individual results for each iteration</li>
<li>Execution time for each iteration</li>
<li>Success/failure status</li>
<li>Error messages for failed iterations</li>
<li>Captured values</li>
</ul>
<h2 id="best-practices-14"><a class="header" href="#best-practices-14">Best Practices</a></h2>
<h3 id="organizing-data-files"><a class="header" href="#organizing-data-files">Organizing Data Files</a></h3>
<ul>
<li>Keep data files in a dedicated directory (e.g., <code>tests/data/</code>)</li>
<li>Use descriptive filenames that indicate the test scenario</li>
<li>Version control your data files alongside your test configurations</li>
<li>Document the structure and purpose of your data files</li>
</ul>
<h3 id="test-design-7"><a class="header" href="#test-design-7">Test Design</a></h3>
<ul>
<li>Start with a small data set during development</li>
<li>Gradually add more test cases as you refine your tests</li>
<li>Include edge cases and error scenarios</li>
<li>Use meaningful placeholder names that reflect their purpose</li>
<li>Group related tests into collections</li>
</ul>
<h3 id="performance-considerations-2"><a class="header" href="#performance-considerations-2">Performance Considerations</a></h3>
<ul>
<li>For large data sets, consider using the <code>--limit</code> option during development</li>
<li>Monitor memory usage when testing with very large data sets</li>
<li>Use the <code>--delay</code> option to prevent overwhelming the system under test</li>
<li>Consider splitting very large data sets into multiple files</li>
</ul>
<h2 id="examples-5"><a class="header" href="#examples-5">Examples</a></h2>
<h3 id="testing-user-registration"><a class="header" href="#testing-user-registration">Testing User Registration</a></h3>
<p>Configuration (<code>user_registration.json</code>):</p>
<pre><code class="language-json">{
  "name": "User Registration - {{username}}",
  "description": "Test user registration with {{email}}",
  "url": "https://api.example.com/register",
  "method": "POST",
  "headers": {
    "Content-Type": "application/json"
  },
  "body": {
    "username": "{{username}}",
    "email": "{{email}}",
    "password": "{{password}}",
    "age": {{age}}
  },
  "expected_status": {{expected_status}},
  "expected_body": {
    "success": {{expected_success}},
    "message": "{{expected_message}}"
  }
}
</code></pre>
<p>Data (<code>registration_data.csv</code>):</p>
<pre><code class="language-csv">username,email,password,age,expected_status,expected_success,expected_message
validuser,valid@example.com,Password123,30,201,true,User registered successfully
,invalid@example.com,Password123,30,400,false,Username is required
validuser,,Password123,30,400,false,Email is required
validuser,valid@example.com,,30,400,false,Password is required
validuser,valid@example.com,Password123,17,400,false,Age must be 18 or older
</code></pre>
<p>Command:</p>
<pre><code class="language-bash">qitops data-driven -c user_registration.json -d registration_data.csv -t csv -r html -o registration_report.html
</code></pre>
<h3 id="testing-product-search"><a class="header" href="#testing-product-search">Testing Product Search</a></h3>
<p>Configuration (<code>product_search.json</code>):</p>
<pre><code class="language-json">{
  "name": "Product Search - {{query}}",
  "description": "Test product search with query '{{query}}'",
  "url": "https://api.example.com/products/search?q={{url_encode:query}}&amp;category={{category}}&amp;min_price={{min_price}}&amp;max_price={{max_price}}",
  "method": "GET",
  "headers": {
    "Accept": "application/json"
  },
  "expected_status": 200,
  "assertions": [
    {
      "type": "json",
      "path": "$.total_results",
      "comparison": "&gt;=",
      "value": {{min_expected_results}}
    },
    {
      "type": "json",
      "path": "$.products[0].category",
      "comparison": "equals",
      "value": "{{category}}"
    }
  ]
}
</code></pre>
<p>Data (<code>search_queries.json</code>):</p>
<pre><code class="language-json">[
  {
    "query": "smartphone",
    "category": "electronics",
    "min_price": 500,
    "max_price": 2000,
    "min_expected_results": 5
  },
  {
    "query": "laptop",
    "category": "electronics",
    "min_price": 1000,
    "max_price": 3000,
    "min_expected_results": 3
  },
  {
    "query": "headphones",
    "category": "accessories",
    "min_price": 50,
    "max_price": 500,
    "min_expected_results": 10
  }
]
</code></pre>
<p>Command:</p>
<pre><code class="language-bash">qitops data-driven -c product_search.json -d search_queries.json -t json -r json -o search_results.json
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="qitops-roadmap"><a class="header" href="#qitops-roadmap">QitOps Roadmap</a></h1>
<p>This document outlines the development roadmap for QitOps, positioning it as a compelling alternative to established testing tools like Postman and k6.</p>
<h2 id="vision"><a class="header" href="#vision">Vision</a></h2>
<p>QitOps aims to be the premier CLI-first testing tool for developers and QA professionals, offering a unified interface for API, performance, security, and web testing with minimal dependencies and maximum flexibility.</p>
<h2 id="-phase-0-lock-the-core-current"><a class="header" href="#-phase-0-lock-the-core-current">🔁 Phase 0: Lock the Core (Current)</a></h2>
<p>Before pursuing feature parity with other tools, we’re focusing on making the current implementation rock-solid:</p>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic API testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic performance testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic security testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement basic web testing module</li>
<li><input disabled="" type="checkbox" checked=""/>
Finalize and stabilize all core modules</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement JSON config schema validation in common.rs</li>
<li><input disabled="" type="checkbox"/>
Clean CLI output with –format options (JSON, human)</li>
<li><input disabled="" type="checkbox"/>
Ensure cargo build –release produces a static binary</li>
<li><input disabled="" type="checkbox" checked=""/>
Document the config format for each testing mode</li>
</ul>
<p><strong>Milestone</strong>: CLI MVP — the “Postman/k6 replacement for power users”</p>
<h2 id="-phase-1-parity-foundation-0-2-months"><a class="header" href="#-phase-1-parity-foundation-0-2-months">📦 Phase 1: Parity Foundation (0-2 months)</a></h2>
<h3 id="-api-testing-postman-lite"><a class="header" href="#-api-testing-postman-lite">🧪 API Testing: Postman Lite</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement Collections (array of requests in one config)</li>
<li><input disabled="" type="checkbox" checked=""/>
Add Variable &amp; Environment interpolation</li>
<li><input disabled="" type="checkbox" checked=""/>
Add Request chaining via captured outputs</li>
<li><input disabled="" type="checkbox" checked=""/>
Expand Auth to support OAuth2, JWT, API Key</li>
<li><input disabled="" type="checkbox"/>
Add optional –history logging to a local SQLite file</li>
</ul>
<h3 id="-performance-testing-k6-core"><a class="header" href="#-performance-testing-k6-core">⚙️ Performance Testing: k6 Core</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement load profiles (constant, ramp-up, spike)</li>
<li><input disabled="" type="checkbox" checked=""/>
Support scenarios in one file (multiple endpoints)</li>
<li><input disabled="" type="checkbox" checked=""/>
Track custom metrics (via tags)</li>
<li><input disabled="" type="checkbox" checked=""/>
Add thresholds for pass/fail criteria</li>
<li><input disabled="" type="checkbox" checked=""/>
CLI streaming metrics (real-time bar/line output)</li>
</ul>
<p><strong>Milestone</strong>: “Parity with a Purpose”</p>
<h2 id="-phase-2-differentiators-2-4-months"><a class="header" href="#-phase-2-differentiators-2-4-months">🧑‍💻 Phase 2: Differentiators (2-4 months)</a></h2>
<h3 id="-integrations"><a class="header" href="#-integrations">🔧 Integrations</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Git sync for test configs (qitops sync)</li>
<li><input disabled="" type="checkbox" checked=""/>
GitHub Actions example template</li>
<li><input disabled="" type="checkbox"/>
Dockerfile for CLI-only image</li>
<li><input disabled="" type="checkbox" checked=""/>
Native CI support: –ci-mode</li>
</ul>
<h3 id="-reporting"><a class="header" href="#-reporting">📊 Reporting</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
JSON + HTML reporters (extend with templates)</li>
<li><input disabled="" type="checkbox"/>
Markdown summary logs (for commits)</li>
<li><input disabled="" type="checkbox" checked=""/>
CSV export for audit logs</li>
</ul>
<h3 id="-data-driven-testing"><a class="header" href="#-data-driven-testing">🧪 Data-Driven Testing</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Parametrize tests with CSV/JSON datasets</li>
<li><input disabled="" type="checkbox" checked=""/>
Support template placeholders: {{user_id}}</li>
</ul>
<p><strong>Milestone</strong>: “Beyond Parity”</p>
<h2 id="-phase-3-ai--ecosystem-4-6-months"><a class="header" href="#-phase-3-ai--ecosystem-4-6-months">🧠 Phase 3: AI &amp; Ecosystem (4-6 months)</a></h2>
<h3 id="-plugin-architecture-cli-first"><a class="header" href="#-plugin-architecture-cli-first">🔌 Plugin Architecture (CLI-first)</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Define QitOpsPlugin trait</li>
<li><input disabled="" type="checkbox"/>
Implement dynamic plugin loader (optional shared lib .so or .dll)</li>
</ul>
<h3 id="-ai-integration"><a class="header" href="#-ai-integration">🧠 AI Integration</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Generate tests from OpenAPI files</li>
<li><input disabled="" type="checkbox"/>
Record &amp; replay traffic (CLI proxy + storage)</li>
<li><input disabled="" type="checkbox"/>
Recommend missing edge cases or optimization via LLM</li>
</ul>
<h3 id="-ui-optional"><a class="header" href="#-ui-optional">🖥️ UI (Optional)</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Add TUI with textual or ratatui</li>
<li><input disabled="" type="checkbox"/>
Optional Web UI (if CLI usage + community demand)</li>
</ul>
<p><strong>Milestone</strong>: “Next-Generation Testing Platform”</p>
<h2 id="-strategic-advantages"><a class="header" href="#-strategic-advantages">📈 Strategic Advantages</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Why It Wins</th></tr></thead><tbody>
<tr><td>Unified Tool</td><td>One CLI for API, performance, security, and (later) AI</td></tr>
<tr><td>Rust Static Binary</td><td>No runtime, no nonsense — fast and portable</td></tr>
<tr><td>Open Source CLI-first</td><td>Speaks devops, CI, Git</td></tr>
<tr><td>TestOps as Code</td><td>Config-driven testing becomes auditable, repeatable</td></tr>
<tr><td>QitOps OS-ready</td><td>Tightest vertical integration possible — CLI + OS</td></tr>
</tbody></table>
</div>
<h2 id="contributing-1"><a class="header" href="#contributing-1">Contributing</a></h2>
<p>We welcome contributions to help realize this roadmap! See our <a href="CONTRIBUTING.html">CONTRIBUTING.md</a> for guidelines on how to get involved.</p>
<h2 id="prioritization"><a class="header" href="#prioritization">Prioritization</a></h2>
<p>This roadmap is subject to change based on community feedback and evolving requirements. The core team will prioritize features based on:</p>
<ol>
<li>Core stability and reliability</li>
<li>Features that enable CI/CD integration</li>
<li>Features that differentiate QitOps from competitors</li>
<li>Features that expand the ecosystem</li>
</ol>
<h2 id="immediate-next-steps"><a class="header" href="#immediate-next-steps">Immediate Next Steps</a></h2>
<ul>
<li>Finalize the README and document config structure per test type</li>
<li>Create a qitops-collections.json sample and scaffold the feature</li>
<li>Start with simple chaining: response.body.token → next.headers.Authorization</li>
<li>Prep plugin.rs with trait + registration model (even before loading logic)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="enhancement-ideas"><a class="header" href="#enhancement-ideas">Enhancement Ideas</a></h1>
<p>This page documents potential enhancements and feature ideas for future QitOps releases. These suggestions are collected from user feedback, community discussions, and internal planning.</p>
<h2 id="web-ui-enhancements"><a class="header" href="#web-ui-enhancements">Web UI Enhancements</a></h2>
<h3 id="real-time-progress-feedback"><a class="header" href="#real-time-progress-feedback">Real-time Progress Feedback</a></h3>
<ul>
<li><strong>Description</strong>: Add real-time progress feedback on test generation and execution via a <code>/status</code> endpoint</li>
<li><strong>Benefits</strong>:
<ul>
<li>Provides visibility into long-running operations</li>
<li>Improves user experience for complex test generation</li>
<li>Allows for cancellation of operations that take too long</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Create a background task system for long-running operations</li>
<li>Implement a <code>/status/:task_id</code> endpoint to query task status</li>
<li>Add WebSocket support for real-time updates</li>
<li>Include progress percentage, current step, and estimated time remaining</li>
</ul>
</li>
</ul>
<h2 id="ai-improvements"><a class="header" href="#ai-improvements">AI Improvements</a></h2>
<h3 id="model-confidence-scoring"><a class="header" href="#model-confidence-scoring">Model Confidence Scoring</a></h3>
<ul>
<li><strong>Description</strong>: Add confidence scoring to AI-generated outputs</li>
<li><strong>Benefits</strong>:
<ul>
<li>Helps users identify potentially unreliable test cases</li>
<li>Provides transparency into AI decision-making</li>
<li>Allows for filtering or highlighting based on confidence</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Extract token logprobs from supported models</li>
<li>Implement confidence calculation algorithms</li>
<li>Add confidence metadata to generated test configurations</li>
<li>Provide visual indicators in reports and UI</li>
</ul>
</li>
</ul>
<h3 id="ai-feedback-loop"><a class="header" href="#ai-feedback-loop">AI Feedback Loop</a></h3>
<ul>
<li><strong>Description</strong>: Add endpoint to rate AI-generated test cases to refine prompts and models</li>
<li><strong>Benefits</strong>:
<ul>
<li>Continuously improves AI generation quality</li>
<li>Captures domain-specific knowledge</li>
<li>Personalizes generation based on user preferences</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement a simple rating system (1-5 stars or thumbs up/down)</li>
<li>Store feedback with associated prompts and outputs</li>
<li>Create a feedback analysis dashboard</li>
<li>Implement prompt refinement based on feedback patterns</li>
</ul>
</li>
</ul>
<h3 id="prompt-flexibility"><a class="header" href="#prompt-flexibility">Prompt Flexibility</a></h3>
<ul>
<li><strong>Description</strong>: Let users choose between different test templates (basic, exhaustive, risk-based)</li>
<li><strong>Benefits</strong>:
<ul>
<li>Accommodates different testing philosophies</li>
<li>Provides appropriate detail level for different scenarios</li>
<li>Allows for specialized testing approaches</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Create a library of prompt templates for different testing styles</li>
<li>Allow template selection via CLI and configuration</li>
<li>Implement template customization and saving</li>
<li>Add documentation for each template type</li>
</ul>
</li>
</ul>
<h2 id="validation-and-quality"><a class="header" href="#validation-and-quality">Validation and Quality</a></h2>
<h3 id="schema-validation"><a class="header" href="#schema-validation">Schema Validation</a></h3>
<ul>
<li><strong>Description</strong>: Add schema validation for input configurations to catch malformed test JSONs</li>
<li><strong>Benefits</strong>:
<ul>
<li>Prevents runtime errors from invalid configurations</li>
<li>Provides clear error messages for configuration issues</li>
<li>Improves overall reliability</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Define JSON Schema for all configuration types</li>
<li>Implement validation at configuration load time</li>
<li>Add detailed error reporting with line numbers and suggestions</li>
<li>Create a configuration linting command</li>
</ul>
</li>
</ul>
<h3 id="ci-snapshot-mode"><a class="header" href="#ci-snapshot-mode">CI Snapshot Mode</a></h3>
<ul>
<li><strong>Description</strong>: Auto-compare results with previous CI runs to detect regressions</li>
<li><strong>Benefits</strong>:
<ul>
<li>Automatically identifies performance regressions</li>
<li>Tracks test stability over time</li>
<li>Provides historical context for test results</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement result storage and retrieval system</li>
<li>Create comparison algorithms for different test types</li>
<li>Add visualization for trend analysis</li>
<li>Integrate with CI systems for automatic comparison</li>
</ul>
</li>
</ul>
<h2 id="output-and-documentation"><a class="header" href="#output-and-documentation">Output and Documentation</a></h2>
<h3 id="markdown-output-mode"><a class="header" href="#markdown-output-mode">Markdown Output Mode</a></h3>
<ul>
<li><strong>Description</strong>: Add optional Markdown output mode for direct pasting into GitHub/GitLab repos</li>
<li><strong>Benefits</strong>:
<ul>
<li>Simplifies documentation workflow</li>
<li>Improves readability in Git repositories</li>
<li>Facilitates sharing of test results</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement Markdown formatter for test results</li>
<li>Add templates for different documentation styles</li>
<li>Include options for embedding charts and tables</li>
<li>Support custom styling via CSS</li>
</ul>
</li>
</ul>
<h2 id="performance-optimizations"><a class="header" href="#performance-optimizations">Performance Optimizations</a></h2>
<h3 id="parallel-test-execution"><a class="header" href="#parallel-test-execution">Parallel Test Execution</a></h3>
<ul>
<li><strong>Description</strong>: Implement parallel execution for independent tests</li>
<li><strong>Benefits</strong>:
<ul>
<li>Reduces overall test execution time</li>
<li>Better utilizes system resources</li>
<li>Improves CI/CD pipeline efficiency</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Analyze test dependencies to identify parallelizable tests</li>
<li>Implement worker pool for parallel execution</li>
<li>Add configuration options for controlling parallelism</li>
<li>Provide visualization of parallel execution</li>
</ul>
</li>
</ul>
<h3 id="result-caching"><a class="header" href="#result-caching">Result Caching</a></h3>
<ul>
<li><strong>Description</strong>: Cache test results to avoid redundant execution</li>
<li><strong>Benefits</strong>:
<ul>
<li>Speeds up repeated test runs</li>
<li>Reduces load on tested systems</li>
<li>Improves developer experience</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement intelligent caching based on test configuration hash</li>
<li>Add cache invalidation strategies</li>
<li>Provide cache statistics and management commands</li>
<li>Allow configuration of cache retention policies</li>
</ul>
</li>
</ul>
<h2 id="integration-enhancements"><a class="header" href="#integration-enhancements">Integration Enhancements</a></h2>
<h3 id="expanded-cicd-support"><a class="header" href="#expanded-cicd-support">Expanded CI/CD Support</a></h3>
<ul>
<li><strong>Description</strong>: Add native support for more CI/CD platforms</li>
<li><strong>Benefits</strong>:
<ul>
<li>Simplifies integration with popular CI/CD systems</li>
<li>Provides optimized reporting for each platform</li>
<li>Reduces configuration overhead</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Add dedicated integrations for GitHub Actions, GitLab CI, CircleCI, Jenkins, etc.</li>
<li>Create platform-specific report formats</li>
<li>Implement automatic environment detection</li>
<li>Provide example configurations for each platform</li>
</ul>
</li>
</ul>
<h3 id="third-party-tool-integration"><a class="header" href="#third-party-tool-integration">Third-party Tool Integration</a></h3>
<ul>
<li><strong>Description</strong>: Add integration with popular testing and monitoring tools</li>
<li><strong>Benefits</strong>:
<ul>
<li>Creates a more comprehensive testing ecosystem</li>
<li>Leverages existing tools and workflows</li>
<li>Provides richer context for test results</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement integrations with tools like Grafana, Prometheus, ELK Stack</li>
<li>Add export capabilities to various formats</li>
<li>Create webhooks for event-driven integration</li>
<li>Document integration patterns and examples</li>
</ul>
</li>
</ul>
<h2 id="security-enhancements"><a class="header" href="#security-enhancements">Security Enhancements</a></h2>
<h3 id="enhanced-security-testing"><a class="header" href="#enhanced-security-testing">Enhanced Security Testing</a></h3>
<ul>
<li><strong>Description</strong>: Expand security testing capabilities with more specialized checks</li>
<li><strong>Benefits</strong>:
<ul>
<li>Provides more comprehensive security coverage</li>
<li>Identifies more sophisticated vulnerabilities</li>
<li>Aligns with industry security standards</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement OWASP Top 10 checks</li>
<li>Add compliance testing for standards like PCI DSS, HIPAA, GDPR</li>
<li>Integrate with security databases for vulnerability checking</li>
<li>Add security scoring and risk assessment</li>
</ul>
</li>
</ul>
<h3 id="sensitive-data-handling"><a class="header" href="#sensitive-data-handling">Sensitive Data Handling</a></h3>
<ul>
<li><strong>Description</strong>: Improve handling of sensitive data in tests and reports</li>
<li><strong>Benefits</strong>:
<ul>
<li>Prevents accidental exposure of sensitive information</li>
<li>Ensures compliance with data protection regulations</li>
<li>Improves overall security posture</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement automatic detection of sensitive data patterns</li>
<li>Add masking and redaction capabilities</li>
<li>Create secure storage for test credentials</li>
<li>Add audit logging for sensitive data access</li>
</ul>
</li>
</ul>
<h2 id="community-and-collaboration"><a class="header" href="#community-and-collaboration">Community and Collaboration</a></h2>
<h3 id="shared-test-repository"><a class="header" href="#shared-test-repository">Shared Test Repository</a></h3>
<ul>
<li><strong>Description</strong>: Create a repository for sharing and discovering test configurations</li>
<li><strong>Benefits</strong>:
<ul>
<li>Promotes reuse of well-designed tests</li>
<li>Builds community knowledge base</li>
<li>Accelerates test development</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Build a searchable repository of test configurations</li>
<li>Implement rating and commenting system</li>
<li>Add version control and forking capabilities</li>
<li>Create contribution guidelines and review process</li>
</ul>
</li>
</ul>
<h3 id="collaborative-testing"><a class="header" href="#collaborative-testing">Collaborative Testing</a></h3>
<ul>
<li><strong>Description</strong>: Add features for team collaboration on test development and execution</li>
<li><strong>Benefits</strong>:
<ul>
<li>Improves coordination in testing teams</li>
<li>Facilitates knowledge sharing</li>
<li>Streamlines review processes</li>
</ul>
</li>
<li><strong>Implementation Notes</strong>:
<ul>
<li>Implement shared workspaces for test configurations</li>
<li>Add commenting and annotation capabilities</li>
<li>Create role-based access control</li>
<li>Implement notification system for test events</li>
</ul>
</li>
</ul>
<h2 id="implementation-priority"><a class="header" href="#implementation-priority">Implementation Priority</a></h2>
<p>Based on potential impact and implementation complexity, here’s a suggested priority order:</p>
<ol>
<li><strong>Schema Validation</strong> - High impact, relatively low complexity</li>
<li><strong>Markdown Output Mode</strong> - High utility, moderate complexity</li>
<li><strong>Real-time Progress Feedback</strong> - Significant UX improvement</li>
<li><strong>CI Snapshot Mode</strong> - High value for CI/CD workflows</li>
<li><strong>Model Confidence Scoring</strong> - Important for AI reliability</li>
<li><strong>Prompt Flexibility</strong> - Enhances AI customization</li>
<li><strong>AI Feedback Loop</strong> - Long-term AI quality improvement</li>
</ol>
<h2 id="contributing-ideas"><a class="header" href="#contributing-ideas">Contributing Ideas</a></h2>
<p>Have an idea for improving QitOps? We welcome contributions and suggestions from the community. Please submit your ideas through:</p>
<ul>
<li>GitHub Issues: <a href="https://github.com/qitops/qitops-cli-tools/issues">https://github.com/qitops/qitops-cli-tools/issues</a></li>
<li>Discussions: <a href="https://github.com/qitops/qitops-cli-tools/discussions">https://github.com/qitops/qitops-cli-tools/discussions</a></li>
<li>Discord Community: <a href="https://discord.gg/qitops">https://discord.gg/qitops</a></li>
</ul>
<p>When submitting ideas, please include:</p>
<ul>
<li>A clear description of the feature</li>
<li>The problem it solves or benefit it provides</li>
<li>Any implementation suggestions you might have</li>
<li>Examples of how it would be used</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="changelog"><a class="header" href="#changelog">Changelog</a></h1>
<p>All notable changes to QitOps will be documented in this file.</p>
<p>The format is based on <a href="https://keepachangelog.com/en/1.0.0/">Keep a Changelog</a>,
and this project adheres to <a href="https://semver.org/spec/v2.0.0.html">Semantic Versioning</a>.</p>
<h2 id="010---2024-05-10"><a class="header" href="#010---2024-05-10">[0.1.0] - 2024-05-10</a></h2>
<h3 id="added"><a class="header" href="#added">Added</a></h3>
<ul>
<li>Initial release of QitOps CLI</li>
<li>Basic API testing module</li>
<li>Basic performance testing module</li>
<li>Basic security testing module</li>
<li>Basic web testing module</li>
<li>API Collections with variable interpolation and request chaining</li>
<li>Enhanced performance testing with load profiles and scenarios</li>
<li>Data-driven testing with CSV and JSON support</li>
<li>JSON config schema validation</li>
<li>Documentation for all test types</li>
<li>GitHub Actions integration example</li>
</ul>
<h3 id="fixed"><a class="header" href="#fixed">Fixed</a></h3>
<ul>
<li>Dead code warnings in api_collection.rs and performance_enhanced.rs</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributing-to-qitops"><a class="header" href="#contributing-to-qitops">Contributing to QitOps</a></h1>
<p>Thank you for your interest in contributing to QitOps! This document provides guidelines and instructions for contributing to the project.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="contributing.html#code-of-conduct">Code of Conduct</a></li>
<li><a href="contributing.html#getting-started">Getting Started</a></li>
<li><a href="contributing.html#development-environment">Development Environment</a></li>
<li><a href="contributing.html#project-structure">Project Structure</a></li>
<li><a href="contributing.html#contribution-workflow">Contribution Workflow</a></li>
<li><a href="contributing.html#coding-standards">Coding Standards</a></li>
<li><a href="contributing.html#testing-guidelines">Testing Guidelines</a></li>
<li><a href="contributing.html#documentation">Documentation</a></li>
<li><a href="contributing.html#issue-and-pr-labels">Issue and PR Labels</a></li>
<li><a href="contributing.html#release-process">Release Process</a></li>
</ul>
<h2 id="code-of-conduct"><a class="header" href="#code-of-conduct">Code of Conduct</a></h2>
<p>By participating in this project, you agree to abide by our Code of Conduct. Please be respectful, inclusive, and considerate in all interactions.</p>
<h2 id="getting-started-8"><a class="header" href="#getting-started-8">Getting Started</a></h2>
<h3 id="prerequisites-3"><a class="header" href="#prerequisites-3">Prerequisites</a></h3>
<ul>
<li>Rust 1.70 or higher</li>
<li>Cargo</li>
<li>Git</li>
</ul>
<h3 id="setting-up-your-development-environment"><a class="header" href="#setting-up-your-development-environment">Setting Up Your Development Environment</a></h3>
<ol>
<li>Fork the repository on GitHub</li>
<li>Clone your fork locally:
<pre><code class="language-bash">git clone https://github.com/YOUR_USERNAME/qitops-cli-tools.git
cd qitops-cli-tools
</code></pre>
</li>
<li>Add the upstream repository as a remote:
<pre><code class="language-bash">git remote add upstream https://github.com/qitops/qitops-cli-tools.git
</code></pre>
</li>
<li>Build the project:
<pre><code class="language-bash">cargo build
</code></pre>
</li>
<li>Run the tests:
<pre><code class="language-bash">cargo test
</code></pre>
</li>
</ol>
<h2 id="development-environment"><a class="header" href="#development-environment">Development Environment</a></h2>
<h3 id="recommended-tools"><a class="header" href="#recommended-tools">Recommended Tools</a></h3>
<ul>
<li><strong>IDE</strong>: VS Code with rust-analyzer extension or IntelliJ IDEA with Rust plugin</li>
<li><strong>Linting</strong>: Clippy (<code>cargo clippy</code>)</li>
<li><strong>Formatting</strong>: Rustfmt (<code>cargo fmt</code>)</li>
<li><strong>Documentation</strong>: Rustdoc (<code>cargo doc</code>)</li>
</ul>
<h3 id="building-with-features"><a class="header" href="#building-with-features">Building with Features</a></h3>
<p>QitOps supports optional features that can be enabled during build:</p>
<pre><code class="language-bash"># Build with AI features
cargo build --features ai

# Build with all features
cargo build --all-features
</code></pre>
<h2 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h2>
<p>The project follows a modular structure:</p>
<pre><code>qitops/
├── src/
│   ├── main.rs        # CLI parsing using clap
│   ├── api.rs         # API testing implementation
│   ├── performance.rs # Performance testing implementation
│   ├── security.rs    # Security testing implementation
│   ├── web.rs         # Web testing implementation
│   ├── ai.rs          # AI-powered test generation
│   ├── reporting.rs   # Report generation
│   ├── common.rs      # Shared functionality and interfaces
│   └── error.rs       # Error handling
├── tests/
│   └── configs/       # JSON test configuration files
├── .github/
│   └── workflows/     # CI configuration
├── docs/              # Documentation
├── src/templates/     # Template files
└── Cargo.toml         # Dependencies
</code></pre>
<h2 id="contribution-workflow"><a class="header" href="#contribution-workflow">Contribution Workflow</a></h2>
<h3 id="finding-issues-to-work-on"><a class="header" href="#finding-issues-to-work-on">Finding Issues to Work On</a></h3>
<ul>
<li>Check the <a href="https://github.com/qitops/qitops-cli-tools/issues">Issues</a> page</li>
<li>Look for issues labeled <code>good-first-issue</code> or <code>help-wanted</code></li>
<li>Review the <a href="https://github.com/qitops/qitops-cli-tools/projects">Project Board</a> to see current priorities</li>
</ul>
<h3 id="making-changes"><a class="header" href="#making-changes">Making Changes</a></h3>
<ol>
<li>Create a new branch for your changes:
<pre><code class="language-bash">git checkout -b feature/your-feature-name
</code></pre>
</li>
<li>Make your changes</li>
<li>Run tests to ensure your changes don’t break existing functionality:
<pre><code class="language-bash">cargo test
</code></pre>
</li>
<li>Format your code:
<pre><code class="language-bash">cargo fmt
</code></pre>
</li>
<li>Run linting checks:
<pre><code class="language-bash">cargo clippy -- -D warnings
</code></pre>
</li>
<li>Commit your changes with a descriptive commit message:
<pre><code class="language-bash">git commit -m "Add feature: your feature description"
</code></pre>
</li>
<li>Push your changes to your fork:
<pre><code class="language-bash">git push origin feature/your-feature-name
</code></pre>
</li>
<li>Create a Pull Request against the <code>master</code> branch of the main repository</li>
</ol>
<h3 id="pull-request-guidelines"><a class="header" href="#pull-request-guidelines">Pull Request Guidelines</a></h3>
<ul>
<li>Provide a clear description of the changes</li>
<li>Link to any related issues using keywords like “Fixes #123” or “Resolves #456”</li>
<li>Include tests for new functionality</li>
<li>Update documentation as needed</li>
<li>Ensure CI checks pass</li>
<li>Be responsive to feedback and review comments</li>
</ul>
<h2 id="coding-standards"><a class="header" href="#coding-standards">Coding Standards</a></h2>
<h3 id="rust-style-guidelines"><a class="header" href="#rust-style-guidelines">Rust Style Guidelines</a></h3>
<ul>
<li>Follow the <a href="https://rust-lang.github.io/api-guidelines/">Rust API Guidelines</a></li>
<li>Use Rustfmt for consistent formatting</li>
<li>Use Clippy to catch common mistakes and non-idiomatic code</li>
<li>Write clear, descriptive variable and function names</li>
<li>Add comments for complex logic</li>
<li>Use proper error handling with the <code>Result</code> type</li>
</ul>
<h3 id="core-principles"><a class="header" href="#core-principles">Core Principles</a></h3>
<p>When contributing, please keep in mind the core principles of the project:</p>
<ul>
<li>Maintain CLI-first approach with no UI dependencies</li>
<li>Keep dependencies minimal and native</li>
<li>Ensure compatibility with static binary compilation</li>
<li>Preserve clear module boundaries</li>
<li>Design for extensibility</li>
</ul>
<h2 id="testing-guidelines"><a class="header" href="#testing-guidelines">Testing Guidelines</a></h2>
<ul>
<li>Write unit tests for all new functionality</li>
<li>Include integration tests for end-to-end workflows</li>
<li>Test edge cases and error conditions</li>
<li>Use test fixtures in the <code>tests/</code> directory</li>
<li>Mock external dependencies when appropriate</li>
</ul>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<ul>
<li>Update the README.md with any user-facing changes</li>
<li>Add inline documentation using rustdoc comments (<code>///</code>)</li>
<li>Update the user guide in the <code>docs/</code> directory</li>
<li>Include examples for new features</li>
</ul>
<h2 id="issue-and-pr-labels"><a class="header" href="#issue-and-pr-labels">Issue and PR Labels</a></h2>
<p>We use the following label categories:</p>
<h3 id="type-1"><a class="header" href="#type-1">Type</a></h3>
<ul>
<li><code>type:bug</code>: Bug fixes</li>
<li><code>type:feature</code>: New features</li>
<li><code>type:enhancement</code>: Improvements to existing features</li>
<li><code>type:documentation</code>: Documentation updates</li>
<li><code>type:refactor</code>: Code refactoring</li>
<li><code>type:test</code>: Test improvements</li>
</ul>
<h3 id="module"><a class="header" href="#module">Module</a></h3>
<ul>
<li><code>module:api</code>: API testing module</li>
<li><code>module:performance</code>: Performance testing module</li>
<li><code>module:security</code>: Security testing module</li>
<li><code>module:web</code>: Web testing module</li>
<li><code>module:ai</code>: AI integration</li>
<li><code>module:common</code>: Common functionality</li>
<li><code>module:cli</code>: Command-line interface</li>
<li><code>module:reporting</code>: Reporting functionality</li>
</ul>
<h3 id="phase"><a class="header" href="#phase">Phase</a></h3>
<ul>
<li><code>phase:0</code>: Core functionality</li>
<li><code>phase:1</code>: Parity features</li>
<li><code>phase:2</code>: Differentiators</li>
<li><code>phase:3</code>: AI &amp; Ecosystem</li>
</ul>
<h3 id="status"><a class="header" href="#status">Status</a></h3>
<ul>
<li><code>status:blocked</code>: Blocked by another issue</li>
<li><code>status:help-wanted</code>: Looking for contributors</li>
<li><code>status:good-first-issue</code>: Good for newcomers</li>
</ul>
<h2 id="release-process"><a class="header" href="#release-process">Release Process</a></h2>
<ol>
<li>Update version in <code>Cargo.toml</code></li>
<li>Update <code>CHANGELOG.md</code> with the new version and changes</li>
<li>Create a new tag with the version number:
<pre><code class="language-bash">git tag -a v0.1.0 -m "Release v0.1.0"
</code></pre>
</li>
<li>Push the tag to trigger the release workflow:
<pre><code class="language-bash">git push origin v0.1.0
</code></pre>
</li>
<li>The CI/CD pipeline will automatically:
<ul>
<li>Build the release binaries</li>
<li>Publish to crates.io</li>
<li>Create a GitHub Release</li>
<li>Push Docker images</li>
</ul>
</li>
</ol>
<h2 id="thank-you"><a class="header" href="#thank-you">Thank You!</a></h2>
<p>Your contributions help make QitOps better for everyone. We appreciate your time and effort!</p>
<div style="break-before: page; page-break-before: always;"></div><p>MIT License</p>
<p>Copyright (c) 2024 Jonathan Opperman</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="github-pages-setup"><a class="header" href="#github-pages-setup">GitHub Pages Setup</a></h1>
<p>This document explains how the QitOps documentation is deployed to GitHub Pages.</p>
<h2 id="overview-7"><a class="header" href="#overview-7">Overview</a></h2>
<p>The QitOps documentation is built using <a href="https://rust-lang.github.io/mdBook/">mdBook</a> and automatically deployed to GitHub Pages whenever changes are pushed to the <code>master</code> branch that affect the documentation.</p>
<p>The deployed documentation is available at: <a href="https://qitops.github.io/qitops-cli-tools/">https://qitops.github.io/qitops-cli-tools/</a></p>
<h2 id="deployment-workflow"><a class="header" href="#deployment-workflow">Deployment Workflow</a></h2>
<p>The deployment is handled by a GitHub Actions workflow defined in <code>.github/workflows/docs.yml</code>. This workflow:</p>
<ol>
<li>
<p>Triggers when changes are pushed to the <code>master</code> branch that affect:</p>
<ul>
<li>Files in the <code>docs/</code> directory</li>
<li>The <code>README.md</code> file</li>
<li>The workflow file itself</li>
</ul>
</li>
<li>
<p>Sets up mdBook using the <code>peaceiris/actions-mdbook@v1</code> action</p>
</li>
<li>
<p>Copies key files to the docs directory:</p>
<ul>
<li><code>README.md</code> → <code>docs/index.md</code></li>
<li><code>CHANGELOG.md</code> → <code>docs/changelog.md</code></li>
<li><code>ROADMAP.md</code> → <code>docs/roadmap.md</code></li>
<li><code>CONTRIBUTING.md</code> → <code>docs/contributing.md</code></li>
</ul>
</li>
<li>
<p>Creates a <code>book.toml</code> configuration file if it doesn’t exist</p>
</li>
<li>
<p>Builds the documentation using mdBook</p>
</li>
<li>
<p>Deploys the built documentation to the <code>gh-pages</code> branch using the <code>peaceiris/actions-gh-pages@v3</code> action</p>
</li>
</ol>
<h2 id="enabling-github-pages"><a class="header" href="#enabling-github-pages">Enabling GitHub Pages</a></h2>
<p>To enable GitHub Pages for the QitOps documentation:</p>
<ol>
<li>Go to the repository on GitHub</li>
<li>Navigate to Settings &gt; Pages</li>
<li>Under “Build and deployment”, set the following:
<ul>
<li>Source: “Deploy from a branch”</li>
<li>Branch: “gh-pages”</li>
<li>Folder: “/ (root)”</li>
</ul>
</li>
<li>Click “Save”</li>
</ol>
<h3 id="using-the-github-cli"><a class="header" href="#using-the-github-cli">Using the GitHub CLI</a></h3>
<p>If you have the GitHub CLI installed and authenticated, you can enable GitHub Pages with the following command:</p>
<pre><code class="language-bash">gh api -X PUT repos/qitops/qitops-cli-tools/pages \
  -H "Accept: application/vnd.github+json" \
  -H "X-GitHub-Api-Version: 2022-11-28" \
  -f build_type=workflow \
  -f source.branch=gh-pages \
  -f source.path=/
</code></pre>
<p>This requires a personal access token with the <code>repo</code> scope.</p>
<h2 id="configuration-6"><a class="header" href="#configuration-6">Configuration</a></h2>
<p>The documentation is configured in the <code>docs/book.toml</code> file, which includes:</p>
<ul>
<li>Book metadata (title, authors, etc.)</li>
<li>HTML output configuration</li>
<li>GitHub repository information</li>
<li>Search settings</li>
<li>Custom CSS and JavaScript</li>
</ul>
<p>Key configuration settings:</p>
<pre><code class="language-toml">[book]
authors = ["Jonathan Opperman"]
language = "en"
multilingual = false
src = "."
title = "QitOps Documentation"

[output.html]
git-repository-url = "https://github.com/qitops/qitops-cli-tools"
git-repository-icon = "fa-github"
edit-url-template = "https://github.com/qitops/qitops-cli-tools/edit/master/docs/{path}"
site-url = "/qitops-cli-tools/"
</code></pre>
<p>The <code>site-url</code> setting is particularly important for GitHub Pages, as it ensures that all relative URLs are correctly resolved.</p>
<h2 id="verifying-the-setup"><a class="header" href="#verifying-the-setup">Verifying the Setup</a></h2>
<p>Once GitHub Pages is enabled, you can verify that the documentation is accessible by visiting:
https://qitops.github.io/qitops-cli-tools/</p>
<h2 id="troubleshooting-10"><a class="header" href="#troubleshooting-10">Troubleshooting</a></h2>
<p>If the documentation is not accessible after enabling GitHub Pages:</p>
<ol>
<li>Check that the gh-pages branch exists</li>
<li>Check that the GitHub Actions workflow has run successfully</li>
<li>Check that the gh-pages branch contains the built documentation</li>
<li>Wait a few minutes for the changes to propagate</li>
<li>Verify that the <code>site-url</code> in <code>book.toml</code> is set correctly</li>
<li>Check the GitHub Actions logs for any errors</li>
</ol>
<h2 id="local-development"><a class="header" href="#local-development">Local Development</a></h2>
<p>To preview the documentation locally:</p>
<ol>
<li>
<p>Install mdBook:</p>
<pre><code class="language-bash">cargo install mdbook
</code></pre>
</li>
<li>
<p>Run the development server:</p>
<pre><code class="language-bash">cd docs
mdbook serve --open
</code></pre>
</li>
<li>
<p>This will open the documentation in your browser and automatically reload when you make changes</p>
</li>
</ol>
<h2 id="adding-new-pages"><a class="header" href="#adding-new-pages">Adding New Pages</a></h2>
<p>To add a new page to the documentation:</p>
<ol>
<li>Create a new Markdown file in the <code>docs</code> directory</li>
<li>Add the page to the <code>SUMMARY.md</code> file to include it in the navigation</li>
</ol>
<p>Example <code>SUMMARY.md</code> entry:</p>
<pre><code class="language-markdown"># Summary

- [Introduction](index.md)
- [Your New Page](your-new-page.md)
</code></pre>
<h2 id="customization"><a class="header" href="#customization">Customization</a></h2>
<p>The documentation uses custom CSS and JavaScript files for styling and interactivity:</p>
<ul>
<li><code>custom.css</code>: Contains custom styles for the documentation</li>
<li><code>custom.js</code>: Contains custom JavaScript for interactive features</li>
</ul>
<p>These files are referenced in the <code>book.toml</code> file.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="editor.js"></script>
        <script src="mode-rust.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="custom.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
